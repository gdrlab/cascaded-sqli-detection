{"cells":[{"cell_type":"markdown","metadata":{"id":"kRXA63pgF_5J"},"source":["# Experiments of the paper: \"Efficient Detection of SQL Injection Attacks Utilising Cascade Natural Language Processing\""]},{"cell_type":"markdown","metadata":{"id":"mlW1ajN9GOp_"},"source":["## Initializations"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"MqgCOCzc1AFe","executionInfo":{"status":"ok","timestamp":1685444573829,"user_tz":-60,"elapsed":197,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}}},"outputs":[],"source":["#%load_ext autoreload\n","#%autoreload 2"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18975,"status":"ok","timestamp":1685448605215,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"r3SajLBfMY2f","outputId":"78c6e239-2b11-4a1b-941d-e4954aa77b38"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"newbm9LK79G_","executionInfo":{"status":"ok","timestamp":1685448616417,"user_tz":-60,"elapsed":396,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}}},"outputs":[],"source":["from pathlib import Path\n","main_folder = Path('/content/drive/MyDrive/Akademik/Research and Projects/Sakir Hoca Projects/AI Security Intelligence/Codes/20230525_sqli_colab')\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4572,"status":"ok","timestamp":1685448621387,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"w_-R9cC9lWx8","outputId":"8d35752b-d79d-4f56-bf4e-7b72f8a2cc59"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Akademik/Research and Projects/Sakir Hoca Projects/AI Security Intelligence/Codes/20230525_sqli_colab\n","total 194K\n","-rw------- 1 root root 3.6K May 23 14:01 classical_models.py\n","-rw------- 1 root root 1.2K May 30 11:02 config.ini\n","drwx------ 2 root root 4.0K May 11 11:42 \u001b[0m\u001b[01;34mdatasets\u001b[0m/\n","-rw------- 1 root root 7.7K May 23 14:01 ensemble_models.py\n","-rw------- 1 root root  20K May 25 12:48 experiments.py\n","-rw------- 1 root root  813 Apr 17 09:08 .gitignore\n","-rw------- 1 root root    3 Apr  3 11:59 LICENSE.md\n","-rw------- 1 root root 126K May 30 12:10 main.ipynb\n","drwx------ 2 root root 4.0K May 25 13:15 \u001b[01;34m__pycache__\u001b[0m/\n","-rw------- 1 root root 5.4K May 11 10:49 README.md\n","drwx------ 2 root root 4.0K May 25 13:06 \u001b[01;34mresults\u001b[0m/\n","-rw------- 1 root root 1.3K May 25 15:31 run_classical_MLs.py\n","-rw------- 1 root root  318 May 11 10:49 sqli-env.yml\n","-rw------- 1 root root 6.3K May 25 14:56 templates.py\n","drwx------ 2 root root 4.0K Apr  3 11:59 \u001b[01;34mtrained_models\u001b[0m/\n","drwx------ 2 root root 4.0K May 25 13:05 \u001b[01;34mutils\u001b[0m/\n"]}],"source":["%cd $main_folder\n","%ls -lah"]},{"cell_type":"markdown","metadata":{"id":"k0DXUQ1tIqEF"},"source":["Warning: BERT libraries had problems after Colab system is upgraded. The solution I found is to downgrade numpy. After running the following code, restart the session and check the numpy version. If the libraries are working just fine in future, you can remove the downgrade fix."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xmn1CHABCsZi"},"outputs":[],"source":["#!pip install -q -U numpy==1.22 --ignore-installed"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1602,"status":"ok","timestamp":1685448625096,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"tqD40wf4069j","outputId":"d0d398c7-f9cc-47dc-f3a1-c05d121ac2ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["numpy: \t\t 1.22.4\n","sklearn: \t 1.2.2\n","Python 3.10.11\n"]}],"source":["import numpy as np\n","import sklearn\n","print(\"numpy: \\t\\t\", np.__version__)\n","print(\"sklearn: \\t\", sklearn.__version__)\n","!python --version"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6252,"status":"ok","timestamp":1685448634053,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"q-YbjCkzw0yU","outputId":"d2a399ab-3921-4ceb-d3b5-5d4a52961681"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m5.7/6.0 MB\u001b[0m \u001b[31m171.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# A dependency of the preprocessing for BERT inputs\n","#!pip install  -q -U \"tensorflow-text==2.8.*\"\n","!pip install  -q -U \"tensorflow-text\""]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28809,"status":"ok","timestamp":1685448662859,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"b-P1ZOA0FkVJ","outputId":"41eeed9b-419c-451a-ffd0-4083799c3c36"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyyaml (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["#!pip install -q tf-models-official==2.7.0\n","!pip install -q tf-models-official"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":391,"status":"ok","timestamp":1685448681018,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"Fw2_o8VS_hpZ","outputId":"ea651252-2bc4-4d82-9f43-0a68317bea9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["The scikit-learn version is 1.2.2.\n"]}],"source":["import sklearn\n","print('The scikit-learn version is {}.'.format(sklearn.__version__))"]},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","from official.nlp import optimization  # to create AdamW optimizer\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-OeGI62dUKnL","executionInfo":{"status":"ok","timestamp":1685448687246,"user_tz":-60,"elapsed":2156,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}},"outputId":"09a171d7-4c9a-4099-ffda-c423ecd27b5b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3579,"status":"ok","timestamp":1685448690817,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"b9AprPGFMhQ4","outputId":"496ea4b3-1aeb-4e2e-93f7-816039e35ce3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Pandas v 1.5.3\n"]}],"source":["from pathlib import Path\n","from datetime import datetime\n","import os\n","import shutil\n","\n","\n","import matplotlib.pyplot as plt\n","\n","import pandas as pd\n","import time\n","\n","\n","import time\n","from sklearn import metrics\n","from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n","\n","from experiments import evaluate, save_results\n","\n","print('Pandas v', pd.__version__)\n","#tf.get_logger().setLevel('ERROR')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1685448694325,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"iXfCnfKRZMty","outputId":"c938b113-9d77-40d6-9a23-4655a4e39062"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue May 30 12:11:33 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    46W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":[" !nvidia-smi"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1415,"status":"ok","timestamp":1685448699882,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"t48CqXYRmrey","outputId":"2ade8fde-a5e7-40f4-e477-ab4d7569bd56"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['config.ini']"]},"metadata":{},"execution_count":11}],"source":["import configparser\n","from templates import DataManager, logger\n","config = configparser.ConfigParser()\n","config.read('config.ini')"]},{"cell_type":"code","source":["config.get('models', 'classic_models').split(',')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eWQiFbnlVMcC","executionInfo":{"status":"ok","timestamp":1685448702307,"user_tz":-60,"elapsed":836,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}},"outputId":"0b6f482c-1978-4e4e-9b05-83ba966efb81"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['MultinomialNB']"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","execution_count":13,"metadata":{"id":"nseZXgKhpjjh","executionInfo":{"status":"ok","timestamp":1685448707470,"user_tz":-60,"elapsed":2239,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}}},"outputs":[],"source":["data_manager = DataManager(config)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":392,"status":"ok","timestamp":1685451925189,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"ccnJtym5lWx-","outputId":"4b17e30e-fb9b-42b7-a1f0-be96a491771c"},"outputs":[{"output_type":"stream","name":"stdout","text":["All results:/content/drive/MyDrive/Akademik/Research and Projects/Sakir Hoca Projects/AI Security Intelligence/Codes/20230525_sqli_colab/results/results_230530_130524.csv\n","Proposed method results:/content/drive/MyDrive/Akademik/Research and Projects/Sakir Hoca Projects/AI Security Intelligence/Codes/20230525_sqli_colab/results/proposed_method_results_230530_130524.csv\n"]}],"source":["#%%script echo skipping\n","results_dir = Path(config['results']['dir'])\n","\n","currentDateAndTime = datetime.now()\n","currentTime = currentDateAndTime.strftime(\"%y%m%d_%H%M%S\")\n","file_name = f'results_{currentTime}.csv'\n","output_file = main_folder / results_dir / file_name\n","proposed_test_results_file = main_folder / results_dir / f'proposed_method_results_{currentTime}.csv'\n","print(f\"All results:{output_file.absolute()}\")\n","print(f\"Proposed method results:{proposed_test_results_file.absolute()}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tr6pW32WGi1D"},"source":["## Classical ML (Single NLP) tests"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8RC2O_SyuIFe","outputId":"4d20e04a-3b9e-43a9-abf4-8a4373d1f1f7","executionInfo":{"status":"ok","timestamp":1685447125183,"user_tz":-60,"elapsed":2432604,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["05-30-2023 11:04:54 l:27| Loaded dataset with 30609 rows.\n","Running the tests for seed: 13\n","\rFeature extractors:   0% 0/1 [00:00<?, ?it/s]05-30-2023 11:04:54 l:83| running 1 of 1 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/1 [00:00<?, ?it/s]\u001b[A05-30-2023 11:04:56 l:91| running 1 of 1 models.\n","05-30-2023 11:04:56 l:151| Training model: MultinomialNB\n","05-30-2023 11:04:56 l:159| Ended training MultinomialNB in: 0.01803496399998039s\n","Models: 100% 1/1 [00:00<00:00, 29.68it/s]\n","Feature extractors: 100% 1/1 [00:02<00:00,  2.53s/it]\n","Feature extractors:   0% 0/3 [00:00<?, ?it/s]05-30-2023 11:04:56 l:130| running 1 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00<?, ?it/s]\u001b[A05-30-2023 11:04:57 l:138| running 1 of 3 models.\n","05-30-2023 11:04:57 l:151| Training model: MultinomialNB\n","05-30-2023 11:04:57 l:159| Ended training MultinomialNB in: 0.006296860000020388s\n","05-30-2023 11:04:57 l:138| running 2 of 3 models.\n","05-30-2023 11:04:57 l:151| Training model: XGBoost\n","05-30-2023 11:05:04 l:159| Ended training XGBoost in: 6.85623572999998s\n","\n","Models:  67% 2/3 [00:06<00:03,  3.46s/it]\u001b[A05-30-2023 11:05:04 l:138| running 3 of 3 models.\n","05-30-2023 11:05:04 l:151| Training model: SVM_RBF\n","05-30-2023 11:05:56 l:159| Ended training SVM_RBF in: 52.40523154900001s\n","\n","Models: 100% 3/3 [01:03<00:00, 21.32s/it]\n","Feature extractors:  33% 1/3 [01:04<02:08, 64.28s/it]05-30-2023 11:06:01 l:130| running 2 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00<?, ?it/s]\u001b[A05-30-2023 11:06:03 l:138| running 1 of 3 models.\n","05-30-2023 11:06:03 l:151| Training model: MultinomialNB\n","05-30-2023 11:06:03 l:159| Ended training MultinomialNB in: 0.019615487000010035s\n","05-30-2023 11:06:03 l:138| running 2 of 3 models.\n","05-30-2023 11:06:03 l:151| Training model: XGBoost\n","05-30-2023 11:07:02 l:159| Ended training XGBoost in: 58.610316614s\n","\n","Models:  67% 2/3 [00:58<00:29, 29.35s/it]\u001b[A05-30-2023 11:07:02 l:138| running 3 of 3 models.\n","05-30-2023 11:07:02 l:151| Training model: SVM_RBF\n","05-30-2023 11:09:32 l:159| Ended training SVM_RBF in: 149.5996260999999s\n","\n","Models: 100% 3/3 [03:44<00:00, 74.71s/it]\n","Feature extractors:  67% 2/3 [04:50<02:39, 159.75s/it]05-30-2023 11:09:47 l:130| running 3 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00<?, ?it/s]\u001b[A05-30-2023 11:09:48 l:138| running 1 of 3 models.\n","05-30-2023 11:09:48 l:151| Training model: MultinomialNB\n","05-30-2023 11:09:48 l:159| Ended training MultinomialNB in: 0.010467838999943524s\n","05-30-2023 11:09:48 l:138| running 2 of 3 models.\n","05-30-2023 11:09:48 l:151| Training model: XGBoost\n","05-30-2023 11:09:54 l:159| Ended training XGBoost in: 5.755510515999958s\n","\n","Models:  67% 2/3 [00:05<00:02,  2.91s/it]\u001b[A05-30-2023 11:09:54 l:138| running 3 of 3 models.\n","05-30-2023 11:09:54 l:151| Training model: SVM_RBF\n","05-30-2023 11:10:00 l:159| Ended training SVM_RBF in: 6.1893083809999325s\n","\n","Models: 100% 3/3 [00:14<00:00,  4.69s/it]\n","Feature extractors: 100% 3/3 [05:05<00:00, 101.99s/it]\n","05-30-2023 11:10:02 l:151| Training model: ensemble_1\n","05-30-2023 11:10:02 l:159| Ended training ensemble_1 in: 2.8134999979556596e-05s\n","05-30-2023 11:10:24 l:151| Training model: ensemble_2\n","05-30-2023 11:10:24 l:159| Ended training ensemble_2 in: 2.014100004998909e-05s\n","05-30-2023 11:10:47 l:151| Training model: ensemble_3\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","05-30-2023 11:12:47 l:159| Ended training ensemble_3 in: 120.02593776599997s\n","05-30-2023 11:12:59 l:40| header is True\n","05-30-2023 11:12:59 l:270| Results saved to results/results_230530_110449.csv\n","05-30-2023 11:12:59 l:188| Params saved to results/params_230530_110449.json\n","Running the tests for seed: 27\n","Feature extractors:   0% 0/1 [00:00<?, ?it/s]05-30-2023 11:12:59 l:83| running 1 of 1 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/1 [00:00<?, ?it/s]\u001b[A05-30-2023 11:13:01 l:91| running 1 of 1 models.\n","05-30-2023 11:13:01 l:151| Training model: MultinomialNB\n","05-30-2023 11:13:01 l:159| Ended training MultinomialNB in: 0.018002313000010872s\n","Models: 100% 1/1 [00:00<00:00, 28.36it/s]\n","Feature extractors: 100% 1/1 [00:02<00:00,  2.52s/it]\n","Feature extractors:   0% 0/3 [00:00<?, ?it/s]05-30-2023 11:13:01 l:130| running 1 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00<?, ?it/s]\u001b[A05-30-2023 11:13:02 l:138| running 1 of 3 models.\n","05-30-2023 11:13:02 l:151| Training model: MultinomialNB\n","05-30-2023 11:13:02 l:159| Ended training MultinomialNB in: 0.006548955999960526s\n","05-30-2023 11:13:02 l:138| running 2 of 3 models.\n","05-30-2023 11:13:02 l:151| Training model: XGBoost\n","05-30-2023 11:13:06 l:159| Ended training XGBoost in: 4.0525390660000085s\n","\n","Models:  67% 2/3 [00:04<00:02,  2.05s/it]\u001b[A05-30-2023 11:13:06 l:138| running 3 of 3 models.\n","05-30-2023 11:13:06 l:151| Training model: SVM_RBF\n","05-30-2023 11:14:00 l:159| Ended training SVM_RBF in: 54.14530865500001s\n","\n","Models: 100% 3/3 [01:01<00:00, 20.55s/it]\n","Feature extractors:  33% 1/3 [01:01<02:03, 61.96s/it]05-30-2023 11:14:03 l:130| running 2 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00<?, ?it/s]\u001b[A05-30-2023 11:14:06 l:138| running 1 of 3 models.\n","05-30-2023 11:14:06 l:151| Training model: MultinomialNB\n","05-30-2023 11:14:06 l:159| Ended training MultinomialNB in: 0.029453525000008085s\n","05-30-2023 11:14:06 l:138| running 2 of 3 models.\n","05-30-2023 11:14:06 l:151| Training model: XGBoost\n","05-30-2023 11:15:07 l:159| Ended training XGBoost in: 60.22849795200011s\n","\n","Models:  67% 2/3 [01:00<00:30, 30.17s/it]\u001b[A05-30-2023 11:15:07 l:138| running 3 of 3 models.\n","05-30-2023 11:15:07 l:151| Training model: SVM_RBF\n","05-30-2023 11:17:38 l:159| Ended training SVM_RBF in: 151.41637586900015s\n","\n","Models: 100% 3/3 [03:48<00:00, 76.04s/it]\n","Feature extractors:  67% 2/3 [04:53<02:41, 161.44s/it]05-30-2023 11:17:54 l:130| running 3 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00<?, ?it/s]\u001b[A05-30-2023 11:17:55 l:138| running 1 of 3 models.\n","05-30-2023 11:17:55 l:151| Training model: MultinomialNB\n","05-30-2023 11:17:55 l:159| Ended training MultinomialNB in: 0.009933487999887802s\n","05-30-2023 11:17:55 l:138| running 2 of 3 models.\n","05-30-2023 11:17:55 l:151| Training model: XGBoost\n","05-30-2023 11:18:01 l:159| Ended training XGBoost in: 5.153582814999936s\n","\n","Models:  67% 2/3 [00:05<00:02,  2.61s/it]\u001b[A05-30-2023 11:18:01 l:138| running 3 of 3 models.\n","05-30-2023 11:18:01 l:151| Training model: SVM_RBF\n","05-30-2023 11:18:07 l:159| Ended training SVM_RBF in: 6.133662437999874s\n","\n","Models: 100% 3/3 [00:13<00:00,  4.51s/it]\n","Feature extractors: 100% 3/3 [05:07<00:00, 102.54s/it]\n","05-30-2023 11:18:09 l:151| Training model: ensemble_1\n","05-30-2023 11:18:09 l:159| Ended training ensemble_1 in: 2.4804000076983357e-05s\n","05-30-2023 11:18:31 l:151| Training model: ensemble_2\n","05-30-2023 11:18:31 l:159| Ended training ensemble_2 in: 3.475299990896019e-05s\n","05-30-2023 11:18:52 l:151| Training model: ensemble_3\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","05-30-2023 11:20:55 l:159| Ended training ensemble_3 in: 122.95542997199982s\n","05-30-2023 11:21:07 l:40| header is True\n","05-30-2023 11:21:07 l:48| Appending to the existing .csv file.\n","05-30-2023 11:21:07 l:270| Results saved to results/results_230530_110449.csv\n","05-30-2023 11:21:07 l:188| Params saved to results/params_230530_110449.json\n","Running the tests for seed: 42\n","Feature extractors:   0% 0/1 [00:00<?, ?it/s]05-30-2023 11:21:07 l:83| running 1 of 1 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/1 [00:00<?, ?it/s]\u001b[A05-30-2023 11:21:10 l:91| running 1 of 1 models.\n","05-30-2023 11:21:10 l:151| Training model: MultinomialNB\n","05-30-2023 11:21:10 l:159| Ended training MultinomialNB in: 0.018059602999983326s\n","Models: 100% 1/1 [00:00<00:00, 28.49it/s]\n","Feature extractors: 100% 1/1 [00:02<00:00,  2.51s/it]\n","Feature extractors:   0% 0/3 [00:00<?, ?it/s]05-30-2023 11:21:10 l:130| running 1 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00<?, ?it/s]\u001b[A05-30-2023 11:21:10 l:138| running 1 of 3 models.\n","05-30-2023 11:21:10 l:151| Training model: MultinomialNB\n","05-30-2023 11:21:10 l:159| Ended training MultinomialNB in: 0.006110227999897688s\n","05-30-2023 11:21:10 l:138| running 2 of 3 models.\n","05-30-2023 11:21:10 l:151| Training model: XGBoost\n","05-30-2023 11:21:14 l:159| Ended training XGBoost in: 4.031907921999846s\n","\n","Models:  67% 2/3 [00:04<00:02,  2.04s/it]\u001b[A05-30-2023 11:21:14 l:138| running 3 of 3 models.\n","05-30-2023 11:21:14 l:151| Training model: SVM_RBF\n","05-30-2023 11:22:08 l:159| Ended training SVM_RBF in: 53.77886760399997s\n","\n","Models: 100% 3/3 [01:01<00:00, 20.39s/it]\n","Feature extractors:  33% 1/3 [01:01<02:02, 61.49s/it]05-30-2023 11:22:11 l:130| running 2 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00<?, ?it/s]\u001b[A05-30-2023 11:22:14 l:138| running 1 of 3 models.\n","05-30-2023 11:22:14 l:151| Training model: MultinomialNB\n","05-30-2023 11:22:14 l:159| Ended training MultinomialNB in: 0.017960390999860465s\n","05-30-2023 11:22:14 l:138| running 2 of 3 models.\n","05-30-2023 11:22:14 l:151| Training model: XGBoost\n","05-30-2023 11:23:10 l:159| Ended training XGBoost in: 55.72350344200004s\n","\n","Models:  67% 2/3 [00:55<00:27, 27.90s/it]\u001b[A05-30-2023 11:23:10 l:138| running 3 of 3 models.\n","05-30-2023 11:23:10 l:151| Training model: SVM_RBF\n","05-30-2023 11:25:42 l:159| Ended training SVM_RBF in: 152.02588985300008s\n","\n","Models: 100% 3/3 [03:43<00:00, 74.49s/it]\n","Feature extractors:  67% 2/3 [04:47<02:38, 158.20s/it]05-30-2023 11:25:57 l:130| running 3 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00<?, ?it/s]\u001b[A05-30-2023 11:25:58 l:138| running 1 of 3 models.\n","05-30-2023 11:25:58 l:151| Training model: MultinomialNB\n","05-30-2023 11:25:58 l:159| Ended training MultinomialNB in: 0.006620892999990247s\n","05-30-2023 11:25:58 l:138| running 2 of 3 models.\n","05-30-2023 11:25:58 l:151| Training model: XGBoost\n","05-30-2023 11:26:02 l:159| Ended training XGBoost in: 4.001867161999826s\n","\n","Models:  67% 2/3 [00:04<00:02,  2.03s/it]\u001b[A05-30-2023 11:26:02 l:138| running 3 of 3 models.\n","05-30-2023 11:26:02 l:151| Training model: SVM_RBF\n","05-30-2023 11:26:09 l:159| Ended training SVM_RBF in: 6.914205625000022s\n","\n","Models: 100% 3/3 [00:12<00:00,  4.19s/it]\n","Feature extractors: 100% 3/3 [05:00<00:00, 100.17s/it]\n","05-30-2023 11:26:10 l:151| Training model: ensemble_1\n","05-30-2023 11:26:10 l:159| Ended training ensemble_1 in: 1.9982000139862066e-05s\n","05-30-2023 11:26:31 l:151| Training model: ensemble_2\n","05-30-2023 11:26:31 l:159| Ended training ensemble_2 in: 2.362800000810239e-05s\n","05-30-2023 11:26:53 l:151| Training model: ensemble_3\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","05-30-2023 11:28:53 l:159| Ended training ensemble_3 in: 119.26276204500004s\n","05-30-2023 11:29:05 l:40| header is True\n","05-30-2023 11:29:05 l:48| Appending to the existing .csv file.\n","05-30-2023 11:29:05 l:270| Results saved to results/results_230530_110449.csv\n","05-30-2023 11:29:05 l:188| Params saved to results/params_230530_110449.json\n","Running the tests for seed: 72\n","Feature extractors:   0% 0/1 [00:00<?, ?it/s]05-30-2023 11:29:05 l:83| running 1 of 1 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/1 [00:00<?, ?it/s]\u001b[A05-30-2023 11:29:07 l:91| running 1 of 1 models.\n","05-30-2023 11:29:07 l:151| Training model: MultinomialNB\n","05-30-2023 11:29:07 l:159| Ended training MultinomialNB in: 0.018817488999957277s\n","Models: 100% 1/1 [00:00<00:00, 27.34it/s]\n","Feature extractors: 100% 1/1 [00:02<00:00,  2.50s/it]\n","Feature extractors:   0% 0/3 [00:00<?, ?it/s]05-30-2023 11:29:07 l:130| running 1 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00<?, ?it/s]\u001b[A05-30-2023 11:29:08 l:138| running 1 of 3 models.\n","05-30-2023 11:29:08 l:151| Training model: MultinomialNB\n","05-30-2023 11:29:08 l:159| Ended training MultinomialNB in: 0.006257344000005105s\n","05-30-2023 11:29:08 l:138| running 2 of 3 models.\n","05-30-2023 11:29:08 l:151| Training model: XGBoost\n","05-30-2023 11:29:15 l:159| Ended training XGBoost in: 6.888748441000189s\n","\n","Models:  67% 2/3 [00:06<00:03,  3.47s/it]\u001b[A05-30-2023 11:29:15 l:138| running 3 of 3 models.\n","05-30-2023 11:29:15 l:151| Training model: SVM_RBF\n","05-30-2023 11:30:07 l:159| Ended training SVM_RBF in: 52.70790419600007s\n","\n","Models: 100% 3/3 [01:04<00:00, 21.47s/it]\n","Feature extractors:  33% 1/3 [01:04<02:09, 64.72s/it]05-30-2023 11:30:12 l:130| running 2 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00<?, ?it/s]\u001b[A05-30-2023 11:30:14 l:138| running 1 of 3 models.\n","05-30-2023 11:30:14 l:151| Training model: MultinomialNB\n","05-30-2023 11:30:15 l:159| Ended training MultinomialNB in: 0.018933567999965817s\n","05-30-2023 11:30:15 l:138| running 2 of 3 models.\n","05-30-2023 11:30:15 l:151| Training model: XGBoost\n","05-30-2023 11:31:11 l:159| Ended training XGBoost in: 56.201926562999915s\n","\n","Models:  67% 2/3 [00:56<00:28, 28.15s/it]\u001b[A05-30-2023 11:31:11 l:138| running 3 of 3 models.\n","05-30-2023 11:31:11 l:151| Training model: SVM_RBF\n","05-30-2023 11:33:41 l:159| Ended training SVM_RBF in: 150.7058733859999s\n","\n","Models: 100% 3/3 [03:42<00:00, 74.27s/it]\n","Feature extractors:  67% 2/3 [04:50<02:39, 159.17s/it]05-30-2023 11:33:57 l:130| running 3 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00<?, ?it/s]\u001b[A05-30-2023 11:33:58 l:138| running 1 of 3 models.\n","05-30-2023 11:33:58 l:151| Training model: MultinomialNB\n","05-30-2023 11:33:58 l:159| Ended training MultinomialNB in: 0.006857595999917976s\n","05-30-2023 11:33:58 l:138| running 2 of 3 models.\n","05-30-2023 11:33:58 l:151| Training model: XGBoost\n","05-30-2023 11:34:05 l:159| Ended training XGBoost in: 6.812119201999849s\n","\n","Models:  67% 2/3 [00:06<00:03,  3.44s/it]\u001b[A05-30-2023 11:34:05 l:138| running 3 of 3 models.\n","05-30-2023 11:34:05 l:151| Training model: SVM_RBF\n","05-30-2023 11:34:11 l:159| Ended training SVM_RBF in: 6.200773935999678s\n","\n","Models: 100% 3/3 [00:14<00:00,  4.98s/it]\n","Feature extractors: 100% 3/3 [05:05<00:00, 101.83s/it]\n","05-30-2023 11:34:13 l:151| Training model: ensemble_1\n","05-30-2023 11:34:13 l:159| Ended training ensemble_1 in: 2.8321999707259238e-05s\n","05-30-2023 11:34:35 l:151| Training model: ensemble_2\n","05-30-2023 11:34:35 l:159| Ended training ensemble_2 in: 2.506500004528789e-05s\n","05-30-2023 11:34:56 l:151| Training model: ensemble_3\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","05-30-2023 11:36:56 l:159| Ended training ensemble_3 in: 119.97725809200028s\n","05-30-2023 11:37:09 l:40| header is True\n","05-30-2023 11:37:09 l:48| Appending to the existing .csv file.\n","05-30-2023 11:37:09 l:270| Results saved to results/results_230530_110449.csv\n","05-30-2023 11:37:09 l:188| Params saved to results/params_230530_110449.json\n","Running the tests for seed: 84\n","Feature extractors:   0% 0/1 [00:00<?, ?it/s]05-30-2023 11:37:09 l:83| running 1 of 1 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/1 [00:00<?, ?it/s]\u001b[A05-30-2023 11:37:12 l:91| running 1 of 1 models.\n","05-30-2023 11:37:12 l:151| Training model: MultinomialNB\n","05-30-2023 11:37:12 l:159| Ended training MultinomialNB in: 0.01808990800009269s\n","Models: 100% 1/1 [00:00<00:00, 27.90it/s]\n","Feature extractors: 100% 1/1 [00:02<00:00,  2.51s/it]\n","Feature extractors:   0% 0/3 [00:00<?, ?it/s]05-30-2023 11:37:12 l:130| running 1 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00<?, ?it/s]\u001b[A05-30-2023 11:37:12 l:138| running 1 of 3 models.\n","05-30-2023 11:37:12 l:151| Training model: MultinomialNB\n","05-30-2023 11:37:12 l:159| Ended training MultinomialNB in: 0.006708681999953114s\n","05-30-2023 11:37:12 l:138| running 2 of 3 models.\n","05-30-2023 11:37:12 l:151| Training model: XGBoost\n","05-30-2023 11:37:16 l:159| Ended training XGBoost in: 4.048851153999749s\n","\n","Models:  67% 2/3 [00:04<00:02,  2.05s/it]\u001b[A05-30-2023 11:37:16 l:138| running 3 of 3 models.\n","05-30-2023 11:37:16 l:151| Training model: SVM_RBF\n","05-30-2023 11:38:11 l:159| Ended training SVM_RBF in: 54.28408469999977s\n","\n","Models: 100% 3/3 [01:01<00:00, 20.59s/it]\n","Feature extractors:  33% 1/3 [01:02<02:04, 62.12s/it]05-30-2023 11:38:14 l:130| running 2 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00<?, ?it/s]\u001b[A05-30-2023 11:38:17 l:138| running 1 of 3 models.\n","05-30-2023 11:38:17 l:151| Training model: MultinomialNB\n","05-30-2023 11:38:17 l:159| Ended training MultinomialNB in: 0.029415900999993028s\n","05-30-2023 11:38:17 l:138| running 2 of 3 models.\n","05-30-2023 11:38:17 l:151| Training model: XGBoost\n","05-30-2023 11:39:13 l:159| Ended training XGBoost in: 56.47486580800023s\n","\n","Models:  67% 2/3 [00:56<00:28, 28.29s/it]\u001b[A05-30-2023 11:39:13 l:138| running 3 of 3 models.\n","05-30-2023 11:39:13 l:151| Training model: SVM_RBF\n","05-30-2023 11:41:51 l:159| Ended training SVM_RBF in: 157.41500342000018s\n","\n","Models: 100% 3/3 [03:50<00:00, 76.78s/it]\n","Feature extractors:  67% 2/3 [04:55<02:42, 162.66s/it]05-30-2023 11:42:07 l:130| running 3 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00<?, ?it/s]\u001b[A05-30-2023 11:42:08 l:138| running 1 of 3 models.\n","05-30-2023 11:42:08 l:151| Training model: MultinomialNB\n","05-30-2023 11:42:08 l:159| Ended training MultinomialNB in: 0.006944731999737996s\n","05-30-2023 11:42:08 l:138| running 2 of 3 models.\n","05-30-2023 11:42:08 l:151| Training model: XGBoost\n","05-30-2023 11:42:17 l:159| Ended training XGBoost in: 8.90182777200016s\n","\n","Models:  67% 2/3 [00:08<00:04,  4.48s/it]\u001b[A05-30-2023 11:42:17 l:138| running 3 of 3 models.\n","05-30-2023 11:42:17 l:151| Training model: SVM_RBF\n","05-30-2023 11:42:23 l:159| Ended training SVM_RBF in: 6.641166761000022s\n","\n","Models: 100% 3/3 [00:17<00:00,  5.88s/it]\n","Feature extractors: 100% 3/3 [05:13<00:00, 104.45s/it]\n","05-30-2023 11:42:25 l:151| Training model: ensemble_1\n","05-30-2023 11:42:25 l:159| Ended training ensemble_1 in: 2.3911000425869133e-05s\n","05-30-2023 11:42:49 l:151| Training model: ensemble_2\n","05-30-2023 11:42:49 l:159| Ended training ensemble_2 in: 2.6648999664757866e-05s\n","05-30-2023 11:43:10 l:151| Training model: ensemble_3\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","05-30-2023 11:45:12 l:159| Ended training ensemble_3 in: 121.45726952999985s\n","05-30-2023 11:45:24 l:40| header is True\n","05-30-2023 11:45:24 l:48| Appending to the existing .csv file.\n","05-30-2023 11:45:24 l:270| Results saved to results/results_230530_110449.csv\n","05-30-2023 11:45:24 l:188| Params saved to results/params_230530_110449.json\n"]}],"source":["!python run_classical_MLs.py -o $file_name"]},{"cell_type":"markdown","metadata":{"id":"8VzVtm9TGuOC"},"source":["## LLM (BERT) tests"]},{"cell_type":"code","execution_count":15,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"id":"y8_ctG55-uTX","outputId":"6f9f66ff-2027-4607-8949-54d756a403cd","executionInfo":{"status":"ok","timestamp":1685448725260,"user_tz":-60,"elapsed":401,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"]}],"source":["#@title Choose a BERT model to fine-tune\n","\n","bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n","\n","map_name_to_handle = {\n","    'bert_en_uncased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n","    'bert_en_cased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n","    'bert_multi_cased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n","    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n","    'albert_en_base':\n","        'https://tfhub.dev/tensorflow/albert_en_base/2',\n","    'electra_small':\n","        'https://tfhub.dev/google/electra_small/2',\n","    'electra_base':\n","        'https://tfhub.dev/google/electra_base/2',\n","    'experts_pubmed':\n","        'https://tfhub.dev/google/experts/bert/pubmed/2',\n","    'experts_wiki_books':\n","        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n","    'talking-heads_base':\n","        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n","}\n","\n","map_model_to_preprocess = {\n","    'bert_en_uncased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'bert_en_cased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'bert_multi_cased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n","    'albert_en_base':\n","        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n","    'electra_small':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'electra_base':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'experts_pubmed':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'experts_wiki_books':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'talking-heads_base':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","}\n","\n","tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n","tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n","\n","print(f'BERT model selected           : {tfhub_handle_encoder}')\n","print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"f5xwsuzFaKiL","executionInfo":{"status":"ok","timestamp":1685448727458,"user_tz":-60,"elapsed":1,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}}},"outputs":[],"source":["# Manual selection\n","bert_model_name_list = ['bert_en_uncased_L-12_H-768_A-12', \n","                        'bert_en_cased_L-12_H-768_A-12',\n","                        'small_bert/bert_en_uncased_L-2_H-128_A-2',\n","                        'small_bert/bert_en_uncased_L-4_H-512_A-8',\n","                        'small_bert/bert_en_uncased_L-8_H-128_A-2',\n","                        'small_bert/bert_en_uncased_L-12_H-768_A-12',\n","                        'bert_multi_cased_L-12_H-768_A-12',\n","                       'albert_en_base',\n","                        'electra_base',\n","                        'electra_small']"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"aksj743St9ga","executionInfo":{"status":"ok","timestamp":1685448729914,"user_tz":-60,"elapsed":1,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}}},"outputs":[],"source":["def build_classifier_model(local_tfhub_handle_preprocess, local_tfhub_handle_encoder):\n","  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='Payload')\n","  preprocessing_layer = hub.KerasLayer(local_tfhub_handle_preprocess, name='preprocessing')\n","  encoder_inputs = preprocessing_layer(text_input)\n","  encoder = hub.KerasLayer(local_tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n","  outputs = encoder(encoder_inputs)\n","  net = outputs['pooled_output']\n","  net = tf.keras.layers.Dropout(0.1)(net)\n","  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n","  return tf.keras.Model(text_input, net)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xFHT4mtCsKHP","outputId":"992ec727-e657-4eaa-a520-8dc42e95e847","executionInfo":{"status":"ok","timestamp":1685448731814,"user_tz":-60,"elapsed":3,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["24487"]},"metadata":{},"execution_count":18}],"source":["data_manager.x_train.shape[0]"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"9tsOsmvENQSG","executionInfo":{"status":"ok","timestamp":1685448740383,"user_tz":-60,"elapsed":4217,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}}},"outputs":[],"source":["#main_dir = Path('/content/drive/MyDrive/Colab Notebooks/kasim/2023 Feb Bert SQLi/')\n","# 'SQLiV3_train.tsv', 'SQLiV3_test.tsv'\n","# 'NEW_normal_plus_waf_bypass_dataset_testing.tsv'\n","# 'NEW_normal_plus_waf_bypass_dataset_training.tsv'\n","#train_file_name = 'NEW_normal_plus_waf_bypass_dataset_training.tsv'\n","#train_file_name = 'SQLiV3_train.tsv'\n","#test_file_name = 'SQLiV3_test.tsv'\n","#train_file = Path(main_dir / train_file_name)\n","#test_file = Path(main_dir / test_file_name)\n","\n","#print(f'Train file exists: {train_file.is_file()}')\n","#print(f'Test file exists: {test_file.is_file()}')\n","\n","\n","currentDateAndTime = datetime.now()\n","currentTime = currentDateAndTime.strftime(\"%y%m%d_%H%M%S\")\n","#recording = Recorder(main_folder / results_dir / f'results_BERT_{currentTime}.csv')\n","\n","\n","AUTOTUNE = tf.data.AUTOTUNE\n","batch_size = 16\n","#seed = 42\n","\n","x_train = data_manager.x_train\n","y_train = data_manager.y_train\n","x_test = data_manager.x_test\n","y_test = data_manager.y_test\n","\n","# Create TensorFlow datasets for the training and validation sets\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(8)\n","val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(8)\n","\n","# Cache the training and validation datasets\n","train_dataset = train_dataset.cache()\n","val_dataset = val_dataset.cache()\n","\n","\n","# Prefetch the training and validation datasets\n","train_ds = train_dataset.prefetch(buffer_size=AUTOTUNE)\n","test_ds = val_dataset.prefetch(buffer_size=AUTOTUNE)\n","\n","\n","\n","#train_ds = test_csv_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","#val_ds = test_csv_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","# test_ds = val_ds\n","\n","class_names = ['payload','label']\n","\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KT17nxwbHb9u","outputId":"da58f633-113e-46ce-e7eb-77d12afffa76","executionInfo":{"status":"ok","timestamp":1685448740384,"user_tz":-60,"elapsed":6,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[b'9869'\n"," b\"1'||  (  select 'mdqc' where 4533  =  4533 and 8189  =    (  select count  (  *  )   from sysibm.systables as t1,sysibm.systables as t2,sysibm.systables as t3  )  --\"\n"," b\"1'   )    )     )   and sleep  (  5  )  #\"\n"," b'1 where 8578  =  8578 and 4770  =  4474--'\n"," b'SELECT COUNT ( officer ) FROM suddenly'\n"," b\"-5597'  )   or make_set  (  2490  =  2164,2164  )  \"\n"," b'SELECT TOP 50 PERCENT * FROM vote SELECT * FROM simplest FETCH FIRST 50 PERCENT ROWS ONLYSELECT TOP 3 * FROM test'\n"," b'calle alfred nobel, 42 7-g'], shape=(8,), dtype=string)\n","tf.Tensor([0 1 1 1 0 1 0 0], shape=(8,), dtype=int64)\n"]}],"source":["tmp = train_ds.take(1)\n","for i in next(iter(tmp)):\n","  print(i)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"6QVYvfmcwWgQ","outputId":"a9d443bb-f5e1-4171-fd2e-4174b5a42161"},"outputs":[{"name":"stdout","output_type":"stream","text":["****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n","Epoch 1/10\n","3061/3061 [==============================] - 188s 55ms/step - loss: 0.1366 - binary_accuracy: 0.9448 - val_loss: 0.0115 - val_binary_accuracy: 0.9977\n","Epoch 2/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0129 - binary_accuracy: 0.9974 - val_loss: 0.0094 - val_binary_accuracy: 0.9984\n","Epoch 3/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0087 - binary_accuracy: 0.9986 - val_loss: 0.0118 - val_binary_accuracy: 0.9985\n","Epoch 4/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0070 - binary_accuracy: 0.9987 - val_loss: 0.0178 - val_binary_accuracy: 0.9975\n","Epoch 5/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0086 - binary_accuracy: 0.9987 - val_loss: 0.0248 - val_binary_accuracy: 0.9967\n","Epoch 6/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0072 - binary_accuracy: 0.9989 - val_loss: 0.0199 - val_binary_accuracy: 0.9975\n","Epoch 7/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0054 - binary_accuracy: 0.9989 - val_loss: 0.0140 - val_binary_accuracy: 0.9987\n","Epoch 8/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0086 - binary_accuracy: 0.9987 - val_loss: 0.0173 - val_binary_accuracy: 0.9977\n","Epoch 9/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0058 - binary_accuracy: 0.9992 - val_loss: 0.0234 - val_binary_accuracy: 0.9972\n","Epoch 10/10\n","3061/3061 [==============================] - 167s 54ms/step - loss: 0.0037 - binary_accuracy: 0.9995 - val_loss: 0.0128 - val_binary_accuracy: 0.9984\n","766/766 [==============================] - 13s 16ms/step - loss: 0.0128 - binary_accuracy: 0.9984\n","Loss: 0.012790115550160408\n","Accuracy: 0.9983665347099304\n","766/766 [==============================] - 12s 15ms/step\n","{'accuracy': 0.9978765109441359, 'precision': 0.9969176574196389, 'recall': 0.9973568281938326, 'f1_score': 0.9971371944505616, 'tp': 2264, 'tn': 3845, 'fp': 7, 'fn': 6, 'feature_method': 'bert_en_uncased_L-12_H-768_A-12', 'model': 'bert_en_uncased_L-12_H-768_A-12', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 68.76933526480656, 'pred_time': 2.059807928509667, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\n","Epoch 1/10\n","3061/3061 [==============================] - 183s 55ms/step - loss: 0.1257 - binary_accuracy: 0.9441 - val_loss: 0.0150 - val_binary_accuracy: 0.9972\n","Epoch 2/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0117 - binary_accuracy: 0.9976 - val_loss: 0.0110 - val_binary_accuracy: 0.9985\n","Epoch 3/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0055 - binary_accuracy: 0.9990 - val_loss: 0.0206 - val_binary_accuracy: 0.9980\n","Epoch 4/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0066 - binary_accuracy: 0.9989 - val_loss: 0.0114 - val_binary_accuracy: 0.9987\n","Epoch 5/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0056 - binary_accuracy: 0.9992 - val_loss: 0.0136 - val_binary_accuracy: 0.9989\n","Epoch 6/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0055 - binary_accuracy: 0.9993 - val_loss: 0.0115 - val_binary_accuracy: 0.9989\n","Epoch 7/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0067 - binary_accuracy: 0.9990 - val_loss: 0.0111 - val_binary_accuracy: 0.9989\n","Epoch 8/10\n","3061/3061 [==============================] - 164s 53ms/step - loss: 0.0064 - binary_accuracy: 0.9991 - val_loss: 0.0168 - val_binary_accuracy: 0.9987\n","Epoch 9/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0062 - binary_accuracy: 0.9990 - val_loss: 0.0155 - val_binary_accuracy: 0.9982\n","Epoch 10/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0176 - binary_accuracy: 0.9973 - val_loss: 0.0176 - val_binary_accuracy: 0.9967\n","766/766 [==============================] - 12s 16ms/step - loss: 0.0176 - binary_accuracy: 0.9967\n","Loss: 0.017641454935073853\n","Accuracy: 0.9967330694198608\n","766/766 [==============================] - 12s 15ms/step\n","{'accuracy': 0.9962430578242405, 'precision': 0.9916849015317286, 'recall': 0.9982378854625551, 'f1_score': 0.9949506037321625, 'tp': 2266, 'tn': 3833, 'fp': 19, 'fn': 4, 'feature_method': 'bert_en_cased_L-12_H-768_A-12', 'model': 'bert_en_cased_L-12_H-768_A-12', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 67.79726553397506, 'pred_time': 2.048929000126696, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1\n","Epoch 1/10\n","3061/3061 [==============================] - 59s 18ms/step - loss: 0.4831 - binary_accuracy: 0.7580 - val_loss: 0.1048 - val_binary_accuracy: 0.9673\n","Epoch 2/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0789 - binary_accuracy: 0.9765 - val_loss: 0.0407 - val_binary_accuracy: 0.9899\n","Epoch 3/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0417 - binary_accuracy: 0.9896 - val_loss: 0.0166 - val_binary_accuracy: 0.9954\n","Epoch 4/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0250 - binary_accuracy: 0.9941 - val_loss: 0.0096 - val_binary_accuracy: 0.9980\n","Epoch 5/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0174 - binary_accuracy: 0.9964 - val_loss: 0.0071 - val_binary_accuracy: 0.9989\n","Epoch 6/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0109 - binary_accuracy: 0.9976 - val_loss: 0.0076 - val_binary_accuracy: 0.9989\n","Epoch 7/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0099 - binary_accuracy: 0.9980 - val_loss: 0.0077 - val_binary_accuracy: 0.9990\n","Epoch 8/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0085 - binary_accuracy: 0.9982 - val_loss: 0.0079 - val_binary_accuracy: 0.9990\n","Epoch 9/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0064 - binary_accuracy: 0.9987 - val_loss: 0.0073 - val_binary_accuracy: 0.9992\n","Epoch 10/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0051 - binary_accuracy: 0.9989 - val_loss: 0.0092 - val_binary_accuracy: 0.9987\n","766/766 [==============================] - 7s 10ms/step - loss: 0.0092 - binary_accuracy: 0.9987\n","Loss: 0.009229135699570179\n","Accuracy: 0.9986932277679443\n","766/766 [==============================] - 7s 9ms/step\n","{'accuracy': 0.9988565828160731, 'precision': 1.0, 'recall': 0.9969162995594714, 'f1_score': 0.9984557688065299, 'tp': 2263, 'tn': 3852, 'fp': 0, 'fn': 7, 'feature_method': 'small_bert/bert_en_uncased_L-2_H-128_A-2', 'model': 'small_bert/bert_en_uncased_L-2_H-128_A-2', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 22.687838174618438, 'pred_time': 1.2491817997780084, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n","Epoch 1/10\n","3061/3061 [==============================] - 82s 25ms/step - loss: 0.1516 - binary_accuracy: 0.9338 - val_loss: 0.0127 - val_binary_accuracy: 0.9971\n","Epoch 2/10\n","3061/3061 [==============================] - 74s 24ms/step - loss: 0.0171 - binary_accuracy: 0.9962 - val_loss: 0.0063 - val_binary_accuracy: 0.9990\n","Epoch 3/10\n","3061/3061 [==============================] - 75s 24ms/step - loss: 0.0090 - binary_accuracy: 0.9980 - val_loss: 0.0072 - val_binary_accuracy: 0.9985\n","Epoch 4/10\n","3061/3061 [==============================] - 74s 24ms/step - loss: 0.0079 - binary_accuracy: 0.9982 - val_loss: 0.0085 - val_binary_accuracy: 0.9985\n","Epoch 5/10\n","3061/3061 [==============================] - 74s 24ms/step - loss: 0.0066 - binary_accuracy: 0.9986 - val_loss: 0.0099 - val_binary_accuracy: 0.9979\n","Epoch 6/10\n","3061/3061 [==============================] - 74s 24ms/step - loss: 0.0048 - binary_accuracy: 0.9990 - val_loss: 0.0177 - val_binary_accuracy: 0.9984\n","Epoch 7/10\n","3061/3061 [==============================] - 75s 24ms/step - loss: 0.0057 - binary_accuracy: 0.9991 - val_loss: 0.0126 - val_binary_accuracy: 0.9982\n","Epoch 8/10\n","3061/3061 [==============================] - 74s 24ms/step - loss: 0.0054 - binary_accuracy: 0.9991 - val_loss: 0.0205 - val_binary_accuracy: 0.9980\n","Epoch 9/10\n","3061/3061 [==============================] - 74s 24ms/step - loss: 0.0047 - binary_accuracy: 0.9992 - val_loss: 0.0199 - val_binary_accuracy: 0.9980\n","Epoch 10/10\n","3061/3061 [==============================] - 74s 24ms/step - loss: 0.0035 - binary_accuracy: 0.9993 - val_loss: 0.0161 - val_binary_accuracy: 0.9980\n","766/766 [==============================] - 9s 11ms/step - loss: 0.0161 - binary_accuracy: 0.9980\n","Loss: 0.016093064099550247\n","Accuracy: 0.9980398416519165\n","766/766 [==============================] - 8s 10ms/step\n","{'accuracy': 0.9980398562561255, 'precision': 0.9982347749338041, 'recall': 0.9964757709251101, 'f1_score': 0.9973544973544974, 'tp': 2262, 'tn': 3848, 'fp': 4, 'fn': 8, 'feature_method': 'small_bert/bert_en_uncased_L-4_H-512_A-8', 'model': 'small_bert/bert_en_uncased_L-4_H-512_A-8', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 30.622556755102373, 'pred_time': 1.391619064184, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1\n","Epoch 1/10\n","3061/3061 [==============================] - 115s 34ms/step - loss: 0.2731 - binary_accuracy: 0.8757 - val_loss: 0.0457 - val_binary_accuracy: 0.9897\n","Epoch 2/10\n","3061/3061 [==============================] - 104s 34ms/step - loss: 0.0412 - binary_accuracy: 0.9907 - val_loss: 0.0137 - val_binary_accuracy: 0.9967\n","Epoch 3/10\n","3061/3061 [==============================] - 103s 34ms/step - loss: 0.0218 - binary_accuracy: 0.9956 - val_loss: 0.0084 - val_binary_accuracy: 0.9982\n","Epoch 4/10\n","3061/3061 [==============================] - 103s 34ms/step - loss: 0.0177 - binary_accuracy: 0.9964 - val_loss: 0.0107 - val_binary_accuracy: 0.9979\n","Epoch 5/10\n","3061/3061 [==============================] - 103s 34ms/step - loss: 0.0124 - binary_accuracy: 0.9975 - val_loss: 0.0127 - val_binary_accuracy: 0.9980\n","Epoch 6/10\n","3061/3061 [==============================] - 104s 34ms/step - loss: 0.0091 - binary_accuracy: 0.9981 - val_loss: 0.0093 - val_binary_accuracy: 0.9987\n","Epoch 7/10\n","3061/3061 [==============================] - 104s 34ms/step - loss: 0.0082 - binary_accuracy: 0.9985 - val_loss: 0.0150 - val_binary_accuracy: 0.9985\n","Epoch 8/10\n","3061/3061 [==============================] - 104s 34ms/step - loss: 0.0102 - binary_accuracy: 0.9982 - val_loss: 0.0090 - val_binary_accuracy: 0.9989\n","Epoch 9/10\n","3061/3061 [==============================] - 104s 34ms/step - loss: 0.0067 - binary_accuracy: 0.9989 - val_loss: 0.0078 - val_binary_accuracy: 0.9990\n","Epoch 10/10\n","3061/3061 [==============================] - 104s 34ms/step - loss: 0.0057 - binary_accuracy: 0.9989 - val_loss: 0.0091 - val_binary_accuracy: 0.9987\n","766/766 [==============================] - 9s 12ms/step - loss: 0.0091 - binary_accuracy: 0.9987\n","Loss: 0.009088876657187939\n","Accuracy: 0.9986932277679443\n","766/766 [==============================] - 10s 12ms/step\n","{'accuracy': 0.9986932375040837, 'precision': 0.9982378854625551, 'recall': 0.9982378854625551, 'f1_score': 0.9982378854625551, 'tp': 2266, 'tn': 3848, 'fp': 4, 'fn': 4, 'feature_method': 'small_bert/bert_en_uncased_L-8_H-128_A-2', 'model': 'small_bert/bert_en_uncased_L-8_H-128_A-2', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 42.80906163273784, 'pred_time': 1.6138235831798116, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1\n","Epoch 1/10\n","3061/3061 [==============================] - 181s 54ms/step - loss: 0.1312 - binary_accuracy: 0.9410 - val_loss: 0.0105 - val_binary_accuracy: 0.9977\n","Epoch 2/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0146 - binary_accuracy: 0.9973 - val_loss: 0.0122 - val_binary_accuracy: 0.9977\n","Epoch 3/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0101 - binary_accuracy: 0.9979 - val_loss: 0.0222 - val_binary_accuracy: 0.9972\n","Epoch 4/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0065 - binary_accuracy: 0.9991 - val_loss: 0.0172 - val_binary_accuracy: 0.9982\n","Epoch 5/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0091 - binary_accuracy: 0.9985 - val_loss: 0.0149 - val_binary_accuracy: 0.9985\n","Epoch 6/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0094 - binary_accuracy: 0.9985 - val_loss: 0.0091 - val_binary_accuracy: 0.9989\n","Epoch 7/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0080 - binary_accuracy: 0.9988 - val_loss: 0.0176 - val_binary_accuracy: 0.9980\n","Epoch 8/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0090 - binary_accuracy: 0.9988 - val_loss: 0.0439 - val_binary_accuracy: 0.9948\n","Epoch 9/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0067 - binary_accuracy: 0.9990 - val_loss: 0.0167 - val_binary_accuracy: 0.9985\n","Epoch 10/10\n","3061/3061 [==============================] - 164s 53ms/step - loss: 0.0068 - binary_accuracy: 0.9987 - val_loss: 0.0222 - val_binary_accuracy: 0.9974\n","766/766 [==============================] - 13s 16ms/step - loss: 0.0222 - binary_accuracy: 0.9974\n","Loss: 0.022158121690154076\n","Accuracy: 0.9973864555358887\n","766/766 [==============================] - 12s 15ms/step\n","{'accuracy': 0.9973864750081672, 'precision': 0.9947322212467077, 'recall': 0.9982378854625551, 'f1_score': 0.9964819700967459, 'tp': 2266, 'tn': 3840, 'fp': 12, 'fn': 4, 'feature_method': 'small_bert/bert_en_uncased_L-12_H-768_A-12', 'model': 'small_bert/bert_en_uncased_L-12_H-768_A-12', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 67.48214822277586, 'pred_time': 2.043110800116563, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3\n","Epoch 1/10\n","3061/3061 [==============================] - 206s 62ms/step - loss: 0.1035 - binary_accuracy: 0.9494 - val_loss: 0.0116 - val_binary_accuracy: 0.9984\n","Epoch 2/10\n","3061/3061 [==============================] - 189s 62ms/step - loss: 0.0132 - binary_accuracy: 0.9980 - val_loss: 0.0121 - val_binary_accuracy: 0.9989\n","Epoch 3/10\n","3061/3061 [==============================] - 190s 62ms/step - loss: 0.0095 - binary_accuracy: 0.9984 - val_loss: 0.0087 - val_binary_accuracy: 0.9992\n","Epoch 4/10\n","3061/3061 [==============================] - 190s 62ms/step - loss: 0.0094 - binary_accuracy: 0.9985 - val_loss: 0.0205 - val_binary_accuracy: 0.9975\n","Epoch 5/10\n","3061/3061 [==============================] - 189s 62ms/step - loss: 0.0104 - binary_accuracy: 0.9987 - val_loss: 0.0127 - val_binary_accuracy: 0.9985\n","Epoch 6/10\n","3061/3061 [==============================] - 190s 62ms/step - loss: 0.0083 - binary_accuracy: 0.9989 - val_loss: 0.0189 - val_binary_accuracy: 0.9982\n","Epoch 7/10\n","3061/3061 [==============================] - 192s 63ms/step - loss: 0.0121 - binary_accuracy: 0.9984 - val_loss: 0.0193 - val_binary_accuracy: 0.9982\n","Epoch 8/10\n","3061/3061 [==============================] - 191s 62ms/step - loss: 0.0194 - binary_accuracy: 0.9941 - val_loss: 0.0135 - val_binary_accuracy: 0.9985\n","Epoch 9/10\n","3061/3061 [==============================] - 191s 62ms/step - loss: 0.0510 - binary_accuracy: 0.9893 - val_loss: 0.0160 - val_binary_accuracy: 0.9980\n","Epoch 10/10\n","3061/3061 [==============================] - 190s 62ms/step - loss: 0.0186 - binary_accuracy: 0.9974 - val_loss: 0.0178 - val_binary_accuracy: 0.9979\n","766/766 [==============================] - 13s 16ms/step - loss: 0.0178 - binary_accuracy: 0.9979\n","Loss: 0.0177945327013731\n","Accuracy: 0.9978765249252319\n","766/766 [==============================] - 12s 15ms/step\n","{'accuracy': 0.9978765109441359, 'precision': 0.9977944419938244, 'recall': 0.9964757709251101, 'f1_score': 0.997134670487106, 'tp': 2262, 'tn': 3847, 'fp': 5, 'fn': 8, 'feature_method': 'bert_multi_cased_L-12_H-768_A-12', 'model': 'bert_multi_cased_L-12_H-768_A-12', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 78.33840470503499, 'pred_time': 2.0438962728904766, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/albert_en_base/2\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/albert_en_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/albert_en_base/2\n","Epoch 1/10\n","3061/3061 [==============================] - 170s 52ms/step - loss: 0.1043 - binary_accuracy: 0.9558 - val_loss: 0.0842 - val_binary_accuracy: 0.9881\n","Epoch 2/10\n","3061/3061 [==============================] - 157s 51ms/step - loss: 0.0467 - binary_accuracy: 0.9919 - val_loss: 0.0247 - val_binary_accuracy: 0.9966\n","Epoch 3/10\n","3061/3061 [==============================] - 156s 51ms/step - loss: 0.0303 - binary_accuracy: 0.9957 - val_loss: 0.0145 - val_binary_accuracy: 0.9979\n","Epoch 4/10\n","3061/3061 [==============================] - 157s 51ms/step - loss: 0.0301 - binary_accuracy: 0.9952 - val_loss: 0.0144 - val_binary_accuracy: 0.9979\n","Epoch 5/10\n","3061/3061 [==============================] - 159s 52ms/step - loss: 0.0329 - binary_accuracy: 0.9939 - val_loss: 0.0186 - val_binary_accuracy: 0.9972\n","Epoch 6/10\n","3061/3061 [==============================] - 160s 52ms/step - loss: 0.0270 - binary_accuracy: 0.9957 - val_loss: 0.0239 - val_binary_accuracy: 0.9966\n","Epoch 7/10\n","3061/3061 [==============================] - 160s 52ms/step - loss: 0.0690 - binary_accuracy: 0.9876 - val_loss: 0.0556 - val_binary_accuracy: 0.9899\n","Epoch 8/10\n","3061/3061 [==============================] - 159s 52ms/step - loss: 0.1915 - binary_accuracy: 0.9279 - val_loss: 0.0498 - val_binary_accuracy: 0.9923\n","Epoch 9/10\n","3061/3061 [==============================] - 158s 52ms/step - loss: 0.0380 - binary_accuracy: 0.9924 - val_loss: 0.0389 - val_binary_accuracy: 0.9944\n","Epoch 10/10\n","3061/3061 [==============================] - 159s 52ms/step - loss: 0.0231 - binary_accuracy: 0.9965 - val_loss: 0.0195 - val_binary_accuracy: 0.9975\n","766/766 [==============================] - 12s 16ms/step - loss: 0.0195 - binary_accuracy: 0.9975\n","Loss: 0.019486598670482635\n","Accuracy: 0.997549831867218\n","766/766 [==============================] - 12s 15ms/step\n","{'accuracy': 0.9975498203201568, 'precision': 0.9973533303925893, 'recall': 0.9960352422907489, 'f1_score': 0.9966938505620454, 'tp': 2261, 'tn': 3846, 'fp': 6, 'fn': 9, 'feature_method': 'albert_en_base', 'model': 'albert_en_base', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 65.16176399129385, 'pred_time': 1.9710840878242062, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/google/electra_base/2\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/google/electra_base/2\n","Epoch 1/10\n","3061/3061 [==============================] - 182s 54ms/step - loss: 0.1368 - binary_accuracy: 0.9385 - val_loss: 0.0189 - val_binary_accuracy: 0.9962\n","Epoch 2/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0195 - binary_accuracy: 0.9962 - val_loss: 0.0127 - val_binary_accuracy: 0.9979\n","Epoch 3/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0132 - binary_accuracy: 0.9975 - val_loss: 0.0166 - val_binary_accuracy: 0.9971\n","Epoch 4/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0130 - binary_accuracy: 0.9979 - val_loss: 0.0233 - val_binary_accuracy: 0.9971\n","Epoch 5/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0099 - binary_accuracy: 0.9980 - val_loss: 0.0081 - val_binary_accuracy: 0.9987\n","Epoch 6/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0103 - binary_accuracy: 0.9982 - val_loss: 0.0207 - val_binary_accuracy: 0.9975\n","Epoch 7/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0119 - binary_accuracy: 0.9984 - val_loss: 0.0260 - val_binary_accuracy: 0.9974\n","Epoch 8/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0088 - binary_accuracy: 0.9987 - val_loss: 0.0162 - val_binary_accuracy: 0.9972\n","Epoch 9/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0093 - binary_accuracy: 0.9984 - val_loss: 0.0178 - val_binary_accuracy: 0.9984\n","Epoch 10/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0121 - binary_accuracy: 0.9980 - val_loss: 0.0130 - val_binary_accuracy: 0.9982\n","766/766 [==============================] - 12s 16ms/step - loss: 0.0130 - binary_accuracy: 0.9982\n","Loss: 0.012969440780580044\n","Accuracy: 0.9982032179832458\n","766/766 [==============================] - 12s 15ms/step\n","{'accuracy': 0.998203201568115, 'precision': 0.9969203695556533, 'recall': 0.9982378854625551, 'f1_score': 0.9975786924939468, 'tp': 2266, 'tn': 3845, 'fp': 7, 'fn': 4, 'feature_method': 'electra_base', 'model': 'electra_base', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 68.10031622841753, 'pred_time': 2.047714007831562, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/google/electra_small/2\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/google/electra_small/2\n","Epoch 1/10\n","3061/3061 [==============================] - 156s 45ms/step - loss: 0.1823 - binary_accuracy: 0.9288 - val_loss: 0.0177 - val_binary_accuracy: 0.9967\n","Epoch 2/10\n","3061/3061 [==============================] - 138s 45ms/step - loss: 0.0225 - binary_accuracy: 0.9958 - val_loss: 0.0087 - val_binary_accuracy: 0.9985\n","Epoch 3/10\n","3061/3061 [==============================] - 138s 45ms/step - loss: 0.0143 - binary_accuracy: 0.9972 - val_loss: 0.0084 - val_binary_accuracy: 0.9987\n","Epoch 4/10\n","3061/3061 [==============================] - 139s 45ms/step - loss: 0.0110 - binary_accuracy: 0.9980 - val_loss: 0.0158 - val_binary_accuracy: 0.9980\n","Epoch 5/10\n","3061/3061 [==============================] - 138s 45ms/step - loss: 0.0098 - binary_accuracy: 0.9983 - val_loss: 0.0159 - val_binary_accuracy: 0.9980\n","Epoch 6/10\n","3061/3061 [==============================] - 138s 45ms/step - loss: 0.0078 - binary_accuracy: 0.9986 - val_loss: 0.0137 - val_binary_accuracy: 0.9987\n","Epoch 7/10\n","3061/3061 [==============================] - 139s 45ms/step - loss: 0.0076 - binary_accuracy: 0.9986 - val_loss: 0.0169 - val_binary_accuracy: 0.9984\n","Epoch 8/10\n","3061/3061 [==============================] - 138s 45ms/step - loss: 0.0081 - binary_accuracy: 0.9987 - val_loss: 0.0063 - val_binary_accuracy: 0.9990\n","Epoch 9/10\n","3061/3061 [==============================] - 139s 45ms/step - loss: 0.0051 - binary_accuracy: 0.9990 - val_loss: 0.0134 - val_binary_accuracy: 0.9980\n","Epoch 10/10\n","3061/3061 [==============================] - 139s 46ms/step - loss: 0.0067 - binary_accuracy: 0.9987 - val_loss: 0.0174 - val_binary_accuracy: 0.9980\n","766/766 [==============================] - 11s 14ms/step - loss: 0.0174 - binary_accuracy: 0.9980\n","Loss: 0.017357932403683662\n","Accuracy: 0.9980398416519165\n","766/766 [==============================] - 11s 14ms/step\n","{'accuracy': 0.9980398562561255, 'precision': 0.9991158267020336, 'recall': 0.9955947136563876, 'f1_score': 0.9973521624007061, 'tp': 2260, 'tn': 3850, 'fp': 2, 'fn': 10, 'feature_method': 'electra_small', 'model': 'electra_small', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 57.25308988757096, 'pred_time': 1.9256281953978016, 'dataset': 'SQLiV3.tsv'}\n"]}],"source":["for bert_model_name in bert_model_name_list:\n","  #bert_model_name = bert_model_name_list[0]\n","  print('****************************************************')\n","  #recording.set_current_method(f\"{bert_model_name}\" )\n","  tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n","  tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n","\n","  print(f'BERT model selected           : {tfhub_handle_encoder}')\n","  print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')\n","\n","\n","  bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n","  bert_model = hub.KerasLayer(tfhub_handle_encoder)\n","  classifier_model = build_classifier_model(tfhub_handle_preprocess, tfhub_handle_encoder)\n","\n","  loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","  metrics = tf.metrics.BinaryAccuracy()\n","\n","  epochs = 10 #modify this\n","  #steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n","  steps_per_epoch = data_manager.x_train.shape[0]\n","  num_train_steps = (steps_per_epoch * epochs) #//200 \n","  num_warmup_steps = int(0.1*num_train_steps)\n","\n","  init_lr = 3e-5\n","  optimizer = optimization.create_optimizer(init_lr=init_lr,\n","                                            num_train_steps=num_train_steps,\n","                                            num_warmup_steps=num_warmup_steps,\n","                                            optimizer_type='adamw')\n","\n","  classifier_model.compile(optimizer=optimizer,\n","                          loss=loss,\n","                          metrics=metrics)\n","\n","\n","  print(f'Training model with {tfhub_handle_encoder}')\n","  start_time = time.time()\n","  history = classifier_model.fit(x=train_ds, #train_ds.take(2)\n","                                validation_data=test_ds, # validation_data=test_ds.take(2),\n","                                epochs=epochs)\n","  stop_time = time.time()\n","  training_time = (stop_time - start_time)*1000 / data_manager.notes['train_size']\n","\n","  loss, accuracy = classifier_model.evaluate(test_ds)\n","\n","  print(f'Loss: {loss}')\n","  print(f'Accuracy: {accuracy}')\n","\n","  start_time = time.time()\n","  y_pred = classifier_model.predict(test_ds)\n","  stop_time = time.time()\n","  testing_time = (stop_time - start_time)*1000 / data_manager.notes['test_size']\n","  y_pred_np = tf.cast(tf.sigmoid(y_pred) > 0.5, tf.int32).numpy()\n","  X, y_true = zip(*test_ds.unbatch())\n","  y_true_np = [y.numpy() for y in y_true]\n","  #precision, recall, f1, support = precision_recall_fscore_support(y_true_np, y_pred_np, average='binary')\n","  #tn, fp, fn, tp = confusion_matrix(y_true_np, y_pred_np).ravel()\n","\n","  notes = {'feature_method': bert_model_name,'model': bert_model_name, \n","           'seed': data_manager.notes['seed'], \n","           'split_ratio': data_manager.notes['split_ratio'],\n","           'train_size': data_manager.notes['train_size'],\n","           'test_size': data_manager.notes['test_size'],\n","           'extraction_time':0, 'feature_size':0,\n","           'train_time': training_time,\n","           'pred_time': testing_time, 'dataset': config['dataset']['file']}\n","  result = evaluate(y_true_np, y_pred_np, notes)\n","  print(result)\n","  save_results([result], output_file)\n"]},{"cell_type":"markdown","metadata":{"id":"K0ObPxN_G4oS"},"source":["## The Proposed Cascade NLP (two-stage) SQLi Detection Tests"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"49AP1MiEnHz8","executionInfo":{"status":"ok","timestamp":1685448749179,"user_tz":-60,"elapsed":821,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}}},"outputs":[],"source":["# Data manager _ split with seed\n","from sklearn.model_selection import train_test_split\n","\n","def split_dataset(seed=42):\n","  split_ratio = float(data_manager.config['data_manager']['split_ratio'])\n","\n","  data_manager.train, data_manager.test = train_test_split(\n","    data_manager.dataset, test_size=split_ratio, random_state=seed)\n","\n","  data_manager.x_train = data_manager.train['payload'].values\n","  data_manager.x_test = data_manager.test['payload'].values\n","  data_manager.y_train = data_manager.train['label'].values\n","  data_manager.y_test = data_manager.test['label'].values\n","\n","  data_manager.notes = {\n","    'seed': seed,\n","    'split_ratio': split_ratio,\n","    'train_size': len(data_manager.train),\n","    'test_size': len(data_manager.test),\n","  }\n","\n","#split_dataset(seed=666)\n","#print(data_manager.notes['seed'])"]},{"cell_type":"markdown","metadata":{"id":"_nC5YnC-ULNx"},"source":["### First Stage - Classical ML"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"kLOa8sfNqfvw","executionInfo":{"status":"ok","timestamp":1685448752352,"user_tz":-60,"elapsed":385,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}}},"outputs":[],"source":["from templates import FeatureExtractor\n","from classical_models import Classical_Model\n","from pprint import pprint\n","from experiments import evaluate\n","\n","xgboost_threshold = 0.05 #prediction\n","scale_pos_weight = 5000.0 #xgboost model parameter\n","\n","pass_aggressive_threshold = -0.3 #prediction\n","class_weights = {1: 0.999, 0: 0.001} #PassiveAggressiveClassifier model parameter\n","\n","feature_method = 'tf-idf_ngram'\n","#model_name = 'XGBoost'\n","#model_name = 'PassiveAggressiveClassifier'"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"pvsG1tcjBROW","executionInfo":{"status":"ok","timestamp":1685451941110,"user_tz":-60,"elapsed":832,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}}},"outputs":[],"source":["\n","# Train and evaluate the first stage\n","def first_stage_passive_aggressive():\n","  model_name = 'PassiveAggressiveClassifier'\n","  feature_extractor = FeatureExtractor(feature_method)\n","  start_time = time.time()\n","  feature_extractor.extract_features(\n","      data_manager.x_train, data_manager.x_test)\n","  stop_time = time.time()\n","  extraction_time = ((stop_time - start_time)*1000 \n","                    / (len(data_manager.x_train) + len(data_manager.x_test)) )\n","\n","  model = Classical_Model(model_name, class_weight=class_weights) #MODIFY IT if you change the model\n","  model.feature_method = feature_extractor.method\n","  start_time = time.time()\n","  model.fit(\n","      feature_extractor.features['train'], \n","      data_manager.y_train) #scale_pos_weight=5.0\n","  stop_time = time.time()\n","  training_time = (stop_time - start_time)*1000 / feature_extractor.features['train'].shape[0]\n","\n","\n","  start_time = time.time()\n","  first_stage_y_pred = model.predict(feature_extractor.features['test'],  pass_aggressive_threshold=pass_aggressive_threshold)\n","  stop_time = time.time()\n","\n","  testing_time = (stop_time - start_time)*1000 / feature_extractor.features['test'].shape[0]\n","\n","  notes = {'feature_method': feature_extractor.method,'model': model_name, \n","            'seed': data_manager.notes['seed'], \n","            'split_ratio': data_manager.notes['split_ratio'],\n","            'train_size': data_manager.notes['train_size'],\n","            'test_size': data_manager.notes['test_size'],\n","            'extraction_time':extraction_time, 'feature_size': feature_extractor.features['train'].shape[1],\n","            'train_time': training_time,\n","            'pred_time': testing_time, 'dataset': config['dataset']['file'],\n","          'class_weights':class_weights,\n","          'pass_aggressive_threshold': pass_aggressive_threshold\n","          }\n","  # Save results to csv file\n","\n","  result = evaluate(data_manager.y_test, first_stage_y_pred, notes=notes)\n","  pprint(result)\n","  save_results([result], proposed_test_results_file)\n","\n","  # Extract the positive predicitions for the second stage\n","  first_stage_positive_preds = data_manager.x_test[(first_stage_y_pred == 1)]\n","  first_stage_positive_preds_true_labels = data_manager.y_test[(first_stage_y_pred == 1)]\n","  fs_pos_len = len(first_stage_positive_preds)\n","  nof_test_samples = len(data_manager.x_test)\n","  fs_rat = fs_pos_len/nof_test_samples\n","  print(f\"Positive predicitions in the first stage: {fs_pos_len} out of {nof_test_samples}. Ratio:{fs_rat}\")\n","\n","  return first_stage_positive_preds, first_stage_positive_preds_true_labels"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"SeqeDDr8HCVt","executionInfo":{"status":"ok","timestamp":1685451944447,"user_tz":-60,"elapsed":394,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}}},"outputs":[],"source":["# Train and evaluate the first stage\n","def first_stage_xgboost():\n","  model_name = 'XGBoost'\n","  feature_extractor = FeatureExtractor(feature_method)\n","  start_time = time.time()\n","  feature_extractor.extract_features(\n","      data_manager.x_train, data_manager.x_test)\n","  stop_time = time.time()\n","  extraction_time = ((stop_time - start_time)*1000 \n","                    / (len(data_manager.x_train) + len(data_manager.x_test)) )\n","\n","  model = Classical_Model(model_name, scale_pos_weight=scale_pos_weight)\n","  model.feature_method = feature_extractor.method\n","  start_time = time.time()\n","  model.fit(\n","      feature_extractor.features['train'], \n","      data_manager.y_train) #scale_pos_weight=5.0\n","  stop_time = time.time()\n","  training_time = (stop_time - start_time)*1000 / feature_extractor.features['train'].shape[0]\n","\n","\n","  start_time = time.time()\n","  first_stage_y_pred = model.predict(feature_extractor.features['test'], xgboost_threshold=xgboost_threshold)\n","  stop_time = time.time()\n","\n","  testing_time = (stop_time - start_time)*1000 / feature_extractor.features['test'].shape[0]\n","\n","  notes = {'feature_method': feature_extractor.method,'model': model_name, \n","            'seed': data_manager.notes['seed'], \n","            'split_ratio': data_manager.notes['split_ratio'],\n","            'train_size': data_manager.notes['train_size'],\n","            'test_size': data_manager.notes['test_size'],\n","            'extraction_time':extraction_time, 'feature_size': feature_extractor.features['train'].shape[1],\n","            'train_time': training_time,\n","            'pred_time': testing_time, 'dataset': config['dataset']['file'],\n","          'scale_pos_weight':scale_pos_weight,\n","          'xgboost_threshold': xgboost_threshold\n","          }\n","  # Save results to csv file\n","\n","  result = evaluate(data_manager.y_test, first_stage_y_pred, notes=notes)\n","  pprint(result)\n","  save_results([result], proposed_test_results_file)\n","\n","  # Extract the positive predicitions for the second stage\n","  first_stage_positive_preds = data_manager.x_test[(first_stage_y_pred == 1)]\n","  first_stage_positive_preds_true_labels = data_manager.y_test[(first_stage_y_pred == 1)]\n","  fs_pos_len = len(first_stage_positive_preds)\n","  nof_test_samples = len(data_manager.x_test)\n","  fs_rat = fs_pos_len/nof_test_samples\n","  print(f\"Positive predicitions in the first stage: {fs_pos_len} out of {nof_test_samples}. Ratio:{fs_rat}\")\n","\n","  return first_stage_positive_preds, first_stage_positive_preds_true_labels"]},{"cell_type":"markdown","metadata":{"id":"Xg20dUuRWJ-4"},"source":["### Second Stage - BERT"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"WrftzeG9XwOx","executionInfo":{"status":"ok","timestamp":1685452148454,"user_tz":-60,"elapsed":616,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}}},"outputs":[],"source":["def second_stage(first_stage_positive_preds, first_stage_positive_preds_true_labels):\n","  # Prepare the training Dataset \n","  currentDateAndTime = datetime.now()\n","  currentTime = currentDateAndTime.strftime(\"%y%m%d_%H%M%S\")\n","  #recording = Recorder(main_folder / results_dir / f'results_BERT_{currentTime}.csv')\n","\n","\n","  AUTOTUNE = tf.data.AUTOTUNE\n","  batch_size = 8\n","  #seed = 42\n","\n","  x_train = data_manager.x_train\n","  y_train = data_manager.y_train\n","  x_test = data_manager.x_test\n","  y_test = data_manager.y_test\n","\n","  # Create TensorFlow datasets for the training and validation sets\n","  train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n","  val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n","\n","  # Cache the training and validation datasets\n","  train_dataset = train_dataset.cache()\n","  val_dataset = val_dataset.cache()\n","\n","\n","  # Prefetch the training and validation datasets\n","  train_ds = train_dataset.prefetch(buffer_size=AUTOTUNE)\n","  test_ds = val_dataset.prefetch(buffer_size=AUTOTUNE)\n","\n","  class_names = ['payload','label']\n","\n","  # First, train the BERT model.\n","\n","  print('****************************************************')\n","  #bert_model_name = 'bert_en_uncased_L-12_H-768_A-12'\n","  bert_model_name = 'small_bert/bert_en_uncased_L-8_H-128_A-2'#smallest Recall\n","\n","  tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n","  tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n","\n","  print(f'BERT model selected           : {tfhub_handle_encoder}')\n","  print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')\n","\n","\n","  bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n","  bert_model = hub.KerasLayer(tfhub_handle_encoder)\n","  second_stage_classifier_model = build_classifier_model(tfhub_handle_preprocess, tfhub_handle_encoder)\n","\n","  loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","  metrics = tf.metrics.BinaryAccuracy()\n","\n","  epochs = 10 #DEBUG MODIFY ME\n","  #steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n","  steps_per_epoch = data_manager.x_train.shape[0]\n","  num_train_steps = (steps_per_epoch * epochs) #//200 \n","  num_warmup_steps = int(0.1*num_train_steps)\n","\n","  init_lr = 3e-5\n","  optimizer = optimization.create_optimizer(init_lr=init_lr,\n","                                            num_train_steps=num_train_steps,\n","                                            num_warmup_steps=num_warmup_steps,\n","                                            optimizer_type='adamw')\n","\n","  second_stage_classifier_model.compile(optimizer=optimizer,\n","                          loss=loss,\n","                          metrics=metrics)\n","\n","\n","  print(f'Training model with {tfhub_handle_encoder}')\n","  start_time = time.time()\n","  history = second_stage_classifier_model.fit(x=train_ds, # x=train_ds.take(2), \n","                                validation_data=test_ds, # validation_data=test_ds.take(2), \n","                                epochs=epochs)\n","  stop_time = time.time()\n","  training_time = (stop_time - start_time)*1000 / data_manager.notes['train_size']\n","\n","  # Prepare first stage outputs for the second stage\n","  print(len(first_stage_positive_preds)) #np array\n","  print(len(first_stage_positive_preds_true_labels)) # np array\n","\n","  # Create TensorFlow datasets for the prediction set\n","  pred_dataset = tf.data.Dataset.from_tensor_slices(\n","      (first_stage_positive_preds, first_stage_positive_preds_true_labels)).batch(batch_size)\n","\n","  # Cache the pred dataset\n","  pred_dataset = pred_dataset.cache()\n","\n","  # Prefetch the pred datasets\n","  first_stage_pos_preds = pred_dataset.prefetch(buffer_size=AUTOTUNE)\n","\n","  # Predict only positive outputs of the first stage\n","  start_time = time.time()\n","  y_pred = second_stage_classifier_model.predict(first_stage_pos_preds)#.take(2))\n","  stop_time = time.time()\n","  testing_time = (stop_time - start_time)*1000 / len(first_stage_positive_preds) \n","  y_pred_np = tf.cast(tf.sigmoid(y_pred) > 0.5, tf.int32).numpy()\n","  X, y_true = zip(*first_stage_pos_preds.unbatch())# take(2).\n","  y_true_np = [y.numpy() for y in y_true]\n","  #precision, recall, f1, support = precision_recall_fscore_support(y_true_np, y_pred_np, average='binary')\n","  #tn, fp, fn, tp = confusion_matrix(y_true_np, y_pred_np).ravel()\n","\n","  notes = {'feature_method': bert_model_name,'model': bert_model_name, \n","            'seed': data_manager.notes['seed'], \n","            'split_ratio': data_manager.notes['split_ratio'],\n","            'train_size': data_manager.notes['train_size'],\n","            'test_size': data_manager.notes['test_size'],\n","            'extraction_time':0, 'feature_size':0,\n","            'train_time': training_time,\n","            'pred_time': testing_time, 'dataset': config['dataset']['file']}\n","  result = evaluate(y_true_np, y_pred_np, notes)\n","  pprint(result)\n","  save_results([result], proposed_test_results_file)\n"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UqfbUsmjrhSB","executionInfo":{"status":"ok","timestamp":1685458225883,"user_tz":-60,"elapsed":6073316,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"}},"outputId":"224036d2-c763-449e-94ed-a3e61e142b24"},"outputs":[{"output_type":"stream","name":"stdout","text":["######################################\n","seed:13\n","13\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["{'accuracy': 0.9890558640967004,\n"," 'class_weights': {0: 0.001, 1: 0.999},\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0.08286838300311697,\n"," 'f1_score': 0.9854189336235039,\n"," 'feature_method': 'tf-idf_ngram',\n"," 'feature_size': 29157,\n"," 'fn': 6,\n"," 'fp': 61,\n"," 'model': 'PassiveAggressiveClassifier',\n"," 'pass_aggressive_threshold': -0.3,\n"," 'precision': 0.973763440860215,\n"," 'pred_time': 0.0006029785789332722,\n"," 'recall': 0.9973568281938326,\n"," 'seed': 13,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 3791,\n"," 'tp': 2264,\n"," 'train_size': 24487,\n"," 'train_time': 0.05485970903768075}\n","Positive predicitions in the first stage: 2325 out of 6122. Ratio:0.3797778503756942\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1\n","Epoch 1/10\n","3061/3061 [==============================] - 137s 40ms/step - loss: 0.2301 - binary_accuracy: 0.8953 - val_loss: 0.0470 - val_binary_accuracy: 0.9887\n","Epoch 2/10\n","3061/3061 [==============================] - 122s 40ms/step - loss: 0.0364 - binary_accuracy: 0.9916 - val_loss: 0.0156 - val_binary_accuracy: 0.9969\n","Epoch 3/10\n","3061/3061 [==============================] - 123s 40ms/step - loss: 0.0231 - binary_accuracy: 0.9955 - val_loss: 0.0131 - val_binary_accuracy: 0.9972\n","Epoch 4/10\n","3061/3061 [==============================] - 123s 40ms/step - loss: 0.0140 - binary_accuracy: 0.9972 - val_loss: 0.0149 - val_binary_accuracy: 0.9975\n","Epoch 5/10\n","3061/3061 [==============================] - 123s 40ms/step - loss: 0.0125 - binary_accuracy: 0.9977 - val_loss: 0.0079 - val_binary_accuracy: 0.9987\n","Epoch 6/10\n","3061/3061 [==============================] - 123s 40ms/step - loss: 0.0097 - binary_accuracy: 0.9981 - val_loss: 0.0094 - val_binary_accuracy: 0.9984\n","Epoch 7/10\n","3061/3061 [==============================] - 122s 40ms/step - loss: 0.0099 - binary_accuracy: 0.9982 - val_loss: 0.0066 - val_binary_accuracy: 0.9989\n","Epoch 8/10\n","3061/3061 [==============================] - 118s 39ms/step - loss: 0.0082 - binary_accuracy: 0.9983 - val_loss: 0.0120 - val_binary_accuracy: 0.9979\n","Epoch 9/10\n","3061/3061 [==============================] - 113s 37ms/step - loss: 0.0058 - binary_accuracy: 0.9986 - val_loss: 0.0153 - val_binary_accuracy: 0.9980\n","Epoch 10/10\n","3061/3061 [==============================] - 113s 37ms/step - loss: 0.0066 - binary_accuracy: 0.9989 - val_loss: 0.0140 - val_binary_accuracy: 0.9984\n","2325\n","2325\n","291/291 [==============================] - 5s 14ms/step\n","{'accuracy': 0.9982795698924731,\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0,\n"," 'f1_score': 0.9991158267020336,\n"," 'feature_method': 'small_bert/bert_en_uncased_L-8_H-128_A-2',\n"," 'feature_size': 0,\n"," 'fn': 4,\n"," 'fp': 0,\n"," 'model': 'small_bert/bert_en_uncased_L-8_H-128_A-2',\n"," 'precision': 1.0,\n"," 'pred_time': 2.0272831250262517,\n"," 'recall': 0.9982332155477032,\n"," 'seed': 13,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 61,\n"," 'tp': 2260,\n"," 'train_size': 24487,\n"," 'train_time': 49.68436649266583}\n","######################################\n","seed:27\n","27\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["{'accuracy': 0.9893825547206795,\n"," 'class_weights': {0: 0.001, 1: 0.999},\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0.07672457713857106,\n"," 'f1_score': 0.985854189336235,\n"," 'feature_method': 'tf-idf_ngram',\n"," 'feature_size': 29212,\n"," 'fn': 7,\n"," 'fp': 58,\n"," 'model': 'PassiveAggressiveClassifier',\n"," 'pass_aggressive_threshold': -0.3,\n"," 'precision': 0.9750322858372794,\n"," 'pred_time': 0.0005681621448076928,\n"," 'recall': 0.996919014084507,\n"," 'seed': 27,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 3792,\n"," 'tp': 2265,\n"," 'train_size': 24487,\n"," 'train_time': 0.046815421195993544}\n","Positive predicitions in the first stage: 2323 out of 6122. Ratio:0.3794511597517151\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1\n","Epoch 1/10\n","3061/3061 [==============================] - 128s 37ms/step - loss: 0.2271 - binary_accuracy: 0.8979 - val_loss: 0.0514 - val_binary_accuracy: 0.9884\n","Epoch 2/10\n","3061/3061 [==============================] - 114s 37ms/step - loss: 0.0452 - binary_accuracy: 0.9902 - val_loss: 0.0172 - val_binary_accuracy: 0.9964\n","Epoch 3/10\n","3061/3061 [==============================] - 113s 37ms/step - loss: 0.0238 - binary_accuracy: 0.9953 - val_loss: 0.0129 - val_binary_accuracy: 0.9974\n","Epoch 4/10\n","3061/3061 [==============================] - 113s 37ms/step - loss: 0.0153 - binary_accuracy: 0.9970 - val_loss: 0.0067 - val_binary_accuracy: 0.9989\n","Epoch 5/10\n","3061/3061 [==============================] - 113s 37ms/step - loss: 0.0111 - binary_accuracy: 0.9976 - val_loss: 0.0141 - val_binary_accuracy: 0.9972\n","Epoch 6/10\n","3061/3061 [==============================] - 114s 37ms/step - loss: 0.0121 - binary_accuracy: 0.9979 - val_loss: 0.0059 - val_binary_accuracy: 0.9989\n","Epoch 7/10\n","3061/3061 [==============================] - 114s 37ms/step - loss: 0.0102 - binary_accuracy: 0.9980 - val_loss: 0.0050 - val_binary_accuracy: 0.9989\n","Epoch 8/10\n","3061/3061 [==============================] - 114s 37ms/step - loss: 0.0083 - binary_accuracy: 0.9984 - val_loss: 0.0113 - val_binary_accuracy: 0.9982\n","Epoch 9/10\n","3061/3061 [==============================] - 114s 37ms/step - loss: 0.0053 - binary_accuracy: 0.9988 - val_loss: 0.0101 - val_binary_accuracy: 0.9984\n","Epoch 10/10\n","3061/3061 [==============================] - 114s 37ms/step - loss: 0.0067 - binary_accuracy: 0.9988 - val_loss: 0.0089 - val_binary_accuracy: 0.9985\n","2323\n","2323\n","291/291 [==============================] - 4s 13ms/step\n","{'accuracy': 0.9995695221696083,\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0,\n"," 'f1_score': 0.9997792007065577,\n"," 'feature_method': 'small_bert/bert_en_uncased_L-8_H-128_A-2',\n"," 'feature_size': 0,\n"," 'fn': 1,\n"," 'fp': 0,\n"," 'model': 'small_bert/bert_en_uncased_L-8_H-128_A-2',\n"," 'precision': 1.0,\n"," 'pred_time': 1.961663320461738,\n"," 'recall': 0.9995584988962473,\n"," 'seed': 27,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 58,\n"," 'tp': 2264,\n"," 'train_size': 24487,\n"," 'train_time': 46.96269593632381}\n","######################################\n","seed:42\n","42\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["{'accuracy': 0.9895459000326691,\n"," 'class_weights': {0: 0.001, 1: 0.999},\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0.07702550377403806,\n"," 'f1_score': 0.9860809047411918,\n"," 'feature_method': 'tf-idf_ngram',\n"," 'feature_size': 29216,\n"," 'fn': 6,\n"," 'fp': 58,\n"," 'model': 'PassiveAggressiveClassifier',\n"," 'pass_aggressive_threshold': -0.3,\n"," 'precision': 0.9750537634408603,\n"," 'pred_time': 0.0005713945430542511,\n"," 'recall': 0.9973603167619886,\n"," 'seed': 42,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 3791,\n"," 'tp': 2267,\n"," 'train_size': 24487,\n"," 'train_time': 0.046303561714556525}\n","Positive predicitions in the first stage: 2325 out of 6122. Ratio:0.3797778503756942\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1\n","Epoch 1/10\n","3061/3061 [==============================] - 127s 38ms/step - loss: 0.3286 - binary_accuracy: 0.8265 - val_loss: 0.0712 - val_binary_accuracy: 0.9840\n","Epoch 2/10\n","3061/3061 [==============================] - 114s 37ms/step - loss: 0.0454 - binary_accuracy: 0.9898 - val_loss: 0.0364 - val_binary_accuracy: 0.9941\n","Epoch 3/10\n","3061/3061 [==============================] - 114s 37ms/step - loss: 0.0214 - binary_accuracy: 0.9954 - val_loss: 0.0213 - val_binary_accuracy: 0.9967\n","Epoch 4/10\n","3061/3061 [==============================] - 114s 37ms/step - loss: 0.0147 - binary_accuracy: 0.9971 - val_loss: 0.0232 - val_binary_accuracy: 0.9969\n","Epoch 5/10\n","3061/3061 [==============================] - 114s 37ms/step - loss: 0.0125 - binary_accuracy: 0.9977 - val_loss: 0.0214 - val_binary_accuracy: 0.9972\n","Epoch 6/10\n","3061/3061 [==============================] - 114s 37ms/step - loss: 0.0099 - binary_accuracy: 0.9981 - val_loss: 0.0174 - val_binary_accuracy: 0.9975\n","Epoch 7/10\n","3061/3061 [==============================] - 114s 37ms/step - loss: 0.0078 - binary_accuracy: 0.9986 - val_loss: 0.0247 - val_binary_accuracy: 0.9969\n","Epoch 8/10\n","3061/3061 [==============================] - 114s 37ms/step - loss: 0.0084 - binary_accuracy: 0.9986 - val_loss: 0.0237 - val_binary_accuracy: 0.9969\n","Epoch 9/10\n","3061/3061 [==============================] - 114s 37ms/step - loss: 0.0070 - binary_accuracy: 0.9987 - val_loss: 0.0171 - val_binary_accuracy: 0.9980\n","Epoch 10/10\n","3061/3061 [==============================] - 114s 37ms/step - loss: 0.0029 - binary_accuracy: 0.9994 - val_loss: 0.0191 - val_binary_accuracy: 0.9980\n","2325\n","2325\n","291/291 [==============================] - 5s 13ms/step\n","{'accuracy': 0.9974193548387097,\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0,\n"," 'f1_score': 0.9986749116607775,\n"," 'feature_method': 'small_bert/bert_en_uncased_L-8_H-128_A-2',\n"," 'feature_size': 0,\n"," 'fn': 6,\n"," 'fp': 0,\n"," 'model': 'small_bert/bert_en_uncased_L-8_H-128_A-2',\n"," 'precision': 1.0,\n"," 'pred_time': 2.0107855848086778,\n"," 'recall': 0.9973533303925893,\n"," 'seed': 42,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 58,\n"," 'tp': 2261,\n"," 'train_size': 24487,\n"," 'train_time': 47.06738504076489}\n","######################################\n","seed:72\n","72\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["{'accuracy': 0.9887291734727214,\n"," 'class_weights': {0: 0.001, 1: 0.999},\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0.07778969884070651,\n"," 'f1_score': 0.9850617016670274,\n"," 'feature_method': 'tf-idf_ngram',\n"," 'feature_size': 29275,\n"," 'fn': 6,\n"," 'fp': 63,\n"," 'model': 'PassiveAggressiveClassifier',\n"," 'pass_aggressive_threshold': -0.3,\n"," 'precision': 0.9730538922155688,\n"," 'pred_time': 0.0005541031596630237,\n"," 'recall': 0.9973695747479175,\n"," 'seed': 72,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 3778,\n"," 'tp': 2275,\n"," 'train_size': 24487,\n"," 'train_time': 0.046288830334224894}\n","Positive predicitions in the first stage: 2338 out of 6122. Ratio:0.3819013394315583\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1\n","Epoch 1/10\n","3061/3061 [==============================] - 125s 37ms/step - loss: 0.2459 - binary_accuracy: 0.8983 - val_loss: 0.0475 - val_binary_accuracy: 0.9891\n","Epoch 2/10\n","3061/3061 [==============================] - 113s 37ms/step - loss: 0.0378 - binary_accuracy: 0.9914 - val_loss: 0.0168 - val_binary_accuracy: 0.9971\n","Epoch 3/10\n","3061/3061 [==============================] - 113s 37ms/step - loss: 0.0207 - binary_accuracy: 0.9960 - val_loss: 0.0099 - val_binary_accuracy: 0.9980\n","Epoch 4/10\n","3061/3061 [==============================] - 113s 37ms/step - loss: 0.0138 - binary_accuracy: 0.9969 - val_loss: 0.0170 - val_binary_accuracy: 0.9969\n","Epoch 5/10\n","3061/3061 [==============================] - 113s 37ms/step - loss: 0.0133 - binary_accuracy: 0.9974 - val_loss: 0.0131 - val_binary_accuracy: 0.9979\n","Epoch 6/10\n","3061/3061 [==============================] - 113s 37ms/step - loss: 0.0095 - binary_accuracy: 0.9982 - val_loss: 0.0086 - val_binary_accuracy: 0.9982\n","Epoch 7/10\n","3061/3061 [==============================] - 115s 38ms/step - loss: 0.0083 - binary_accuracy: 0.9984 - val_loss: 0.0083 - val_binary_accuracy: 0.9989\n","Epoch 8/10\n","3061/3061 [==============================] - 123s 40ms/step - loss: 0.0082 - binary_accuracy: 0.9984 - val_loss: 0.0205 - val_binary_accuracy: 0.9974\n","Epoch 9/10\n","3061/3061 [==============================] - 122s 40ms/step - loss: 0.0044 - binary_accuracy: 0.9989 - val_loss: 0.0161 - val_binary_accuracy: 0.9984\n","Epoch 10/10\n","3061/3061 [==============================] - 122s 40ms/step - loss: 0.0052 - binary_accuracy: 0.9989 - val_loss: 0.0117 - val_binary_accuracy: 0.9985\n","2338\n","2338\n","293/293 [==============================] - 5s 14ms/step\n","{'accuracy': 0.9991445680068435,\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0,\n"," 'f1_score': 0.9995602462620932,\n"," 'feature_method': 'small_bert/bert_en_uncased_L-8_H-128_A-2',\n"," 'feature_size': 0,\n"," 'fn': 2,\n"," 'fp': 0,\n"," 'model': 'small_bert/bert_en_uncased_L-8_H-128_A-2',\n"," 'precision': 1.0,\n"," 'pred_time': 2.1950202277830466,\n"," 'recall': 0.9991208791208791,\n"," 'seed': 72,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 63,\n"," 'tp': 2273,\n"," 'train_size': 24487,\n"," 'train_time': 47.88209391374394}\n","######################################\n","seed:84\n","84\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["{'accuracy': 0.9895459000326691,\n"," 'class_weights': {0: 0.001, 1: 0.999},\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0.08281817403971115,\n"," 'f1_score': 0.9858719646799118,\n"," 'feature_method': 'tf-idf_ngram',\n"," 'feature_size': 29187,\n"," 'fn': 6,\n"," 'fp': 58,\n"," 'model': 'PassiveAggressiveClassifier',\n"," 'pass_aggressive_threshold': -0.3,\n"," 'precision': 0.9746835443037974,\n"," 'pred_time': 0.0005840125795829845,\n"," 'recall': 0.9973202322465387,\n"," 'seed': 84,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 3825,\n"," 'tp': 2233,\n"," 'train_size': 24487,\n"," 'train_time': 0.05082743911845982}\n","Positive predicitions in the first stage: 2291 out of 6122. Ratio:0.37422410976804965\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1\n","Epoch 1/10\n","3061/3061 [==============================] - 138s 40ms/step - loss: 0.2755 - binary_accuracy: 0.8852 - val_loss: 0.0559 - val_binary_accuracy: 0.9884\n","Epoch 2/10\n","3061/3061 [==============================] - 123s 40ms/step - loss: 0.0438 - binary_accuracy: 0.9899 - val_loss: 0.0193 - val_binary_accuracy: 0.9961\n","Epoch 3/10\n","3061/3061 [==============================] - 122s 40ms/step - loss: 0.0229 - binary_accuracy: 0.9957 - val_loss: 0.0156 - val_binary_accuracy: 0.9972\n","Epoch 4/10\n","3061/3061 [==============================] - 123s 40ms/step - loss: 0.0170 - binary_accuracy: 0.9967 - val_loss: 0.0116 - val_binary_accuracy: 0.9979\n","Epoch 5/10\n","3061/3061 [==============================] - 123s 40ms/step - loss: 0.0126 - binary_accuracy: 0.9975 - val_loss: 0.0094 - val_binary_accuracy: 0.9982\n","Epoch 6/10\n","3061/3061 [==============================] - 123s 40ms/step - loss: 0.0104 - binary_accuracy: 0.9979 - val_loss: 0.0059 - val_binary_accuracy: 0.9990\n","Epoch 7/10\n","3061/3061 [==============================] - 123s 40ms/step - loss: 0.0113 - binary_accuracy: 0.9977 - val_loss: 0.0135 - val_binary_accuracy: 0.9984\n","Epoch 8/10\n","3061/3061 [==============================] - 123s 40ms/step - loss: 0.0075 - binary_accuracy: 0.9986 - val_loss: 0.0165 - val_binary_accuracy: 0.9980\n","Epoch 9/10\n","3061/3061 [==============================] - 123s 40ms/step - loss: 0.0061 - binary_accuracy: 0.9989 - val_loss: 0.0130 - val_binary_accuracy: 0.9987\n","Epoch 10/10\n","3061/3061 [==============================] - 123s 40ms/step - loss: 0.0038 - binary_accuracy: 0.9992 - val_loss: 0.0155 - val_binary_accuracy: 0.9984\n","2291\n","2291\n","287/287 [==============================] - 5s 15ms/step\n","{'accuracy': 0.998254037538193,\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0,\n"," 'f1_score': 0.9991039426523298,\n"," 'feature_method': 'small_bert/bert_en_uncased_L-8_H-128_A-2',\n"," 'feature_size': 0,\n"," 'fn': 3,\n"," 'fp': 1,\n"," 'model': 'small_bert/bert_en_uncased_L-8_H-128_A-2',\n"," 'precision': 0.9995517705064993,\n"," 'pred_time': 2.261784752088569,\n"," 'recall': 0.9986565158978952,\n"," 'seed': 84,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 57,\n"," 'tp': 2230,\n"," 'train_size': 24487,\n"," 'train_time': 50.823644235046785}\n"]}],"source":["# Run first and second stages with different seeds:\n","seeds = [13, 27, 42, 72, 84]# 34, 1984, 1994, 77]\n","#seeds = [13]\n","for seed in seeds:\n","  print('######################################')\n","  print(f\"seed:{seed}\")\n","  split_dataset(seed=seed)\n","  print(data_manager.notes['seed'])\n","  #first_stage_y_pred, first_stage_positive_preds_true_labels = first_stage_xgboost()\n","  first_stage_y_pred, first_stage_positive_preds_true_labels = first_stage_passive_aggressive()\n","  second_stage(first_stage_y_pred, first_stage_positive_preds_true_labels)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"https://github.com/tensorflow/text/blob/master/docs/tutorials/classify_text_with_bert.ipynb","timestamp":1675862264150}],"gpuType":"A100","gpuClass":"premium"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"vscode":{"interpreter":{"hash":"085c9640c77a34c1b406144a3bd4a3c83460825e7fcd209668d2630032a9442a"}}},"nbformat":4,"nbformat_minor":0}