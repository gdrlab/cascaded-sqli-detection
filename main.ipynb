{"cells":[{"cell_type":"markdown","metadata":{"id":"kRXA63pgF_5J"},"source":["# Experiments of the paper: \"Efficient Detection of SQL Injection Attacks Utilising Cascade Natural Language Processing\""]},{"cell_type":"markdown","metadata":{"id":"mlW1ajN9GOp_"},"source":["## Initializations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MqgCOCzc1AFe"},"outputs":[],"source":["#%load_ext autoreload\n","#%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21804,"status":"ok","timestamp":1685028812490,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"r3SajLBfMY2f","outputId":"54cc3c75-bd44-4581-b160-9f486ef05941"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"newbm9LK79G_"},"outputs":[],"source":["from pathlib import Path\n","main_folder = Path('/content/drive/MyDrive/Akademik/Research and Projects/Sakir Hoca Projects/AI Security Intelligence/Codes/20230525_sqli_colab')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3618,"status":"ok","timestamp":1685028816095,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"w_-R9cC9lWx8","outputId":"09d364ea-c2b4-41ad-99f8-b3ebb0f3496e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Akademik/Research and Projects/Sakir Hoca Projects/AI Security Intelligence/Codes/20230525_sqli_colab\n","total 104K\n","-rw------- 1 root root 3.6K May 23 14:01 classical_models.py\n","-rw------- 1 root root 1.1K May 25 15:23 config.ini\n","drwx------ 2 root root 4.0K May 11 11:42 \u001b[0m\u001b[01;34mdatasets\u001b[0m/\n","-rw------- 1 root root 7.7K May 23 14:01 ensemble_models.py\n","-rw------- 1 root root  20K May 25 12:48 experiments.py\n","-rw------- 1 root root  813 Apr 17 09:08 .gitignore\n","-rw------- 1 root root    3 Apr  3 11:59 LICENSE.md\n","-rw------- 1 root root  36K May 25 15:33 main.ipynb\n","drwx------ 2 root root 4.0K May 25 13:15 \u001b[01;34m__pycache__\u001b[0m/\n","-rw------- 1 root root 5.4K May 11 10:49 README.md\n","drwx------ 2 root root 4.0K May 25 13:06 \u001b[01;34mresults\u001b[0m/\n","-rw------- 1 root root 1.3K May 25 15:31 run_classical_MLs.py\n","-rw------- 1 root root  318 May 11 10:49 sqli-env.yml\n","-rw------- 1 root root 6.3K May 25 14:56 templates.py\n","drwx------ 2 root root 4.0K Apr  3 11:59 \u001b[01;34mtrained_models\u001b[0m/\n","drwx------ 2 root root 4.0K May 25 13:05 \u001b[01;34mutils\u001b[0m/\n"]}],"source":["%cd $main_folder\n","%ls -lah"]},{"cell_type":"markdown","metadata":{"id":"k0DXUQ1tIqEF"},"source":["Warning: BERT libraries had problems after Colab system is upgraded. The solution I found is to downgrade numpy. After running the following code, restart the session and check the numpy version. If the libraries are working just fine in future, you can remove the downgrade fix."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xmn1CHABCsZi"},"outputs":[],"source":["#!pip install -q -U numpy==1.22 --ignore-installed"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1685028816096,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"tqD40wf4069j","outputId":"1d177111-1edc-4922-ad75-f85014655e0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["numpy: \t\t 1.22.4\n","sklearn: \t 1.2.2\n","Python 3.10.11\n"]}],"source":["import numpy as np\n","import sklearn\n","print(\"numpy: \\t\\t\", np.__version__)\n","print(\"sklearn: \\t\", sklearn.__version__)\n","!python --version"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6231,"status":"ok","timestamp":1685028822322,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"q-YbjCkzw0yU","outputId":"b1b3e6a0-531e-446a-ee57-a2ebdb56c354"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m181.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# A dependency of the preprocessing for BERT inputs\n","#!pip install  -q -U \"tensorflow-text==2.8.*\"\n","!pip install  -q -U \"tensorflow-text\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27523,"status":"ok","timestamp":1685028849840,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"b-P1ZOA0FkVJ","outputId":"8ec99c31-e476-4842-9e8d-34042b70d94b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyyaml (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["#!pip install -q tf-models-official==2.7.0\n","!pip install -q tf-models-official"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1685028849841,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"Fw2_o8VS_hpZ","outputId":"23ddb496-ea42-4029-9096-01cd63e78510"},"outputs":[{"name":"stdout","output_type":"stream","text":["The scikit-learn version is 1.2.2.\n"]}],"source":["import sklearn\n","print('The scikit-learn version is {}.'.format(sklearn.__version__))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6690,"status":"ok","timestamp":1685028856517,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"b9AprPGFMhQ4","outputId":"e6f4905f-2f98-474a-b6ba-6ff04cb2bab5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Pandas v 1.5.3\n"]}],"source":["from pathlib import Path\n","from datetime import datetime\n","import os\n","import shutil\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","from official.nlp import optimization  # to create AdamW optimizer\n","\n","import matplotlib.pyplot as plt\n","\n","import pandas as pd\n","import time\n","\n","\n","import time\n","from sklearn import metrics\n","from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n","\n","from experiments import evaluate, save_results\n","\n","print('Pandas v', pd.__version__)\n","#tf.get_logger().setLevel('ERROR')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":442,"status":"ok","timestamp":1685028856955,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"iXfCnfKRZMty","outputId":"c64a9741-816c-4a3f-9104-18755895cd7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu May 25 15:34:14 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   31C    P0    46W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":[" !nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1685028856955,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"t48CqXYRmrey","outputId":"7dc1eddf-d554-4243-b261-1b02bf3c8264"},"outputs":[{"data":{"text/plain":["['config.ini']"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["import configparser\n","from templates import DataManager, logger\n","config = configparser.ConfigParser()\n","config.read('config.ini')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nseZXgKhpjjh"},"outputs":[],"source":["data_manager = DataManager(config)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1685028858188,"user":{"displayName":"Kasim Tasdemir","userId":"13577932980440881494"},"user_tz":-60},"id":"ccnJtym5lWx-","outputId":"f45e34fa-a74a-42fa-8c3c-805fc5a9dff9"},"outputs":[{"name":"stdout","output_type":"stream","text":["All results:/content/drive/MyDrive/Akademik/Research and Projects/Sakir Hoca Projects/AI Security Intelligence/Codes/20230525_sqli_colab/results/results_230525_153416.csv\n","Proposed method results:/content/drive/MyDrive/Akademik/Research and Projects/Sakir Hoca Projects/AI Security Intelligence/Codes/20230525_sqli_colab/results/proposed_method_results.csv\n"]}],"source":["#%%script echo skipping\n","results_dir = Path(config['results']['dir'])\n","\n","currentDateAndTime = datetime.now()\n","currentTime = currentDateAndTime.strftime(\"%y%m%d_%H%M%S\")\n","file_name = f'results_{currentTime}.csv'\n","output_file = main_folder / results_dir / file_name\n","proposed_test_results_file = main_folder / results_dir / 'proposed_method_results.csv'\n","print(f\"All results:{output_file.absolute()}\")\n","print(f\"Proposed method results:{proposed_test_results_file.absolute()}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tr6pW32WGi1D"},"source":["## Classical ML (Single NLP) tests"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"8RC2O_SyuIFe","outputId":"cbdd102e-4f12-40b8-9c77-859d22993624"},"outputs":[{"name":"stdout","output_type":"stream","text":["05-25-2023 15:34:18 l:27| Loaded dataset with 30609 rows.\n","Running the tests for seed: 13\n","Feature extractors:   0% 0/1 [00:00\u003c?, ?it/s]05-25-2023 15:34:18 l:83| running 1 of 1 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/21 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 15:34:20 l:91| running 1 of 21 models.\n","05-25-2023 15:34:20 l:151| Training model: XGBoost\n","05-25-2023 15:34:39 l:159| Ended training XGBoost in: 18.065535517s\n","\n","Models:   5% 1/21 [00:18\u003c06:01, 18.09s/it]\u001b[A05-25-2023 15:34:39 l:91| running 2 of 21 models.\n","05-25-2023 15:34:39 l:151| Training model: MultinomialNB\n","05-25-2023 15:34:39 l:159| Ended training MultinomialNB in: 0.016300705000020344s\n","05-25-2023 15:34:39 l:91| running 3 of 21 models.\n","05-25-2023 15:34:39 l:151| Training model: SVM_RBF\n","05-25-2023 15:36:40 l:159| Ended training SVM_RBF in: 121.83940907400003s\n","\n","Models:  14% 3/21 [02:32\u003c16:22, 54.59s/it]\u001b[A05-25-2023 15:36:53 l:91| running 4 of 21 models.\n","05-25-2023 15:36:53 l:151| Training model: MLPClassifier\n","05-25-2023 15:37:33 l:159| Ended training MLPClassifier in: 39.593385125s\n","\n","Models:  19% 4/21 [03:12\u003c14:00, 49.41s/it]\u001b[A05-25-2023 15:37:33 l:91| running 5 of 21 models.\n","05-25-2023 15:37:33 l:151| Training model: KNeighborsClassifier\n","05-25-2023 15:37:33 l:159| Ended training KNeighborsClassifier in: 0.017706536999980926s\n","\n","Models:  24% 5/21 [06:26\u003c25:56, 97.27s/it]\u001b[A05-25-2023 15:40:47 l:91| running 6 of 21 models.\n","05-25-2023 15:40:47 l:151| Training model: NearestCentroid\n","05-25-2023 15:40:47 l:159| Ended training NearestCentroid in: 0.032491420000042126s\n","05-25-2023 15:40:47 l:91| running 7 of 21 models.\n","05-25-2023 15:40:47 l:151| Training model: RadiusNeighborsClassifier\n","05-25-2023 15:40:47 l:159| Ended training RadiusNeighborsClassifier in: 0.009179988000028061s\n","\n","Models:  33% 7/21 [09:40\u003c22:39, 97.14s/it]\u001b[A05-25-2023 15:44:01 l:91| running 8 of 21 models.\n","05-25-2023 15:44:01 l:151| Training model: SVC-GC\n","05-25-2023 15:48:41 l:159| Ended training SVC-GC in: 280.10581599299996s\n","\n","Models:  38% 8/21 [14:43\u003c32:33, 150.25s/it]\u001b[A05-25-2023 15:49:04 l:91| running 9 of 21 models.\n","05-25-2023 15:49:04 l:151| Training model: NuSVC\n","05-25-2023 15:55:30 l:159| Ended training NuSVC in: 385.293907796s\n","\n","Models:  43% 9/21 [21:57\u003c45:16, 226.38s/it]\u001b[A05-25-2023 15:56:18 l:91| running 10 of 21 models.\n","05-25-2023 15:56:18 l:151| Training model: LinearSVC\n","05-25-2023 15:56:18 l:159| Ended training LinearSVC in: 0.15219468700001926s\n","\n","Models:  48% 10/21 [21:57\u003c29:59, 163.58s/it]\u001b[A05-25-2023 15:56:18 l:91| running 11 of 21 models.\n","05-25-2023 15:56:18 l:151| Training model: DecisionTreeClassifier\n","05-25-2023 15:56:19 l:159| Ended training DecisionTreeClassifier in: 1.798562420000053s\n","\n","Models:  52% 11/21 [21:59\u003c19:36, 117.64s/it]\u001b[A05-25-2023 15:56:19 l:91| running 12 of 21 models.\n","05-25-2023 15:56:19 l:151| Training model: AdaBoostClassifier\n","05-25-2023 15:56:40 l:159| Ended training AdaBoostClassifier in: 20.34660873300004s\n","\n","Models:  57% 12/21 [22:19\u003c13:26, 89.61s/it] \u001b[A05-25-2023 15:56:40 l:91| running 13 of 21 models.\n","05-25-2023 15:56:40 l:151| Training model: BaggingClassifier\n","05-25-2023 15:57:40 l:159| Ended training BaggingClassifier in: 60.15468409799996s\n","\n","Models:  62% 13/21 [23:19\u003c10:48, 81.03s/it]\u001b[A05-25-2023 15:57:40 l:91| running 14 of 21 models.\n","05-25-2023 15:57:40 l:151| Training model: ExtraTreesClassifier\n","05-25-2023 15:57:51 l:159| Ended training ExtraTreesClassifier in: 10.718403918999911s\n","\n","Models:  67% 14/21 [23:30\u003c07:03, 60.44s/it]\u001b[A05-25-2023 15:57:51 l:91| running 15 of 21 models.\n","05-25-2023 15:57:51 l:151| Training model: RidgeClassifier\n","05-25-2023 15:57:53 l:159| Ended training RidgeClassifier in: 1.7422279689999414s\n","\n","Models:  71% 15/21 [23:32\u003c04:18, 43.08s/it]\u001b[A05-25-2023 15:57:53 l:91| running 16 of 21 models.\n","05-25-2023 15:57:53 l:151| Training model: SGDClassifier\n","05-25-2023 15:57:53 l:159| Ended training SGDClassifier in: 0.12419161700017867s\n","\n","Models:  76% 16/21 [23:32\u003c02:31, 30.32s/it]\u001b[A05-25-2023 15:57:53 l:91| running 17 of 21 models.\n","05-25-2023 15:57:53 l:151| Training model: Perceptron\n","05-25-2023 15:57:53 l:159| Ended training Perceptron in: 0.06571206299986443s\n","05-25-2023 15:57:53 l:91| running 18 of 21 models.\n","05-25-2023 15:57:53 l:151| Training model: LogisticRegression\n","05-25-2023 15:57:55 l:159| Ended training LogisticRegression in: 1.6195394179999312s\n","\n","Models:  86% 18/21 [23:34\u003c00:50, 16.79s/it]\u001b[A05-25-2023 15:57:55 l:91| running 19 of 21 models.\n","05-25-2023 15:57:55 l:151| Training model: PassiveAggressiveClassifier\n","05-25-2023 15:57:55 l:159| Ended training PassiveAggressiveClassifier in: 0.11995180399981109s\n","\n","Models:  90% 19/21 [23:34\u003c00:25, 12.68s/it]\u001b[A05-25-2023 15:57:55 l:91| running 20 of 21 models.\n","05-25-2023 15:57:55 l:151| Training model: OneVsRestClassifier\n","05-25-2023 15:58:05 l:159| Ended training OneVsRestClassifier in: 9.666239075000021s\n","\n","Models:  95% 20/21 [23:44\u003c00:11, 11.90s/it]\u001b[A05-25-2023 15:58:05 l:91| running 21 of 21 models.\n","05-25-2023 15:58:05 l:151| Training model: OneVsOneClassifier\n","05-25-2023 15:58:13 l:159| Ended training OneVsOneClassifier in: 7.820671540999911s\n","\n","Models: 100% 21/21 [23:52\u003c00:00, 68.20s/it]\n","Feature extractors: 100% 1/1 [23:54\u003c00:00, 1434.41s/it]\n","Feature extractors:   0% 0/3 [00:00\u003c?, ?it/s]05-25-2023 15:58:13 l:130| running 1 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 15:58:13 l:138| running 1 of 3 models.\n","05-25-2023 15:58:13 l:151| Training model: MultinomialNB\n","05-25-2023 15:58:13 l:159| Ended training MultinomialNB in: 0.005601764999937586s\n","05-25-2023 15:58:13 l:138| running 2 of 3 models.\n","05-25-2023 15:58:13 l:151| Training model: XGBoost\n","05-25-2023 15:58:14 l:159| Ended training XGBoost in: 1.0909897480000836s\n","\n","Models:  67% 2/3 [00:01\u003c00:00,  1.77it/s]\u001b[A05-25-2023 15:58:14 l:138| running 3 of 3 models.\n","05-25-2023 15:58:14 l:151| Training model: SVM_RBF\n","05-25-2023 15:59:00 l:159| Ended training SVM_RBF in: 45.56872075900014s\n","\n","Models: 100% 3/3 [00:49\u003c00:00, 16.57s/it]\n","Feature extractors:  33% 1/3 [00:49\u003c01:39, 50.00s/it]05-25-2023 15:59:03 l:130| running 2 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 15:59:05 l:138| running 1 of 3 models.\n","05-25-2023 15:59:05 l:151| Training model: MultinomialNB\n","05-25-2023 15:59:05 l:159| Ended training MultinomialNB in: 0.017323582000017268s\n","05-25-2023 15:59:05 l:138| running 2 of 3 models.\n","05-25-2023 15:59:05 l:151| Training model: XGBoost\n","05-25-2023 15:59:14 l:159| Ended training XGBoost in: 9.595308744000022s\n","\n","Models:  67% 2/3 [00:09\u003c00:04,  4.83s/it]\u001b[A05-25-2023 15:59:14 l:138| running 3 of 3 models.\n","05-25-2023 15:59:14 l:151| Training model: SVM_RBF\n","05-25-2023 16:01:18 l:159| Ended training SVM_RBF in: 123.31504330899998s\n","\n","Models: 100% 3/3 [02:25\u003c00:00, 48.62s/it]\n","Feature extractors:  67% 2/3 [03:18\u003c01:47, 107.67s/it]05-25-2023 16:01:31 l:130| running 3 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 16:01:31 l:138| running 1 of 3 models.\n","05-25-2023 16:01:31 l:151| Training model: MultinomialNB\n","05-25-2023 16:01:31 l:159| Ended training MultinomialNB in: 0.006104012999912811s\n","05-25-2023 16:01:31 l:138| running 2 of 3 models.\n","05-25-2023 16:01:31 l:151| Training model: XGBoost\n","05-25-2023 16:01:32 l:159| Ended training XGBoost in: 0.8416192380000211s\n","\n","Models:  67% 2/3 [00:00\u003c00:00,  2.28it/s]\u001b[A05-25-2023 16:01:32 l:138| running 3 of 3 models.\n","05-25-2023 16:01:32 l:151| Training model: SVM_RBF\n","05-25-2023 16:01:38 l:159| Ended training SVM_RBF in: 5.647090857999956s\n","\n","Models: 100% 3/3 [00:07\u003c00:00,  2.65s/it]\n","Feature extractors: 100% 3/3 [03:26\u003c00:00, 68.83s/it]\n","No ensemble method selected in config.ini file.\n","05-25-2023 16:01:39 l:40| header is True\n","05-25-2023 16:01:39 l:270| Results saved to results/results_230525_153416.csv\n","05-25-2023 16:01:39 l:188| Params saved to results/params_230525_153416.json\n","Running the tests for seed: 27\n","Feature extractors:   0% 0/1 [00:00\u003c?, ?it/s]05-25-2023 16:01:39 l:83| running 1 of 1 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/21 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 16:01:41 l:91| running 1 of 21 models.\n","05-25-2023 16:01:41 l:151| Training model: XGBoost\n","05-25-2023 16:01:49 l:159| Ended training XGBoost in: 7.850337311999965s\n","\n","Models:   5% 1/21 [00:07\u003c02:37,  7.87s/it]\u001b[A05-25-2023 16:01:49 l:91| running 2 of 21 models.\n","05-25-2023 16:01:49 l:151| Training model: MultinomialNB\n","05-25-2023 16:01:49 l:159| Ended training MultinomialNB in: 0.016921575999958804s\n","05-25-2023 16:01:49 l:91| running 3 of 21 models.\n","05-25-2023 16:01:49 l:151| Training model: SVM_RBF\n","05-25-2023 16:03:54 l:159| Ended training SVM_RBF in: 124.39794270199991s\n","\n","Models:  14% 3/21 [02:25\u003c15:54, 53.00s/it]\u001b[A05-25-2023 16:04:07 l:91| running 4 of 21 models.\n","05-25-2023 16:04:07 l:151| Training model: MLPClassifier\n","05-25-2023 16:04:47 l:159| Ended training MLPClassifier in: 40.16285503599988s\n","\n","Models:  19% 4/21 [03:05\u003c13:45, 48.57s/it]\u001b[A05-25-2023 16:04:47 l:91| running 5 of 21 models.\n","05-25-2023 16:04:47 l:151| Training model: KNeighborsClassifier\n","05-25-2023 16:04:47 l:159| Ended training KNeighborsClassifier in: 0.01014033899991773s\n","\n","Models:  24% 5/21 [06:20\u003c25:49, 96.83s/it]\u001b[A05-25-2023 16:08:02 l:91| running 6 of 21 models.\n","05-25-2023 16:08:02 l:151| Training model: NearestCentroid\n","05-25-2023 16:08:02 l:159| Ended training NearestCentroid in: 0.02587948799964579s\n","05-25-2023 16:08:02 l:91| running 7 of 21 models.\n","05-25-2023 16:08:02 l:151| Training model: RadiusNeighborsClassifier\n","05-25-2023 16:08:02 l:159| Ended training RadiusNeighborsClassifier in: 0.009347111999886693s\n","\n","Models:  33% 7/21 [09:34\u003c22:39, 97.10s/it]\u001b[A05-25-2023 16:11:16 l:91| running 8 of 21 models.\n","05-25-2023 16:11:16 l:151| Training model: SVC-GC\n","05-25-2023 16:15:46 l:159| Ended training SVC-GC in: 270.15861038699995s\n","\n","Models:  38% 8/21 [14:28\u003c32:00, 147.72s/it]\u001b[A05-25-2023 16:16:10 l:91| running 9 of 21 models.\n","05-25-2023 16:16:10 l:151| Training model: NuSVC\n","05-25-2023 16:22:30 l:159| Ended training NuSVC in: 380.35899610700017s\n","\n","Models:  43% 9/21 [21:36\u003c44:39, 223.26s/it]\u001b[A05-25-2023 16:23:18 l:91| running 10 of 21 models.\n","05-25-2023 16:23:18 l:151| Training model: LinearSVC\n","05-25-2023 16:23:18 l:159| Ended training LinearSVC in: 0.11453461900009643s\n","\n","Models:  48% 10/21 [21:37\u003c29:34, 161.31s/it]\u001b[A05-25-2023 16:23:18 l:91| running 11 of 21 models.\n","05-25-2023 16:23:18 l:151| Training model: DecisionTreeClassifier\n","05-25-2023 16:23:20 l:159| Ended training DecisionTreeClassifier in: 1.7896925650002231s\n","\n","Models:  52% 11/21 [21:38\u003c19:20, 116.01s/it]\u001b[A05-25-2023 16:23:20 l:91| running 12 of 21 models.\n","05-25-2023 16:23:20 l:151| Training model: AdaBoostClassifier\n","05-25-2023 16:23:41 l:159| Ended training AdaBoostClassifier in: 20.260898199000167s\n","\n","Models:  57% 12/21 [21:59\u003c13:15, 88.43s/it] \u001b[A05-25-2023 16:23:41 l:91| running 13 of 21 models.\n","05-25-2023 16:23:41 l:151| Training model: BaggingClassifier\n","05-25-2023 16:24:39 l:159| Ended training BaggingClassifier in: 58.25379175299986s\n","\n","Models:  62% 13/21 [22:57\u003c10:37, 79.64s/it]\u001b[A05-25-2023 16:24:39 l:91| running 14 of 21 models.\n","05-25-2023 16:24:39 l:151| Training model: ExtraTreesClassifier\n","05-25-2023 16:24:50 l:159| Ended training ExtraTreesClassifier in: 10.626821573000143s\n","\n","Models:  67% 14/21 [23:08\u003c06:56, 59.44s/it]\u001b[A05-25-2023 16:24:50 l:91| running 15 of 21 models.\n","05-25-2023 16:24:50 l:151| Training model: RidgeClassifier\n","05-25-2023 16:24:52 l:159| Ended training RidgeClassifier in: 1.7911178230001497s\n","\n","Models:  71% 15/21 [23:10\u003c04:14, 42.38s/it]\u001b[A05-25-2023 16:24:52 l:91| running 16 of 21 models.\n","05-25-2023 16:24:52 l:151| Training model: SGDClassifier\n","05-25-2023 16:24:52 l:159| Ended training SGDClassifier in: 0.1335060439996596s\n","\n","Models:  76% 16/21 [23:10\u003c02:29, 29.83s/it]\u001b[A05-25-2023 16:24:52 l:91| running 17 of 21 models.\n","05-25-2023 16:24:52 l:151| Training model: Perceptron\n","05-25-2023 16:24:52 l:159| Ended training Perceptron in: 0.0670697789996666s\n","05-25-2023 16:24:52 l:91| running 18 of 21 models.\n","05-25-2023 16:24:52 l:151| Training model: LogisticRegression\n","05-25-2023 16:24:54 l:159| Ended training LogisticRegression in: 1.6107363500000247s\n","\n","Models:  86% 18/21 [23:12\u003c00:49, 16.53s/it]\u001b[A05-25-2023 16:24:54 l:91| running 19 of 21 models.\n","05-25-2023 16:24:54 l:151| Training model: PassiveAggressiveClassifier\n","05-25-2023 16:24:54 l:159| Ended training PassiveAggressiveClassifier in: 0.15245866399982333s\n","\n","Models:  90% 19/21 [23:12\u003c00:24, 12.49s/it]\u001b[A05-25-2023 16:24:54 l:91| running 20 of 21 models.\n","05-25-2023 16:24:54 l:151| Training model: OneVsRestClassifier\n","05-25-2023 16:25:02 l:159| Ended training OneVsRestClassifier in: 8.10321971700023s\n","\n","Models:  95% 20/21 [23:20\u003c00:11, 11.35s/it]\u001b[A05-25-2023 16:25:02 l:91| running 21 of 21 models.\n","05-25-2023 16:25:02 l:151| Training model: OneVsOneClassifier\n","05-25-2023 16:25:12 l:159| Ended training OneVsOneClassifier in: 9.643935124000109s\n","\n","Models: 100% 21/21 [23:30\u003c00:00, 67.16s/it]\n","Feature extractors: 100% 1/1 [23:32\u003c00:00, 1412.54s/it]\n","Feature extractors:   0% 0/3 [00:00\u003c?, ?it/s]05-25-2023 16:25:12 l:130| running 1 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 16:25:12 l:138| running 1 of 3 models.\n","05-25-2023 16:25:12 l:151| Training model: MultinomialNB\n","05-25-2023 16:25:12 l:159| Ended training MultinomialNB in: 0.005869968999832054s\n","05-25-2023 16:25:12 l:138| running 2 of 3 models.\n","05-25-2023 16:25:12 l:151| Training model: XGBoost\n","05-25-2023 16:25:13 l:159| Ended training XGBoost in: 1.2431441010003255s\n","\n","Models:  67% 2/3 [00:01\u003c00:00,  1.56it/s]\u001b[A05-25-2023 16:25:13 l:138| running 3 of 3 models.\n","05-25-2023 16:25:13 l:151| Training model: SVM_RBF\n","05-25-2023 16:25:59 l:159| Ended training SVM_RBF in: 45.257974159999776s\n","\n","Models: 100% 3/3 [00:49\u003c00:00, 16.54s/it]\n","Feature extractors:  33% 1/3 [00:49\u003c01:39, 49.92s/it]05-25-2023 16:26:02 l:130| running 2 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 16:26:04 l:138| running 1 of 3 models.\n","05-25-2023 16:26:04 l:151| Training model: MultinomialNB\n","05-25-2023 16:26:04 l:159| Ended training MultinomialNB in: 0.016590393000115s\n","05-25-2023 16:26:04 l:138| running 2 of 3 models.\n","05-25-2023 16:26:04 l:151| Training model: XGBoost\n","05-25-2023 16:26:13 l:159| Ended training XGBoost in: 9.024636648000069s\n","\n","Models:  67% 2/3 [00:09\u003c00:04,  4.54s/it]\u001b[A05-25-2023 16:26:13 l:138| running 3 of 3 models.\n","05-25-2023 16:26:13 l:151| Training model: SVM_RBF\n","05-25-2023 16:28:17 l:159| Ended training SVM_RBF in: 124.35996165200004s\n","\n","Models: 100% 3/3 [02:26\u003c00:00, 48.90s/it]\n","Feature extractors:  67% 2/3 [03:18\u003c01:48, 108.13s/it]05-25-2023 16:28:31 l:130| running 3 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 16:28:31 l:138| running 1 of 3 models.\n","05-25-2023 16:28:31 l:151| Training model: MultinomialNB\n","05-25-2023 16:28:31 l:159| Ended training MultinomialNB in: 0.00616567200040663s\n","05-25-2023 16:28:31 l:138| running 2 of 3 models.\n","05-25-2023 16:28:31 l:151| Training model: XGBoost\n","05-25-2023 16:28:32 l:159| Ended training XGBoost in: 0.7941998060000515s\n","\n","Models:  67% 2/3 [00:00\u003c00:00,  2.41it/s]\u001b[A05-25-2023 16:28:32 l:138| running 3 of 3 models.\n","05-25-2023 16:28:32 l:151| Training model: SVM_RBF\n","05-25-2023 16:28:37 l:159| Ended training SVM_RBF in: 5.588525003000086s\n","\n","Models: 100% 3/3 [00:07\u003c00:00,  2.63s/it]\n","Feature extractors: 100% 3/3 [03:27\u003c00:00, 69.06s/it]\n","No ensemble method selected in config.ini file.\n","05-25-2023 16:28:39 l:40| header is True\n","05-25-2023 16:28:39 l:48| Appending to the existing .csv file.\n","05-25-2023 16:28:39 l:270| Results saved to results/results_230525_153416.csv\n","05-25-2023 16:28:39 l:188| Params saved to results/params_230525_153416.json\n","Running the tests for seed: 42\n","Feature extractors:   0% 0/1 [00:00\u003c?, ?it/s]05-25-2023 16:28:39 l:83| running 1 of 1 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/21 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 16:28:41 l:91| running 1 of 21 models.\n","05-25-2023 16:28:41 l:151| Training model: XGBoost\n","05-25-2023 16:28:51 l:159| Ended training XGBoost in: 9.84061692000023s\n","\n","Models:   5% 1/21 [00:09\u003c03:17,  9.87s/it]\u001b[A05-25-2023 16:28:51 l:91| running 2 of 21 models.\n","05-25-2023 16:28:51 l:151| Training model: MultinomialNB\n","05-25-2023 16:28:51 l:159| Ended training MultinomialNB in: 0.016567120000217983s\n","05-25-2023 16:28:51 l:91| running 3 of 21 models.\n","05-25-2023 16:28:51 l:151| Training model: SVM_RBF\n","05-25-2023 16:30:54 l:159| Ended training SVM_RBF in: 123.13311858299994s\n","\n","Models:  14% 3/21 [02:26\u003c15:53, 52.99s/it]\u001b[A05-25-2023 16:31:07 l:91| running 4 of 21 models.\n","05-25-2023 16:31:07 l:151| Training model: MLPClassifier\n","05-25-2023 16:32:02 l:159| Ended training MLPClassifier in: 55.07221188600033s\n","\n","Models:  19% 4/21 [03:21\u003c15:13, 53.72s/it]\u001b[A05-25-2023 16:32:02 l:91| running 5 of 21 models.\n","05-25-2023 16:32:02 l:151| Training model: KNeighborsClassifier\n","05-25-2023 16:32:02 l:159| Ended training KNeighborsClassifier in: 0.018074356999932206s\n","\n","Models:  24% 5/21 [06:33\u003c26:35, 99.69s/it]\u001b[A05-25-2023 16:35:15 l:91| running 6 of 21 models.\n","05-25-2023 16:35:15 l:151| Training model: NearestCentroid\n","05-25-2023 16:35:15 l:159| Ended training NearestCentroid in: 0.024776403000032587s\n","05-25-2023 16:35:15 l:91| running 7 of 21 models.\n","05-25-2023 16:35:15 l:151| Training model: RadiusNeighborsClassifier\n","05-25-2023 16:35:15 l:159| Ended training RadiusNeighborsClassifier in: 0.008763788999658573s\n","\n","Models:  33% 7/21 [09:46\u003c22:51, 97.96s/it]\u001b[A05-25-2023 16:38:27 l:91| running 8 of 21 models.\n","05-25-2023 16:38:27 l:151| Training model: SVC-GC\n","05-25-2023 16:43:02 l:159| Ended training SVC-GC in: 274.53404330600006s\n","\n","Models:  38% 8/21 [14:43\u003c32:22, 149.42s/it]\u001b[A05-25-2023 16:43:25 l:91| running 9 of 21 models.\n","05-25-2023 16:43:25 l:151| Training model: NuSVC\n","05-25-2023 16:49:47 l:159| Ended training NuSVC in: 381.9914406810003s\n","\n","Models:  43% 9/21 [21:53\u003c44:57, 224.81s/it]\u001b[A05-25-2023 16:50:35 l:91| running 10 of 21 models.\n","05-25-2023 16:50:35 l:151| Training model: LinearSVC\n","05-25-2023 16:50:35 l:159| Ended training LinearSVC in: 0.10815029700006562s\n","\n","Models:  48% 10/21 [21:53\u003c29:46, 162.43s/it]\u001b[A05-25-2023 16:50:35 l:91| running 11 of 21 models.\n","05-25-2023 16:50:35 l:151| Training model: DecisionTreeClassifier\n","05-25-2023 16:50:36 l:159| Ended training DecisionTreeClassifier in: 1.7645185199999105s\n","\n","Models:  52% 11/21 [21:55\u003c19:28, 116.81s/it]\u001b[A05-25-2023 16:50:36 l:91| running 12 of 21 models.\n","05-25-2023 16:50:36 l:151| Training model: AdaBoostClassifier\n","05-25-2023 16:50:57 l:159| Ended training AdaBoostClassifier in: 20.102904106000096s\n","\n","Models:  57% 12/21 [22:15\u003c13:20, 88.94s/it] \u001b[A05-25-2023 16:50:57 l:91| running 13 of 21 models.\n","05-25-2023 16:50:57 l:151| Training model: BaggingClassifier\n","05-25-2023 16:51:56 l:159| Ended training BaggingClassifier in: 58.92734569299955s\n","\n","Models:  62% 13/21 [23:14\u003c10:41, 80.21s/it]\u001b[A05-25-2023 16:51:56 l:91| running 14 of 21 models.\n","05-25-2023 16:51:56 l:151| Training model: ExtraTreesClassifier\n","05-25-2023 16:52:06 l:159| Ended training ExtraTreesClassifier in: 10.386439818000326s\n","\n","Models:  67% 14/21 [23:25\u003c06:58, 59.76s/it]\u001b[A05-25-2023 16:52:06 l:91| running 15 of 21 models.\n","05-25-2023 16:52:06 l:151| Training model: RidgeClassifier\n","05-25-2023 16:52:08 l:159| Ended training RidgeClassifier in: 1.763964775000204s\n","\n","Models:  71% 15/21 [23:27\u003c04:15, 42.60s/it]\u001b[A05-25-2023 16:52:08 l:91| running 16 of 21 models.\n","05-25-2023 16:52:08 l:151| Training model: SGDClassifier\n","05-25-2023 16:52:08 l:159| Ended training SGDClassifier in: 0.11462348400073097s\n","\n","Models:  76% 16/21 [23:27\u003c02:29, 29.98s/it]\u001b[A05-25-2023 16:52:08 l:91| running 17 of 21 models.\n","05-25-2023 16:52:08 l:151| Training model: Perceptron\n","05-25-2023 16:52:08 l:159| Ended training Perceptron in: 0.050936845999785874s\n","05-25-2023 16:52:08 l:91| running 18 of 21 models.\n","05-25-2023 16:52:08 l:151| Training model: LogisticRegression\n","05-25-2023 16:52:10 l:159| Ended training LogisticRegression in: 2.0417316470002334s\n","\n","Models:  86% 18/21 [23:29\u003c00:50, 16.71s/it]\u001b[A05-25-2023 16:52:11 l:91| running 19 of 21 models.\n","05-25-2023 16:52:11 l:151| Training model: PassiveAggressiveClassifier\n","05-25-2023 16:52:11 l:159| Ended training PassiveAggressiveClassifier in: 0.14324809400022787s\n","\n","Models:  90% 19/21 [23:29\u003c00:25, 12.62s/it]\u001b[A05-25-2023 16:52:11 l:91| running 20 of 21 models.\n","05-25-2023 16:52:11 l:151| Training model: OneVsRestClassifier\n","05-25-2023 16:52:19 l:159| Ended training OneVsRestClassifier in: 8.687850827000148s\n","\n","Models:  95% 20/21 [23:38\u003c00:11, 11.61s/it]\u001b[A05-25-2023 16:52:19 l:91| running 21 of 21 models.\n","05-25-2023 16:52:19 l:151| Training model: OneVsOneClassifier\n","05-25-2023 16:52:28 l:159| Ended training OneVsOneClassifier in: 9.04609725299997s\n","\n","Models: 100% 21/21 [23:47\u003c00:00, 67.97s/it]\n","Feature extractors: 100% 1/1 [23:49\u003c00:00, 1429.59s/it]\n","Feature extractors:   0% 0/3 [00:00\u003c?, ?it/s]05-25-2023 16:52:29 l:130| running 1 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 16:52:29 l:138| running 1 of 3 models.\n","05-25-2023 16:52:29 l:151| Training model: MultinomialNB\n","05-25-2023 16:52:29 l:159| Ended training MultinomialNB in: 0.005536996999580879s\n","05-25-2023 16:52:29 l:138| running 2 of 3 models.\n","05-25-2023 16:52:29 l:151| Training model: XGBoost\n","05-25-2023 16:52:30 l:159| Ended training XGBoost in: 1.1159404250001899s\n","\n","Models:  67% 2/3 [00:01\u003c00:00,  1.74it/s]\u001b[A05-25-2023 16:52:30 l:138| running 3 of 3 models.\n","05-25-2023 16:52:30 l:151| Training model: SVM_RBF\n","05-25-2023 16:53:15 l:159| Ended training SVM_RBF in: 44.84277454000039s\n","\n","Models: 100% 3/3 [00:49\u003c00:00, 16.35s/it]\n","Feature extractors:  33% 1/3 [00:49\u003c01:38, 49.35s/it]05-25-2023 16:53:18 l:130| running 2 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 16:53:20 l:138| running 1 of 3 models.\n","05-25-2023 16:53:20 l:151| Training model: MultinomialNB\n","05-25-2023 16:53:20 l:159| Ended training MultinomialNB in: 0.01686281999991479s\n","05-25-2023 16:53:20 l:138| running 2 of 3 models.\n","05-25-2023 16:53:20 l:151| Training model: XGBoost\n","05-25-2023 16:53:28 l:159| Ended training XGBoost in: 7.8445719629999076s\n","\n","Models:  67% 2/3 [00:07\u003c00:03,  3.95s/it]\u001b[A05-25-2023 16:53:28 l:138| running 3 of 3 models.\n","05-25-2023 16:53:28 l:151| Training model: SVM_RBF\n","05-25-2023 16:55:31 l:159| Ended training SVM_RBF in: 122.63460095200026s\n","\n","Models: 100% 3/3 [02:23\u003c00:00, 47.83s/it]\n","Feature extractors:  67% 2/3 [03:15\u003c01:46, 106.03s/it]05-25-2023 16:55:44 l:130| running 3 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 16:55:44 l:138| running 1 of 3 models.\n","05-25-2023 16:55:44 l:151| Training model: MultinomialNB\n","05-25-2023 16:55:44 l:159| Ended training MultinomialNB in: 0.006053177000467258s\n","05-25-2023 16:55:44 l:138| running 2 of 3 models.\n","05-25-2023 16:55:44 l:151| Training model: XGBoost\n","05-25-2023 16:55:45 l:159| Ended training XGBoost in: 1.01875110400033s\n","\n","Models:  67% 2/3 [00:01\u003c00:00,  1.90it/s]\u001b[A05-25-2023 16:55:45 l:138| running 3 of 3 models.\n","05-25-2023 16:55:45 l:151| Training model: SVM_RBF\n","05-25-2023 16:55:51 l:159| Ended training SVM_RBF in: 5.54842200100029s\n","\n","Models: 100% 3/3 [00:08\u003c00:00,  2.68s/it]\n","Feature extractors: 100% 3/3 [03:23\u003c00:00, 67.87s/it]\n","No ensemble method selected in config.ini file.\n","05-25-2023 16:55:52 l:40| header is True\n","05-25-2023 16:55:52 l:48| Appending to the existing .csv file.\n","05-25-2023 16:55:52 l:270| Results saved to results/results_230525_153416.csv\n","05-25-2023 16:55:52 l:188| Params saved to results/params_230525_153416.json\n","Running the tests for seed: 72\n","Feature extractors:   0% 0/1 [00:00\u003c?, ?it/s]05-25-2023 16:55:52 l:83| running 1 of 1 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/21 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 16:55:54 l:91| running 1 of 21 models.\n","05-25-2023 16:55:54 l:151| Training model: XGBoost\n","05-25-2023 16:56:04 l:159| Ended training XGBoost in: 9.523955476000083s\n","\n","Models:   5% 1/21 [00:09\u003c03:10,  9.55s/it]\u001b[A05-25-2023 16:56:04 l:91| running 2 of 21 models.\n","05-25-2023 16:56:04 l:151| Training model: MultinomialNB\n","05-25-2023 16:56:04 l:159| Ended training MultinomialNB in: 0.017808038000111992s\n","05-25-2023 16:56:04 l:91| running 3 of 21 models.\n","05-25-2023 16:56:04 l:151| Training model: SVM_RBF\n","05-25-2023 16:58:08 l:159| Ended training SVM_RBF in: 123.60462008200011s\n","\n","Models:  14% 3/21 [02:26\u003c15:55, 53.11s/it]\u001b[A05-25-2023 16:58:21 l:91| running 4 of 21 models.\n","05-25-2023 16:58:21 l:151| Training model: MLPClassifier\n","05-25-2023 16:58:59 l:159| Ended training MLPClassifier in: 38.42949926500023s\n","\n","Models:  19% 4/21 [03:04\u003c13:36, 48.05s/it]\u001b[A05-25-2023 16:58:59 l:91| running 5 of 21 models.\n","05-25-2023 16:58:59 l:151| Training model: KNeighborsClassifier\n","05-25-2023 16:58:59 l:159| Ended training KNeighborsClassifier in: 0.010025464999671385s\n","\n","Models:  24% 5/21 [06:18\u003c25:40, 96.28s/it]\u001b[A05-25-2023 17:02:13 l:91| running 6 of 21 models.\n","05-25-2023 17:02:13 l:151| Training model: NearestCentroid\n","05-25-2023 17:02:13 l:159| Ended training NearestCentroid in: 0.025356705000376678s\n","05-25-2023 17:02:13 l:91| running 7 of 21 models.\n","05-25-2023 17:02:13 l:151| Training model: RadiusNeighborsClassifier\n","05-25-2023 17:02:13 l:159| Ended training RadiusNeighborsClassifier in: 0.009034929999870656s\n","\n","Models:  33% 7/21 [09:32\u003c22:31, 96.53s/it]\u001b[A05-25-2023 17:05:27 l:91| running 8 of 21 models.\n","05-25-2023 17:05:27 l:151| Training model: SVC-GC\n","05-25-2023 17:09:58 l:159| Ended training SVC-GC in: 271.36073093199957s\n","\n","Models:  38% 8/21 [14:26\u003c31:58, 147.60s/it]\u001b[A05-25-2023 17:10:21 l:91| running 9 of 21 models.\n","05-25-2023 17:10:21 l:151| Training model: NuSVC\n","05-25-2023 17:16:40 l:159| Ended training NuSVC in: 378.6727253319996s\n","\n","Models:  43% 9/21 [21:33\u003c44:31, 222.65s/it]\u001b[A05-25-2023 17:17:28 l:91| running 10 of 21 models.\n","05-25-2023 17:17:28 l:151| Training model: LinearSVC\n","05-25-2023 17:17:28 l:159| Ended training LinearSVC in: 0.10726720500042575s\n","\n","Models:  48% 10/21 [21:33\u003c29:29, 160.87s/it]\u001b[A05-25-2023 17:17:28 l:91| running 11 of 21 models.\n","05-25-2023 17:17:28 l:151| Training model: DecisionTreeClassifier\n","05-25-2023 17:17:30 l:159| Ended training DecisionTreeClassifier in: 1.759896349999508s\n","\n","Models:  52% 11/21 [21:35\u003c19:16, 115.69s/it]\u001b[A05-25-2023 17:17:30 l:91| running 12 of 21 models.\n","05-25-2023 17:17:30 l:151| Training model: AdaBoostClassifier\n","05-25-2023 17:17:50 l:159| Ended training AdaBoostClassifier in: 20.04083375099981s\n","\n","Models:  57% 12/21 [21:55\u003c13:13, 88.13s/it] \u001b[A05-25-2023 17:17:50 l:91| running 13 of 21 models.\n","05-25-2023 17:17:50 l:151| Training model: BaggingClassifier\n","05-25-2023 17:18:48 l:159| Ended training BaggingClassifier in: 57.94933588399999s\n","\n","Models:  62% 13/21 [22:53\u003c10:34, 79.34s/it]\u001b[A05-25-2023 17:18:48 l:91| running 14 of 21 models.\n","05-25-2023 17:18:48 l:151| Training model: ExtraTreesClassifier\n","05-25-2023 17:18:58 l:159| Ended training ExtraTreesClassifier in: 10.470300891000079s\n","\n","Models:  67% 14/21 [23:04\u003c06:54, 59.18s/it]\u001b[A05-25-2023 17:18:59 l:91| running 15 of 21 models.\n","05-25-2023 17:18:59 l:151| Training model: RidgeClassifier\n","05-25-2023 17:19:00 l:159| Ended training RidgeClassifier in: 1.5286380939996889s\n","\n","Models:  71% 15/21 [23:06\u003c04:12, 42.12s/it]\u001b[A05-25-2023 17:19:00 l:91| running 16 of 21 models.\n","05-25-2023 17:19:00 l:151| Training model: SGDClassifier\n","05-25-2023 17:19:00 l:159| Ended training SGDClassifier in: 0.11678054399999382s\n","\n","Models:  76% 16/21 [23:06\u003c02:28, 29.65s/it]\u001b[A05-25-2023 17:19:00 l:91| running 17 of 21 models.\n","05-25-2023 17:19:00 l:151| Training model: Perceptron\n","05-25-2023 17:19:01 l:159| Ended training Perceptron in: 0.0627995490003741s\n","05-25-2023 17:19:01 l:91| running 18 of 21 models.\n","05-25-2023 17:19:01 l:151| Training model: LogisticRegression\n","05-25-2023 17:19:03 l:159| Ended training LogisticRegression in: 2.10847584000021s\n","\n","Models:  86% 18/21 [23:08\u003c00:49, 16.55s/it]\u001b[A05-25-2023 17:19:03 l:91| running 19 of 21 models.\n","05-25-2023 17:19:03 l:151| Training model: PassiveAggressiveClassifier\n","05-25-2023 17:19:03 l:159| Ended training PassiveAggressiveClassifier in: 0.14727663600024243s\n","\n","Models:  90% 19/21 [23:08\u003c00:24, 12.50s/it]\u001b[A05-25-2023 17:19:03 l:91| running 20 of 21 models.\n","05-25-2023 17:19:03 l:151| Training model: OneVsRestClassifier\n","05-25-2023 17:19:12 l:159| Ended training OneVsRestClassifier in: 9.434611370000312s\n","\n","Models:  95% 20/21 [23:17\u003c00:11, 11.71s/it]\u001b[A05-25-2023 17:19:12 l:91| running 21 of 21 models.\n","05-25-2023 17:19:12 l:151| Training model: OneVsOneClassifier\n","05-25-2023 17:19:20 l:159| Ended training OneVsOneClassifier in: 7.619795315999909s\n","\n","Models: 100% 21/21 [23:25\u003c00:00, 66.94s/it]\n","Feature extractors: 100% 1/1 [23:27\u003c00:00, 1407.83s/it]\n","Feature extractors:   0% 0/3 [00:00\u003c?, ?it/s]05-25-2023 17:19:20 l:130| running 1 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 17:19:20 l:138| running 1 of 3 models.\n","05-25-2023 17:19:20 l:151| Training model: MultinomialNB\n","05-25-2023 17:19:20 l:159| Ended training MultinomialNB in: 0.0056302510001842165s\n","05-25-2023 17:19:20 l:138| running 2 of 3 models.\n","05-25-2023 17:19:20 l:151| Training model: XGBoost\n","05-25-2023 17:19:21 l:159| Ended training XGBoost in: 1.0705716200000097s\n","\n","Models:  67% 2/3 [00:01\u003c00:00,  1.80it/s]\u001b[A05-25-2023 17:19:21 l:138| running 3 of 3 models.\n","05-25-2023 17:19:21 l:151| Training model: SVM_RBF\n","05-25-2023 17:20:06 l:159| Ended training SVM_RBF in: 45.08356196499972s\n","\n","Models: 100% 3/3 [00:49\u003c00:00, 16.42s/it]\n","Feature extractors:  33% 1/3 [00:49\u003c01:39, 49.54s/it]05-25-2023 17:20:10 l:130| running 2 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 17:20:12 l:138| running 1 of 3 models.\n","05-25-2023 17:20:12 l:151| Training model: MultinomialNB\n","05-25-2023 17:20:12 l:159| Ended training MultinomialNB in: 0.016460581000501406s\n","05-25-2023 17:20:12 l:138| running 2 of 3 models.\n","05-25-2023 17:20:12 l:151| Training model: XGBoost\n","05-25-2023 17:20:21 l:159| Ended training XGBoost in: 9.32330543900025s\n","\n","Models:  67% 2/3 [00:09\u003c00:04,  4.69s/it]\u001b[A05-25-2023 17:20:21 l:138| running 3 of 3 models.\n","05-25-2023 17:20:21 l:151| Training model: SVM_RBF\n","05-25-2023 17:22:23 l:159| Ended training SVM_RBF in: 122.41866934900008s\n","\n","Models: 100% 3/3 [02:24\u003c00:00, 48.30s/it]\n","Feature extractors:  67% 2/3 [03:16\u003c01:46, 106.92s/it]05-25-2023 17:22:37 l:130| running 3 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 17:22:37 l:138| running 1 of 3 models.\n","05-25-2023 17:22:37 l:151| Training model: MultinomialNB\n","05-25-2023 17:22:37 l:159| Ended training MultinomialNB in: 0.006016297999849485s\n","05-25-2023 17:22:37 l:138| running 2 of 3 models.\n","05-25-2023 17:22:37 l:151| Training model: XGBoost\n","05-25-2023 17:22:38 l:159| Ended training XGBoost in: 0.8137347490001048s\n","\n","Models:  67% 2/3 [00:00\u003c00:00,  2.35it/s]\u001b[A05-25-2023 17:22:38 l:138| running 3 of 3 models.\n","05-25-2023 17:22:38 l:151| Training model: SVM_RBF\n","05-25-2023 17:22:43 l:159| Ended training SVM_RBF in: 5.5270606619997125s\n","\n","Models: 100% 3/3 [00:07\u003c00:00,  2.61s/it]\n","Feature extractors: 100% 3/3 [03:24\u003c00:00, 68.31s/it]\n","No ensemble method selected in config.ini file.\n","05-25-2023 17:22:45 l:40| header is True\n","05-25-2023 17:22:45 l:48| Appending to the existing .csv file.\n","05-25-2023 17:22:45 l:270| Results saved to results/results_230525_153416.csv\n","05-25-2023 17:22:45 l:188| Params saved to results/params_230525_153416.json\n","Running the tests for seed: 84\n","Feature extractors:   0% 0/1 [00:00\u003c?, ?it/s]05-25-2023 17:22:45 l:83| running 1 of 1 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/21 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 17:22:47 l:91| running 1 of 21 models.\n","05-25-2023 17:22:47 l:151| Training model: XGBoost\n","05-25-2023 17:22:55 l:159| Ended training XGBoost in: 8.188182926000081s\n","\n","Models:   5% 1/21 [00:08\u003c02:44,  8.21s/it]\u001b[A05-25-2023 17:22:55 l:91| running 2 of 21 models.\n","05-25-2023 17:22:55 l:151| Training model: MultinomialNB\n","05-25-2023 17:22:55 l:159| Ended training MultinomialNB in: 0.016310662000250886s\n","05-25-2023 17:22:55 l:91| running 3 of 21 models.\n","05-25-2023 17:22:55 l:151| Training model: SVM_RBF\n","05-25-2023 17:24:57 l:159| Ended training SVM_RBF in: 122.09008455299954s\n","\n","Models:  14% 3/21 [02:23\u003c15:39, 52.18s/it]\u001b[A05-25-2023 17:25:10 l:91| running 4 of 21 models.\n","05-25-2023 17:25:10 l:151| Training model: MLPClassifier\n","05-25-2023 17:26:04 l:159| Ended training MLPClassifier in: 53.33238688700021s\n","\n","Models:  19% 4/21 [03:16\u003c14:54, 52.59s/it]\u001b[A05-25-2023 17:26:04 l:91| running 5 of 21 models.\n","05-25-2023 17:26:04 l:151| Training model: KNeighborsClassifier\n","05-25-2023 17:26:04 l:159| Ended training KNeighborsClassifier in: 0.010622333000355866s\n","\n","Models:  24% 5/21 [06:30\u003c26:31, 99.46s/it]\u001b[A05-25-2023 17:29:18 l:91| running 6 of 21 models.\n","05-25-2023 17:29:18 l:151| Training model: NearestCentroid\n","05-25-2023 17:29:18 l:159| Ended training NearestCentroid in: 0.025614706999476766s\n","05-25-2023 17:29:18 l:91| running 7 of 21 models.\n","05-25-2023 17:29:18 l:151| Training model: RadiusNeighborsClassifier\n","05-25-2023 17:29:18 l:159| Ended training RadiusNeighborsClassifier in: 0.00916014999984327s\n","\n","Models:  33% 7/21 [09:45\u003c22:56, 98.36s/it]\u001b[A05-25-2023 17:32:33 l:91| running 8 of 21 models.\n","05-25-2023 17:32:33 l:151| Training model: SVC-GC\n","05-25-2023 17:37:07 l:159| Ended training SVC-GC in: 274.48607590899974s\n","\n","Models:  38% 8/21 [14:43\u003c32:27, 149.77s/it]\u001b[A05-25-2023 17:37:30 l:91| running 9 of 21 models.\n","05-25-2023 17:37:30 l:151| Training model: NuSVC\n","05-25-2023 17:43:53 l:159| Ended training NuSVC in: 382.92111986800046s\n","\n","Models:  43% 9/21 [21:54\u003c45:05, 225.42s/it]\u001b[A05-25-2023 17:44:41 l:91| running 10 of 21 models.\n","05-25-2023 17:44:41 l:151| Training model: LinearSVC\n","05-25-2023 17:44:42 l:159| Ended training LinearSVC in: 0.151810254999873s\n","\n","Models:  48% 10/21 [21:54\u003c29:51, 162.88s/it]\u001b[A05-25-2023 17:44:42 l:91| running 11 of 21 models.\n","05-25-2023 17:44:42 l:151| Training model: DecisionTreeClassifier\n","05-25-2023 17:44:43 l:159| Ended training DecisionTreeClassifier in: 1.7864118210000015s\n","\n","Models:  52% 11/21 [21:56\u003c19:31, 117.14s/it]\u001b[A05-25-2023 17:44:43 l:91| running 12 of 21 models.\n","05-25-2023 17:44:43 l:151| Training model: AdaBoostClassifier\n","05-25-2023 17:45:03 l:159| Ended training AdaBoostClassifier in: 20.105660760999854s\n","\n","Models:  57% 12/21 [22:16\u003c13:22, 89.18s/it] \u001b[A05-25-2023 17:45:04 l:91| running 13 of 21 models.\n","05-25-2023 17:45:04 l:151| Training model: BaggingClassifier\n","05-25-2023 17:46:01 l:159| Ended training BaggingClassifier in: 57.17691120000018s\n","\n","Models:  62% 13/21 [23:13\u003c10:38, 79.86s/it]\u001b[A05-25-2023 17:46:01 l:91| running 14 of 21 models.\n","05-25-2023 17:46:01 l:151| Training model: ExtraTreesClassifier\n","05-25-2023 17:46:11 l:159| Ended training ExtraTreesClassifier in: 10.239932503000091s\n","\n","Models:  67% 14/21 [23:24\u003c06:56, 59.47s/it]\u001b[A05-25-2023 17:46:11 l:91| running 15 of 21 models.\n","05-25-2023 17:46:11 l:151| Training model: RidgeClassifier\n","05-25-2023 17:46:13 l:159| Ended training RidgeClassifier in: 1.6221752189994731s\n","\n","Models:  71% 15/21 [23:25\u003c04:14, 42.36s/it]\u001b[A05-25-2023 17:46:13 l:91| running 16 of 21 models.\n","05-25-2023 17:46:13 l:151| Training model: SGDClassifier\n","05-25-2023 17:46:13 l:159| Ended training SGDClassifier in: 0.13366368799961492s\n","\n","Models:  76% 16/21 [23:26\u003c02:29, 29.82s/it]\u001b[A05-25-2023 17:46:13 l:91| running 17 of 21 models.\n","05-25-2023 17:46:13 l:151| Training model: Perceptron\n","05-25-2023 17:46:13 l:159| Ended training Perceptron in: 0.07166228000005503s\n","05-25-2023 17:46:13 l:91| running 18 of 21 models.\n","05-25-2023 17:46:13 l:151| Training model: LogisticRegression\n","05-25-2023 17:46:14 l:159| Ended training LogisticRegression in: 0.9961358569998993s\n","\n","Models:  86% 18/21 [23:27\u003c00:49, 16.38s/it]\u001b[A05-25-2023 17:46:14 l:91| running 19 of 21 models.\n","05-25-2023 17:46:14 l:151| Training model: PassiveAggressiveClassifier\n","05-25-2023 17:46:14 l:159| Ended training PassiveAggressiveClassifier in: 0.13791526800014253s\n","\n","Models:  90% 19/21 [23:27\u003c00:24, 12.37s/it]\u001b[A05-25-2023 17:46:15 l:91| running 20 of 21 models.\n","05-25-2023 17:46:15 l:151| Training model: OneVsRestClassifier\n","05-25-2023 17:46:24 l:159| Ended training OneVsRestClassifier in: 9.954093165999438s\n","\n","Models:  95% 20/21 [23:37\u003c00:11, 11.75s/it]\u001b[A05-25-2023 17:46:24 l:91| running 21 of 21 models.\n","05-25-2023 17:46:24 l:151| Training model: OneVsOneClassifier\n","05-25-2023 17:46:33 l:159| Ended training OneVsOneClassifier in: 8.64776896300009s\n","\n","Models: 100% 21/21 [23:46\u003c00:00, 67.91s/it]\n","Feature extractors: 100% 1/1 [23:48\u003c00:00, 1428.25s/it]\n","Feature extractors:   0% 0/3 [00:00\u003c?, ?it/s]05-25-2023 17:46:33 l:130| running 1 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 17:46:33 l:138| running 1 of 3 models.\n","05-25-2023 17:46:33 l:151| Training model: MultinomialNB\n","05-25-2023 17:46:33 l:159| Ended training MultinomialNB in: 0.005664667999553785s\n","05-25-2023 17:46:33 l:138| running 2 of 3 models.\n","05-25-2023 17:46:33 l:151| Training model: XGBoost\n","05-25-2023 17:46:35 l:159| Ended training XGBoost in: 1.0617395709996345s\n","\n","Models:  67% 2/3 [00:01\u003c00:00,  1.82it/s]\u001b[A05-25-2023 17:46:35 l:138| running 3 of 3 models.\n","05-25-2023 17:46:35 l:151| Training model: SVM_RBF\n","05-25-2023 17:47:20 l:159| Ended training SVM_RBF in: 45.51187971900072s\n","\n","Models: 100% 3/3 [00:49\u003c00:00, 16.57s/it]\n","Feature extractors:  33% 1/3 [00:50\u003c01:40, 50.01s/it]05-25-2023 17:47:23 l:130| running 2 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 17:47:25 l:138| running 1 of 3 models.\n","05-25-2023 17:47:25 l:151| Training model: MultinomialNB\n","05-25-2023 17:47:25 l:159| Ended training MultinomialNB in: 0.01670820600065781s\n","05-25-2023 17:47:25 l:138| running 2 of 3 models.\n","05-25-2023 17:47:25 l:151| Training model: XGBoost\n","05-25-2023 17:47:35 l:159| Ended training XGBoost in: 10.076010339000277s\n","\n","Models:  67% 2/3 [00:10\u003c00:05,  5.07s/it]\u001b[A05-25-2023 17:47:36 l:138| running 3 of 3 models.\n","05-25-2023 17:47:36 l:151| Training model: SVM_RBF\n","05-25-2023 17:49:37 l:159| Ended training SVM_RBF in: 121.49901937599952s\n","\n","Models: 100% 3/3 [02:24\u003c00:00, 48.21s/it]\n","Feature extractors:  67% 2/3 [03:16\u003c01:46, 106.97s/it]05-25-2023 17:49:50 l:130| running 3 of 3 feature extractors.\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","\n","Models:   0% 0/3 [00:00\u003c?, ?it/s]\u001b[A05-25-2023 17:49:51 l:138| running 1 of 3 models.\n","05-25-2023 17:49:51 l:151| Training model: MultinomialNB\n","05-25-2023 17:49:51 l:159| Ended training MultinomialNB in: 0.005948722000539419s\n","05-25-2023 17:49:51 l:138| running 2 of 3 models.\n","05-25-2023 17:49:51 l:151| Training model: XGBoost\n","05-25-2023 17:49:51 l:159| Ended training XGBoost in: 0.8278777480009012s\n","\n","Models:  67% 2/3 [00:00\u003c00:00,  2.31it/s]\u001b[A05-25-2023 17:49:51 l:138| running 3 of 3 models.\n","05-25-2023 17:49:51 l:151| Training model: SVM_RBF\n","05-25-2023 17:49:57 l:159| Ended training SVM_RBF in: 5.586922487000265s\n","\n","Models: 100% 3/3 [00:07\u003c00:00,  2.64s/it]\n","Feature extractors: 100% 3/3 [03:25\u003c00:00, 68.42s/it]\n","No ensemble method selected in config.ini file.\n","05-25-2023 17:49:58 l:40| header is True\n","05-25-2023 17:49:58 l:48| Appending to the existing .csv file.\n","05-25-2023 17:49:58 l:270| Results saved to results/results_230525_153416.csv\n","05-25-2023 17:49:58 l:188| Params saved to results/params_230525_153416.json\n"]}],"source":["!python run_classical_MLs.py -o $file_name"]},{"cell_type":"markdown","metadata":{"id":"8VzVtm9TGuOC"},"source":["## LLM (BERT) tests"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"background_save":true},"id":"y8_ctG55-uTX","outputId":"4002e67a-57a1-4843-d4ca-8a50343f06ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"]}],"source":["#@title Choose a BERT model to fine-tune\n","\n","bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n","\n","map_name_to_handle = {\n","    'bert_en_uncased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n","    'bert_en_cased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n","    'bert_multi_cased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n","    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n","    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n","    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n","    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n","    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n","    'albert_en_base':\n","        'https://tfhub.dev/tensorflow/albert_en_base/2',\n","    'electra_small':\n","        'https://tfhub.dev/google/electra_small/2',\n","    'electra_base':\n","        'https://tfhub.dev/google/electra_base/2',\n","    'experts_pubmed':\n","        'https://tfhub.dev/google/experts/bert/pubmed/2',\n","    'experts_wiki_books':\n","        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n","    'talking-heads_base':\n","        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n","}\n","\n","map_model_to_preprocess = {\n","    'bert_en_uncased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'bert_en_cased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'bert_multi_cased_L-12_H-768_A-12':\n","        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n","    'albert_en_base':\n","        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n","    'electra_small':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'electra_base':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'experts_pubmed':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'experts_wiki_books':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","    'talking-heads_base':\n","        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n","}\n","\n","tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n","tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n","\n","print(f'BERT model selected           : {tfhub_handle_encoder}')\n","print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"f5xwsuzFaKiL"},"outputs":[],"source":["# Manual selection\n","bert_model_name_list = ['bert_en_uncased_L-12_H-768_A-12', \n","                        'bert_en_cased_L-12_H-768_A-12',\n","                        'small_bert/bert_en_uncased_L-2_H-128_A-2',\n","                        'small_bert/bert_en_uncased_L-4_H-512_A-8',\n","                        'small_bert/bert_en_uncased_L-8_H-128_A-2',\n","                        'small_bert/bert_en_uncased_L-12_H-768_A-12',\n","                        'bert_multi_cased_L-12_H-768_A-12',\n","                       'albert_en_base',\n","                        'electra_base',\n","                        'electra_small']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"aksj743St9ga"},"outputs":[],"source":["def build_classifier_model(local_tfhub_handle_preprocess, local_tfhub_handle_encoder):\n","  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='Payload')\n","  preprocessing_layer = hub.KerasLayer(local_tfhub_handle_preprocess, name='preprocessing')\n","  encoder_inputs = preprocessing_layer(text_input)\n","  encoder = hub.KerasLayer(local_tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n","  outputs = encoder(encoder_inputs)\n","  net = outputs['pooled_output']\n","  net = tf.keras.layers.Dropout(0.1)(net)\n","  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n","  return tf.keras.Model(text_input, net)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xFHT4mtCsKHP","outputId":"ede39e78-09c4-4c7c-a19d-3238d3f070ce"},"outputs":[{"data":{"text/plain":["24487"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["data_manager.x_train.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9tsOsmvENQSG"},"outputs":[],"source":["#main_dir = Path('/content/drive/MyDrive/Colab Notebooks/kasim/2023 Feb Bert SQLi/')\n","# 'SQLiV3_train.tsv', 'SQLiV3_test.tsv'\n","# 'NEW_normal_plus_waf_bypass_dataset_testing.tsv'\n","# 'NEW_normal_plus_waf_bypass_dataset_training.tsv'\n","#train_file_name = 'NEW_normal_plus_waf_bypass_dataset_training.tsv'\n","#train_file_name = 'SQLiV3_train.tsv'\n","#test_file_name = 'SQLiV3_test.tsv'\n","#train_file = Path(main_dir / train_file_name)\n","#test_file = Path(main_dir / test_file_name)\n","\n","#print(f'Train file exists: {train_file.is_file()}')\n","#print(f'Test file exists: {test_file.is_file()}')\n","\n","\n","currentDateAndTime = datetime.now()\n","currentTime = currentDateAndTime.strftime(\"%y%m%d_%H%M%S\")\n","#recording = Recorder(main_folder / results_dir / f'results_BERT_{currentTime}.csv')\n","\n","\n","AUTOTUNE = tf.data.AUTOTUNE\n","batch_size = 16\n","#seed = 42\n","\n","x_train = data_manager.x_train\n","y_train = data_manager.y_train\n","x_test = data_manager.x_test\n","y_test = data_manager.y_test\n","\n","# Create TensorFlow datasets for the training and validation sets\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(8)\n","val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(8)\n","\n","# Cache the training and validation datasets\n","train_dataset = train_dataset.cache()\n","val_dataset = val_dataset.cache()\n","\n","\n","# Prefetch the training and validation datasets\n","train_ds = train_dataset.prefetch(buffer_size=AUTOTUNE)\n","test_ds = val_dataset.prefetch(buffer_size=AUTOTUNE)\n","\n","\n","\n","#train_ds = test_csv_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","#val_ds = test_csv_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","# test_ds = val_ds\n","\n","class_names = ['payload','label']\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KT17nxwbHb9u","outputId":"55ecb80f-9c9c-420c-be3e-c10d34e0067d"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[b'9869'\n"," b\"1'||  (  select 'mdqc' where 4533  =  4533 and 8189  =    (  select count  (  *  )   from sysibm.systables as t1,sysibm.systables as t2,sysibm.systables as t3  )  --\"\n"," b\"1'   )    )     )   and sleep  (  5  )  #\"\n"," b'1 where 8578  =  8578 and 4770  =  4474--'\n"," b'SELECT COUNT ( officer ) FROM suddenly'\n"," b\"-5597'  )   or make_set  (  2490  =  2164,2164  )  \"\n"," b'SELECT TOP 50 PERCENT * FROM vote SELECT * FROM simplest FETCH FIRST 50 PERCENT ROWS ONLYSELECT TOP 3 * FROM test'\n"," b'calle alfred nobel, 42 7-g'], shape=(8,), dtype=string)\n","tf.Tensor([0 1 1 1 0 1 0 0], shape=(8,), dtype=int64)\n"]}],"source":["tmp = train_ds.take(1)\n","for i in next(iter(tmp)):\n","  print(i)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"6QVYvfmcwWgQ"},"outputs":[{"name":"stdout","output_type":"stream","text":["****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n","Epoch 1/10\n","3061/3061 [==============================] - 188s 55ms/step - loss: 0.1366 - binary_accuracy: 0.9448 - val_loss: 0.0115 - val_binary_accuracy: 0.9977\n","Epoch 2/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0129 - binary_accuracy: 0.9974 - val_loss: 0.0094 - val_binary_accuracy: 0.9984\n","Epoch 3/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0087 - binary_accuracy: 0.9986 - val_loss: 0.0118 - val_binary_accuracy: 0.9985\n","Epoch 4/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0070 - binary_accuracy: 0.9987 - val_loss: 0.0178 - val_binary_accuracy: 0.9975\n","Epoch 5/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0086 - binary_accuracy: 0.9987 - val_loss: 0.0248 - val_binary_accuracy: 0.9967\n","Epoch 6/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0072 - binary_accuracy: 0.9989 - val_loss: 0.0199 - val_binary_accuracy: 0.9975\n","Epoch 7/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0054 - binary_accuracy: 0.9989 - val_loss: 0.0140 - val_binary_accuracy: 0.9987\n","Epoch 8/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0086 - binary_accuracy: 0.9987 - val_loss: 0.0173 - val_binary_accuracy: 0.9977\n","Epoch 9/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0058 - binary_accuracy: 0.9992 - val_loss: 0.0234 - val_binary_accuracy: 0.9972\n","Epoch 10/10\n","3061/3061 [==============================] - 167s 54ms/step - loss: 0.0037 - binary_accuracy: 0.9995 - val_loss: 0.0128 - val_binary_accuracy: 0.9984\n","766/766 [==============================] - 13s 16ms/step - loss: 0.0128 - binary_accuracy: 0.9984\n","Loss: 0.012790115550160408\n","Accuracy: 0.9983665347099304\n","766/766 [==============================] - 12s 15ms/step\n","{'accuracy': 0.9978765109441359, 'precision': 0.9969176574196389, 'recall': 0.9973568281938326, 'f1_score': 0.9971371944505616, 'tp': 2264, 'tn': 3845, 'fp': 7, 'fn': 6, 'feature_method': 'bert_en_uncased_L-12_H-768_A-12', 'model': 'bert_en_uncased_L-12_H-768_A-12', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 68.76933526480656, 'pred_time': 2.059807928509667, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\n","Epoch 1/10\n","3061/3061 [==============================] - 183s 55ms/step - loss: 0.1257 - binary_accuracy: 0.9441 - val_loss: 0.0150 - val_binary_accuracy: 0.9972\n","Epoch 2/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0117 - binary_accuracy: 0.9976 - val_loss: 0.0110 - val_binary_accuracy: 0.9985\n","Epoch 3/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0055 - binary_accuracy: 0.9990 - val_loss: 0.0206 - val_binary_accuracy: 0.9980\n","Epoch 4/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0066 - binary_accuracy: 0.9989 - val_loss: 0.0114 - val_binary_accuracy: 0.9987\n","Epoch 5/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0056 - binary_accuracy: 0.9992 - val_loss: 0.0136 - val_binary_accuracy: 0.9989\n","Epoch 6/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0055 - binary_accuracy: 0.9993 - val_loss: 0.0115 - val_binary_accuracy: 0.9989\n","Epoch 7/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0067 - binary_accuracy: 0.9990 - val_loss: 0.0111 - val_binary_accuracy: 0.9989\n","Epoch 8/10\n","3061/3061 [==============================] - 164s 53ms/step - loss: 0.0064 - binary_accuracy: 0.9991 - val_loss: 0.0168 - val_binary_accuracy: 0.9987\n","Epoch 9/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0062 - binary_accuracy: 0.9990 - val_loss: 0.0155 - val_binary_accuracy: 0.9982\n","Epoch 10/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0176 - binary_accuracy: 0.9973 - val_loss: 0.0176 - val_binary_accuracy: 0.9967\n","766/766 [==============================] - 12s 16ms/step - loss: 0.0176 - binary_accuracy: 0.9967\n","Loss: 0.017641454935073853\n","Accuracy: 0.9967330694198608\n","766/766 [==============================] - 12s 15ms/step\n","{'accuracy': 0.9962430578242405, 'precision': 0.9916849015317286, 'recall': 0.9982378854625551, 'f1_score': 0.9949506037321625, 'tp': 2266, 'tn': 3833, 'fp': 19, 'fn': 4, 'feature_method': 'bert_en_cased_L-12_H-768_A-12', 'model': 'bert_en_cased_L-12_H-768_A-12', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 67.79726553397506, 'pred_time': 2.048929000126696, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1\n","Epoch 1/10\n","3061/3061 [==============================] - 59s 18ms/step - loss: 0.4831 - binary_accuracy: 0.7580 - val_loss: 0.1048 - val_binary_accuracy: 0.9673\n","Epoch 2/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0789 - binary_accuracy: 0.9765 - val_loss: 0.0407 - val_binary_accuracy: 0.9899\n","Epoch 3/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0417 - binary_accuracy: 0.9896 - val_loss: 0.0166 - val_binary_accuracy: 0.9954\n","Epoch 4/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0250 - binary_accuracy: 0.9941 - val_loss: 0.0096 - val_binary_accuracy: 0.9980\n","Epoch 5/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0174 - binary_accuracy: 0.9964 - val_loss: 0.0071 - val_binary_accuracy: 0.9989\n","Epoch 6/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0109 - binary_accuracy: 0.9976 - val_loss: 0.0076 - val_binary_accuracy: 0.9989\n","Epoch 7/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0099 - binary_accuracy: 0.9980 - val_loss: 0.0077 - val_binary_accuracy: 0.9990\n","Epoch 8/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0085 - binary_accuracy: 0.9982 - val_loss: 0.0079 - val_binary_accuracy: 0.9990\n","Epoch 9/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0064 - binary_accuracy: 0.9987 - val_loss: 0.0073 - val_binary_accuracy: 0.9992\n","Epoch 10/10\n","3061/3061 [==============================] - 55s 18ms/step - loss: 0.0051 - binary_accuracy: 0.9989 - val_loss: 0.0092 - val_binary_accuracy: 0.9987\n","766/766 [==============================] - 7s 10ms/step - loss: 0.0092 - binary_accuracy: 0.9987\n","Loss: 0.009229135699570179\n","Accuracy: 0.9986932277679443\n","766/766 [==============================] - 7s 9ms/step\n","{'accuracy': 0.9988565828160731, 'precision': 1.0, 'recall': 0.9969162995594714, 'f1_score': 0.9984557688065299, 'tp': 2263, 'tn': 3852, 'fp': 0, 'fn': 7, 'feature_method': 'small_bert/bert_en_uncased_L-2_H-128_A-2', 'model': 'small_bert/bert_en_uncased_L-2_H-128_A-2', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 22.687838174618438, 'pred_time': 1.2491817997780084, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n","Epoch 1/10\n","3061/3061 [==============================] - 82s 25ms/step - loss: 0.1516 - binary_accuracy: 0.9338 - val_loss: 0.0127 - val_binary_accuracy: 0.9971\n","Epoch 2/10\n","3061/3061 [==============================] - 74s 24ms/step - loss: 0.0171 - binary_accuracy: 0.9962 - val_loss: 0.0063 - val_binary_accuracy: 0.9990\n","Epoch 3/10\n","3061/3061 [==============================] - 75s 24ms/step - loss: 0.0090 - binary_accuracy: 0.9980 - val_loss: 0.0072 - val_binary_accuracy: 0.9985\n","Epoch 4/10\n","3061/3061 [==============================] - 74s 24ms/step - loss: 0.0079 - binary_accuracy: 0.9982 - val_loss: 0.0085 - val_binary_accuracy: 0.9985\n","Epoch 5/10\n","3061/3061 [==============================] - 74s 24ms/step - loss: 0.0066 - binary_accuracy: 0.9986 - val_loss: 0.0099 - val_binary_accuracy: 0.9979\n","Epoch 6/10\n","3061/3061 [==============================] - 74s 24ms/step - loss: 0.0048 - binary_accuracy: 0.9990 - val_loss: 0.0177 - val_binary_accuracy: 0.9984\n","Epoch 7/10\n","3061/3061 [==============================] - 75s 24ms/step - loss: 0.0057 - binary_accuracy: 0.9991 - val_loss: 0.0126 - val_binary_accuracy: 0.9982\n","Epoch 8/10\n","3061/3061 [==============================] - 74s 24ms/step - loss: 0.0054 - binary_accuracy: 0.9991 - val_loss: 0.0205 - val_binary_accuracy: 0.9980\n","Epoch 9/10\n","3061/3061 [==============================] - 74s 24ms/step - loss: 0.0047 - binary_accuracy: 0.9992 - val_loss: 0.0199 - val_binary_accuracy: 0.9980\n","Epoch 10/10\n","3061/3061 [==============================] - 74s 24ms/step - loss: 0.0035 - binary_accuracy: 0.9993 - val_loss: 0.0161 - val_binary_accuracy: 0.9980\n","766/766 [==============================] - 9s 11ms/step - loss: 0.0161 - binary_accuracy: 0.9980\n","Loss: 0.016093064099550247\n","Accuracy: 0.9980398416519165\n","766/766 [==============================] - 8s 10ms/step\n","{'accuracy': 0.9980398562561255, 'precision': 0.9982347749338041, 'recall': 0.9964757709251101, 'f1_score': 0.9973544973544974, 'tp': 2262, 'tn': 3848, 'fp': 4, 'fn': 8, 'feature_method': 'small_bert/bert_en_uncased_L-4_H-512_A-8', 'model': 'small_bert/bert_en_uncased_L-4_H-512_A-8', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 30.622556755102373, 'pred_time': 1.391619064184, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1\n","Epoch 1/10\n","3061/3061 [==============================] - 115s 34ms/step - loss: 0.2731 - binary_accuracy: 0.8757 - val_loss: 0.0457 - val_binary_accuracy: 0.9897\n","Epoch 2/10\n","3061/3061 [==============================] - 104s 34ms/step - loss: 0.0412 - binary_accuracy: 0.9907 - val_loss: 0.0137 - val_binary_accuracy: 0.9967\n","Epoch 3/10\n","3061/3061 [==============================] - 103s 34ms/step - loss: 0.0218 - binary_accuracy: 0.9956 - val_loss: 0.0084 - val_binary_accuracy: 0.9982\n","Epoch 4/10\n","3061/3061 [==============================] - 103s 34ms/step - loss: 0.0177 - binary_accuracy: 0.9964 - val_loss: 0.0107 - val_binary_accuracy: 0.9979\n","Epoch 5/10\n","3061/3061 [==============================] - 103s 34ms/step - loss: 0.0124 - binary_accuracy: 0.9975 - val_loss: 0.0127 - val_binary_accuracy: 0.9980\n","Epoch 6/10\n","3061/3061 [==============================] - 104s 34ms/step - loss: 0.0091 - binary_accuracy: 0.9981 - val_loss: 0.0093 - val_binary_accuracy: 0.9987\n","Epoch 7/10\n","3061/3061 [==============================] - 104s 34ms/step - loss: 0.0082 - binary_accuracy: 0.9985 - val_loss: 0.0150 - val_binary_accuracy: 0.9985\n","Epoch 8/10\n","3061/3061 [==============================] - 104s 34ms/step - loss: 0.0102 - binary_accuracy: 0.9982 - val_loss: 0.0090 - val_binary_accuracy: 0.9989\n","Epoch 9/10\n","3061/3061 [==============================] - 104s 34ms/step - loss: 0.0067 - binary_accuracy: 0.9989 - val_loss: 0.0078 - val_binary_accuracy: 0.9990\n","Epoch 10/10\n","3061/3061 [==============================] - 104s 34ms/step - loss: 0.0057 - binary_accuracy: 0.9989 - val_loss: 0.0091 - val_binary_accuracy: 0.9987\n","766/766 [==============================] - 9s 12ms/step - loss: 0.0091 - binary_accuracy: 0.9987\n","Loss: 0.009088876657187939\n","Accuracy: 0.9986932277679443\n","766/766 [==============================] - 10s 12ms/step\n","{'accuracy': 0.9986932375040837, 'precision': 0.9982378854625551, 'recall': 0.9982378854625551, 'f1_score': 0.9982378854625551, 'tp': 2266, 'tn': 3848, 'fp': 4, 'fn': 4, 'feature_method': 'small_bert/bert_en_uncased_L-8_H-128_A-2', 'model': 'small_bert/bert_en_uncased_L-8_H-128_A-2', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 42.80906163273784, 'pred_time': 1.6138235831798116, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1\n","Epoch 1/10\n","3061/3061 [==============================] - 181s 54ms/step - loss: 0.1312 - binary_accuracy: 0.9410 - val_loss: 0.0105 - val_binary_accuracy: 0.9977\n","Epoch 2/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0146 - binary_accuracy: 0.9973 - val_loss: 0.0122 - val_binary_accuracy: 0.9977\n","Epoch 3/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0101 - binary_accuracy: 0.9979 - val_loss: 0.0222 - val_binary_accuracy: 0.9972\n","Epoch 4/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0065 - binary_accuracy: 0.9991 - val_loss: 0.0172 - val_binary_accuracy: 0.9982\n","Epoch 5/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0091 - binary_accuracy: 0.9985 - val_loss: 0.0149 - val_binary_accuracy: 0.9985\n","Epoch 6/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0094 - binary_accuracy: 0.9985 - val_loss: 0.0091 - val_binary_accuracy: 0.9989\n","Epoch 7/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0080 - binary_accuracy: 0.9988 - val_loss: 0.0176 - val_binary_accuracy: 0.9980\n","Epoch 8/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0090 - binary_accuracy: 0.9988 - val_loss: 0.0439 - val_binary_accuracy: 0.9948\n","Epoch 9/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0067 - binary_accuracy: 0.9990 - val_loss: 0.0167 - val_binary_accuracy: 0.9985\n","Epoch 10/10\n","3061/3061 [==============================] - 164s 53ms/step - loss: 0.0068 - binary_accuracy: 0.9987 - val_loss: 0.0222 - val_binary_accuracy: 0.9974\n","766/766 [==============================] - 13s 16ms/step - loss: 0.0222 - binary_accuracy: 0.9974\n","Loss: 0.022158121690154076\n","Accuracy: 0.9973864555358887\n","766/766 [==============================] - 12s 15ms/step\n","{'accuracy': 0.9973864750081672, 'precision': 0.9947322212467077, 'recall': 0.9982378854625551, 'f1_score': 0.9964819700967459, 'tp': 2266, 'tn': 3840, 'fp': 12, 'fn': 4, 'feature_method': 'small_bert/bert_en_uncased_L-12_H-768_A-12', 'model': 'small_bert/bert_en_uncased_L-12_H-768_A-12', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 67.48214822277586, 'pred_time': 2.043110800116563, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3\n","Epoch 1/10\n","3061/3061 [==============================] - 206s 62ms/step - loss: 0.1035 - binary_accuracy: 0.9494 - val_loss: 0.0116 - val_binary_accuracy: 0.9984\n","Epoch 2/10\n","3061/3061 [==============================] - 189s 62ms/step - loss: 0.0132 - binary_accuracy: 0.9980 - val_loss: 0.0121 - val_binary_accuracy: 0.9989\n","Epoch 3/10\n","3061/3061 [==============================] - 190s 62ms/step - loss: 0.0095 - binary_accuracy: 0.9984 - val_loss: 0.0087 - val_binary_accuracy: 0.9992\n","Epoch 4/10\n","3061/3061 [==============================] - 190s 62ms/step - loss: 0.0094 - binary_accuracy: 0.9985 - val_loss: 0.0205 - val_binary_accuracy: 0.9975\n","Epoch 5/10\n","3061/3061 [==============================] - 189s 62ms/step - loss: 0.0104 - binary_accuracy: 0.9987 - val_loss: 0.0127 - val_binary_accuracy: 0.9985\n","Epoch 6/10\n","3061/3061 [==============================] - 190s 62ms/step - loss: 0.0083 - binary_accuracy: 0.9989 - val_loss: 0.0189 - val_binary_accuracy: 0.9982\n","Epoch 7/10\n","3061/3061 [==============================] - 192s 63ms/step - loss: 0.0121 - binary_accuracy: 0.9984 - val_loss: 0.0193 - val_binary_accuracy: 0.9982\n","Epoch 8/10\n","3061/3061 [==============================] - 191s 62ms/step - loss: 0.0194 - binary_accuracy: 0.9941 - val_loss: 0.0135 - val_binary_accuracy: 0.9985\n","Epoch 9/10\n","3061/3061 [==============================] - 191s 62ms/step - loss: 0.0510 - binary_accuracy: 0.9893 - val_loss: 0.0160 - val_binary_accuracy: 0.9980\n","Epoch 10/10\n","3061/3061 [==============================] - 190s 62ms/step - loss: 0.0186 - binary_accuracy: 0.9974 - val_loss: 0.0178 - val_binary_accuracy: 0.9979\n","766/766 [==============================] - 13s 16ms/step - loss: 0.0178 - binary_accuracy: 0.9979\n","Loss: 0.0177945327013731\n","Accuracy: 0.9978765249252319\n","766/766 [==============================] - 12s 15ms/step\n","{'accuracy': 0.9978765109441359, 'precision': 0.9977944419938244, 'recall': 0.9964757709251101, 'f1_score': 0.997134670487106, 'tp': 2262, 'tn': 3847, 'fp': 5, 'fn': 8, 'feature_method': 'bert_multi_cased_L-12_H-768_A-12', 'model': 'bert_multi_cased_L-12_H-768_A-12', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 78.33840470503499, 'pred_time': 2.0438962728904766, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/albert_en_base/2\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/albert_en_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/albert_en_base/2\n","Epoch 1/10\n","3061/3061 [==============================] - 170s 52ms/step - loss: 0.1043 - binary_accuracy: 0.9558 - val_loss: 0.0842 - val_binary_accuracy: 0.9881\n","Epoch 2/10\n","3061/3061 [==============================] - 157s 51ms/step - loss: 0.0467 - binary_accuracy: 0.9919 - val_loss: 0.0247 - val_binary_accuracy: 0.9966\n","Epoch 3/10\n","3061/3061 [==============================] - 156s 51ms/step - loss: 0.0303 - binary_accuracy: 0.9957 - val_loss: 0.0145 - val_binary_accuracy: 0.9979\n","Epoch 4/10\n","3061/3061 [==============================] - 157s 51ms/step - loss: 0.0301 - binary_accuracy: 0.9952 - val_loss: 0.0144 - val_binary_accuracy: 0.9979\n","Epoch 5/10\n","3061/3061 [==============================] - 159s 52ms/step - loss: 0.0329 - binary_accuracy: 0.9939 - val_loss: 0.0186 - val_binary_accuracy: 0.9972\n","Epoch 6/10\n","3061/3061 [==============================] - 160s 52ms/step - loss: 0.0270 - binary_accuracy: 0.9957 - val_loss: 0.0239 - val_binary_accuracy: 0.9966\n","Epoch 7/10\n","3061/3061 [==============================] - 160s 52ms/step - loss: 0.0690 - binary_accuracy: 0.9876 - val_loss: 0.0556 - val_binary_accuracy: 0.9899\n","Epoch 8/10\n","3061/3061 [==============================] - 159s 52ms/step - loss: 0.1915 - binary_accuracy: 0.9279 - val_loss: 0.0498 - val_binary_accuracy: 0.9923\n","Epoch 9/10\n","3061/3061 [==============================] - 158s 52ms/step - loss: 0.0380 - binary_accuracy: 0.9924 - val_loss: 0.0389 - val_binary_accuracy: 0.9944\n","Epoch 10/10\n","3061/3061 [==============================] - 159s 52ms/step - loss: 0.0231 - binary_accuracy: 0.9965 - val_loss: 0.0195 - val_binary_accuracy: 0.9975\n","766/766 [==============================] - 12s 16ms/step - loss: 0.0195 - binary_accuracy: 0.9975\n","Loss: 0.019486598670482635\n","Accuracy: 0.997549831867218\n","766/766 [==============================] - 12s 15ms/step\n","{'accuracy': 0.9975498203201568, 'precision': 0.9973533303925893, 'recall': 0.9960352422907489, 'f1_score': 0.9966938505620454, 'tp': 2261, 'tn': 3846, 'fp': 6, 'fn': 9, 'feature_method': 'albert_en_base', 'model': 'albert_en_base', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 65.16176399129385, 'pred_time': 1.9710840878242062, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/google/electra_base/2\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/google/electra_base/2\n","Epoch 1/10\n","3061/3061 [==============================] - 182s 54ms/step - loss: 0.1368 - binary_accuracy: 0.9385 - val_loss: 0.0189 - val_binary_accuracy: 0.9962\n","Epoch 2/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0195 - binary_accuracy: 0.9962 - val_loss: 0.0127 - val_binary_accuracy: 0.9979\n","Epoch 3/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0132 - binary_accuracy: 0.9975 - val_loss: 0.0166 - val_binary_accuracy: 0.9971\n","Epoch 4/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0130 - binary_accuracy: 0.9979 - val_loss: 0.0233 - val_binary_accuracy: 0.9971\n","Epoch 5/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0099 - binary_accuracy: 0.9980 - val_loss: 0.0081 - val_binary_accuracy: 0.9987\n","Epoch 6/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0103 - binary_accuracy: 0.9982 - val_loss: 0.0207 - val_binary_accuracy: 0.9975\n","Epoch 7/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0119 - binary_accuracy: 0.9984 - val_loss: 0.0260 - val_binary_accuracy: 0.9974\n","Epoch 8/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0088 - binary_accuracy: 0.9987 - val_loss: 0.0162 - val_binary_accuracy: 0.9972\n","Epoch 9/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0093 - binary_accuracy: 0.9984 - val_loss: 0.0178 - val_binary_accuracy: 0.9984\n","Epoch 10/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0121 - binary_accuracy: 0.9980 - val_loss: 0.0130 - val_binary_accuracy: 0.9982\n","766/766 [==============================] - 12s 16ms/step - loss: 0.0130 - binary_accuracy: 0.9982\n","Loss: 0.012969440780580044\n","Accuracy: 0.9982032179832458\n","766/766 [==============================] - 12s 15ms/step\n","{'accuracy': 0.998203201568115, 'precision': 0.9969203695556533, 'recall': 0.9982378854625551, 'f1_score': 0.9975786924939468, 'tp': 2266, 'tn': 3845, 'fp': 7, 'fn': 4, 'feature_method': 'electra_base', 'model': 'electra_base', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 68.10031622841753, 'pred_time': 2.047714007831562, 'dataset': 'SQLiV3.tsv'}\n","****************************************************\n","BERT model selected           : https://tfhub.dev/google/electra_small/2\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/google/electra_small/2\n","Epoch 1/10\n","3061/3061 [==============================] - 156s 45ms/step - loss: 0.1823 - binary_accuracy: 0.9288 - val_loss: 0.0177 - val_binary_accuracy: 0.9967\n","Epoch 2/10\n","3061/3061 [==============================] - 138s 45ms/step - loss: 0.0225 - binary_accuracy: 0.9958 - val_loss: 0.0087 - val_binary_accuracy: 0.9985\n","Epoch 3/10\n","3061/3061 [==============================] - 138s 45ms/step - loss: 0.0143 - binary_accuracy: 0.9972 - val_loss: 0.0084 - val_binary_accuracy: 0.9987\n","Epoch 4/10\n","3061/3061 [==============================] - 139s 45ms/step - loss: 0.0110 - binary_accuracy: 0.9980 - val_loss: 0.0158 - val_binary_accuracy: 0.9980\n","Epoch 5/10\n","3061/3061 [==============================] - 138s 45ms/step - loss: 0.0098 - binary_accuracy: 0.9983 - val_loss: 0.0159 - val_binary_accuracy: 0.9980\n","Epoch 6/10\n","3061/3061 [==============================] - 138s 45ms/step - loss: 0.0078 - binary_accuracy: 0.9986 - val_loss: 0.0137 - val_binary_accuracy: 0.9987\n","Epoch 7/10\n","3061/3061 [==============================] - 139s 45ms/step - loss: 0.0076 - binary_accuracy: 0.9986 - val_loss: 0.0169 - val_binary_accuracy: 0.9984\n","Epoch 8/10\n","3061/3061 [==============================] - 138s 45ms/step - loss: 0.0081 - binary_accuracy: 0.9987 - val_loss: 0.0063 - val_binary_accuracy: 0.9990\n","Epoch 9/10\n","3061/3061 [==============================] - 139s 45ms/step - loss: 0.0051 - binary_accuracy: 0.9990 - val_loss: 0.0134 - val_binary_accuracy: 0.9980\n","Epoch 10/10\n","3061/3061 [==============================] - 139s 46ms/step - loss: 0.0067 - binary_accuracy: 0.9987 - val_loss: 0.0174 - val_binary_accuracy: 0.9980\n","766/766 [==============================] - 11s 14ms/step - loss: 0.0174 - binary_accuracy: 0.9980\n","Loss: 0.017357932403683662\n","Accuracy: 0.9980398416519165\n","766/766 [==============================] - 11s 14ms/step\n","{'accuracy': 0.9980398562561255, 'precision': 0.9991158267020336, 'recall': 0.9955947136563876, 'f1_score': 0.9973521624007061, 'tp': 2260, 'tn': 3850, 'fp': 2, 'fn': 10, 'feature_method': 'electra_small', 'model': 'electra_small', 'seed': 13, 'split_ratio': 0.2, 'train_size': 24487, 'test_size': 6122, 'extraction_time': 0, 'feature_size': 0, 'train_time': 57.25308988757096, 'pred_time': 1.9256281953978016, 'dataset': 'SQLiV3.tsv'}\n"]}],"source":["for bert_model_name in bert_model_name_list:\n","  #bert_model_name = bert_model_name_list[0]\n","  print('****************************************************')\n","  #recording.set_current_method(f\"{bert_model_name}\" )\n","  tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n","  tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n","\n","  print(f'BERT model selected           : {tfhub_handle_encoder}')\n","  print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')\n","\n","\n","  bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n","  bert_model = hub.KerasLayer(tfhub_handle_encoder)\n","  classifier_model = build_classifier_model(tfhub_handle_preprocess, tfhub_handle_encoder)\n","\n","  loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","  metrics = tf.metrics.BinaryAccuracy()\n","\n","  epochs = 10 #modify this\n","  #steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n","  steps_per_epoch = data_manager.x_train.shape[0]\n","  num_train_steps = (steps_per_epoch * epochs) #//200 \n","  num_warmup_steps = int(0.1*num_train_steps)\n","\n","  init_lr = 3e-5\n","  optimizer = optimization.create_optimizer(init_lr=init_lr,\n","                                            num_train_steps=num_train_steps,\n","                                            num_warmup_steps=num_warmup_steps,\n","                                            optimizer_type='adamw')\n","\n","  classifier_model.compile(optimizer=optimizer,\n","                          loss=loss,\n","                          metrics=metrics)\n","\n","\n","  print(f'Training model with {tfhub_handle_encoder}')\n","  start_time = time.time()\n","  history = classifier_model.fit(x=train_ds, #train_ds.take(2)\n","                                validation_data=test_ds, # validation_data=test_ds.take(2),\n","                                epochs=epochs)\n","  stop_time = time.time()\n","  training_time = (stop_time - start_time)*1000 / data_manager.notes['train_size']\n","\n","  loss, accuracy = classifier_model.evaluate(test_ds)\n","\n","  print(f'Loss: {loss}')\n","  print(f'Accuracy: {accuracy}')\n","\n","  start_time = time.time()\n","  y_pred = classifier_model.predict(test_ds)\n","  stop_time = time.time()\n","  testing_time = (stop_time - start_time)*1000 / data_manager.notes['test_size']\n","  y_pred_np = tf.cast(tf.sigmoid(y_pred) \u003e 0.5, tf.int32).numpy()\n","  X, y_true = zip(*test_ds.unbatch())\n","  y_true_np = [y.numpy() for y in y_true]\n","  #precision, recall, f1, support = precision_recall_fscore_support(y_true_np, y_pred_np, average='binary')\n","  #tn, fp, fn, tp = confusion_matrix(y_true_np, y_pred_np).ravel()\n","\n","  notes = {'feature_method': bert_model_name,'model': bert_model_name, \n","           'seed': data_manager.notes['seed'], \n","           'split_ratio': data_manager.notes['split_ratio'],\n","           'train_size': data_manager.notes['train_size'],\n","           'test_size': data_manager.notes['test_size'],\n","           'extraction_time':0, 'feature_size':0,\n","           'train_time': training_time,\n","           'pred_time': testing_time, 'dataset': config['dataset']['file']}\n","  result = evaluate(y_true_np, y_pred_np, notes)\n","  print(result)\n","  save_results([result], output_file)\n"]},{"cell_type":"markdown","metadata":{"id":"K0ObPxN_G4oS"},"source":["## The Proposed Cascade NLP (two-stage) SQLi Detection Tests"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"49AP1MiEnHz8"},"outputs":[],"source":["# Data manager _ split with seed\n","from sklearn.model_selection import train_test_split\n","\n","def split_dataset(seed=42):\n","  split_ratio = float(data_manager.config['data_manager']['split_ratio'])\n","\n","  data_manager.train, data_manager.test = train_test_split(\n","    data_manager.dataset, test_size=split_ratio, random_state=seed)\n","\n","  data_manager.x_train = data_manager.train['payload'].values\n","  data_manager.x_test = data_manager.test['payload'].values\n","  data_manager.y_train = data_manager.train['label'].values\n","  data_manager.y_test = data_manager.test['label'].values\n","\n","  data_manager.notes = {\n","    'seed': seed,\n","    'split_ratio': split_ratio,\n","    'train_size': len(data_manager.train),\n","    'test_size': len(data_manager.test),\n","  }\n","\n","#split_dataset(seed=666)\n","#print(data_manager.notes['seed'])"]},{"cell_type":"markdown","metadata":{"id":"_nC5YnC-ULNx"},"source":["### First Stage - Classical ML"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"kLOa8sfNqfvw"},"outputs":[],"source":["from templates import FeatureExtractor\n","from classical_models import Classical_Model\n","from pprint import pprint\n","from experiments import evaluate\n","\n","xgboost_threshold = 0.05 #prediction\n","scale_pos_weight = 5000.0 #xgboost model parameter\n","\n","pass_aggressive_threshold = -0.3 #prediction\n","class_weights = {1: 0.999, 0: 0.001} #PassiveAggressiveClassifier model parameter\n","\n","feature_method = 'tf-idf_ngram'\n","#model_name = 'XGBoost'\n","#model_name = 'PassiveAggressiveClassifier'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pvsG1tcjBROW"},"outputs":[],"source":["\n","# Train and evaluate the first stage\n","def first_stage_passive_aggressive():\n","  model_name = 'PassiveAggressiveClassifier'\n","  feature_extractor = FeatureExtractor(feature_method)\n","  start_time = time.time()\n","  feature_extractor.extract_features(\n","      data_manager.x_train, data_manager.x_test)\n","  stop_time = time.time()\n","  extraction_time = ((stop_time - start_time)*1000 \n","                    / (len(data_manager.x_train) + len(data_manager.x_test)) )\n","\n","  model = Classical_Model(model_name, class_weight=class_weights) #MODIFY IT if you change the model\n","  model.feature_method = feature_extractor.method\n","  start_time = time.time()\n","  model.fit(\n","      feature_extractor.features['train'], \n","      data_manager.y_train) #scale_pos_weight=5.0\n","  stop_time = time.time()\n","  training_time = (stop_time - start_time)*1000 / feature_extractor.features['train'].shape[0]\n","\n","\n","  start_time = time.time()\n","  first_stage_y_pred = model.predict(feature_extractor.features['test'],  pass_aggressive_threshold=pass_aggressive_threshold)\n","  stop_time = time.time()\n","\n","  testing_time = (stop_time - start_time)*1000 / feature_extractor.features['test'].shape[0]\n","\n","  notes = {'feature_method': feature_extractor.method,'model': model_name, \n","            'seed': data_manager.notes['seed'], \n","            'split_ratio': data_manager.notes['split_ratio'],\n","            'train_size': data_manager.notes['train_size'],\n","            'test_size': data_manager.notes['test_size'],\n","            'extraction_time':extraction_time, 'feature_size': feature_extractor.features['train'].shape[1],\n","            'train_time': training_time,\n","            'pred_time': testing_time, 'dataset': config['dataset']['file'],\n","          'class_weights':class_weights,\n","          'pass_aggressive_threshold': pass_aggressive_threshold\n","          }\n","  # Save results to csv file\n","\n","  result = evaluate(data_manager.y_test, first_stage_y_pred, notes=notes)\n","  pprint(result)\n","  save_results([result], proposed_test_results_file)\n","\n","  # Extract the positive predicitions for the second stage\n","  first_stage_positive_preds = data_manager.x_test[(first_stage_y_pred == 1)]\n","  first_stage_positive_preds_true_labels = data_manager.y_test[(first_stage_y_pred == 1)]\n","  fs_pos_len = len(first_stage_positive_preds)\n","  nof_test_samples = len(data_manager.x_test)\n","  fs_rat = fs_pos_len/nof_test_samples\n","  print(f\"Positive predicitions in the first stage: {fs_pos_len} out of {nof_test_samples}. Ratio:{fs_rat}\")\n","\n","  return first_stage_positive_preds, first_stage_positive_preds_true_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SeqeDDr8HCVt"},"outputs":[],"source":["# Train and evaluate the first stage\n","def first_stage_xgboost():\n","  model_name = 'XGBoost'\n","  feature_extractor = FeatureExtractor(feature_method)\n","  start_time = time.time()\n","  feature_extractor.extract_features(\n","      data_manager.x_train, data_manager.x_test)\n","  stop_time = time.time()\n","  extraction_time = ((stop_time - start_time)*1000 \n","                    / (len(data_manager.x_train) + len(data_manager.x_test)) )\n","\n","  model = Classical_Model(model_name, scale_pos_weight=scale_pos_weight)\n","  model.feature_method = feature_extractor.method\n","  start_time = time.time()\n","  model.fit(\n","      feature_extractor.features['train'], \n","      data_manager.y_train) #scale_pos_weight=5.0\n","  stop_time = time.time()\n","  training_time = (stop_time - start_time)*1000 / feature_extractor.features['train'].shape[0]\n","\n","\n","  start_time = time.time()\n","  first_stage_y_pred = model.predict(feature_extractor.features['test'], xgboost_threshold=xgboost_threshold)\n","  stop_time = time.time()\n","\n","  testing_time = (stop_time - start_time)*1000 / feature_extractor.features['test'].shape[0]\n","\n","  notes = {'feature_method': feature_extractor.method,'model': model_name, \n","            'seed': data_manager.notes['seed'], \n","            'split_ratio': data_manager.notes['split_ratio'],\n","            'train_size': data_manager.notes['train_size'],\n","            'test_size': data_manager.notes['test_size'],\n","            'extraction_time':extraction_time, 'feature_size': feature_extractor.features['train'].shape[1],\n","            'train_time': training_time,\n","            'pred_time': testing_time, 'dataset': config['dataset']['file'],\n","          'scale_pos_weight':scale_pos_weight,\n","          'threshold': threshold\n","          }\n","  # Save results to csv file\n","\n","  result = evaluate(data_manager.y_test, first_stage_y_pred, notes=notes)\n","  pprint(result)\n","  save_results([result], proposed_test_results_file)\n","\n","  # Extract the positive predicitions for the second stage\n","  first_stage_positive_preds = data_manager.x_test[(first_stage_y_pred == 1)]\n","  first_stage_positive_preds_true_labels = data_manager.y_test[(first_stage_y_pred == 1)]\n","  fs_pos_len = len(first_stage_positive_preds)\n","  nof_test_samples = len(data_manager.x_test)\n","  fs_rat = fs_pos_len/nof_test_samples\n","  print(f\"Positive predicitions in the first stage: {fs_pos_len} out of {nof_test_samples}. Ratio:{fs_rat}\")\n","\n","  return first_stage_positive_preds, first_stage_positive_preds_true_labels"]},{"cell_type":"markdown","metadata":{"id":"Xg20dUuRWJ-4"},"source":["### Second Stage - BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WrftzeG9XwOx"},"outputs":[],"source":["def second_stage(first_stage_positive_preds, first_stage_positive_preds_true_labels):\n","  # Prepare the training Dataset \n","  currentDateAndTime = datetime.now()\n","  currentTime = currentDateAndTime.strftime(\"%y%m%d_%H%M%S\")\n","  #recording = Recorder(main_folder / results_dir / f'results_BERT_{currentTime}.csv')\n","\n","\n","  AUTOTUNE = tf.data.AUTOTUNE\n","  batch_size = 8\n","  #seed = 42\n","\n","  x_train = data_manager.x_train\n","  y_train = data_manager.y_train\n","  x_test = data_manager.x_test\n","  y_test = data_manager.y_test\n","\n","  # Create TensorFlow datasets for the training and validation sets\n","  train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n","  val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n","\n","  # Cache the training and validation datasets\n","  train_dataset = train_dataset.cache()\n","  val_dataset = val_dataset.cache()\n","\n","\n","  # Prefetch the training and validation datasets\n","  train_ds = train_dataset.prefetch(buffer_size=AUTOTUNE)\n","  test_ds = val_dataset.prefetch(buffer_size=AUTOTUNE)\n","\n","  class_names = ['payload','label']\n","\n","  # First, train the BERT model.\n","\n","  print('****************************************************')\n","  bert_model_name = 'bert_en_uncased_L-12_H-768_A-12'\n","  tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n","  tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n","\n","  print(f'BERT model selected           : {tfhub_handle_encoder}')\n","  print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')\n","\n","\n","  bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n","  bert_model = hub.KerasLayer(tfhub_handle_encoder)\n","  second_stage_classifier_model = build_classifier_model(tfhub_handle_preprocess, tfhub_handle_encoder)\n","\n","  loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","  metrics = tf.metrics.BinaryAccuracy()\n","\n","  epochs = 10 #DEBUG MODIFY ME\n","  #steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n","  steps_per_epoch = data_manager.x_train.shape[0]\n","  num_train_steps = (steps_per_epoch * epochs) #//200 \n","  num_warmup_steps = int(0.1*num_train_steps)\n","\n","  init_lr = 3e-5\n","  optimizer = optimization.create_optimizer(init_lr=init_lr,\n","                                            num_train_steps=num_train_steps,\n","                                            num_warmup_steps=num_warmup_steps,\n","                                            optimizer_type='adamw')\n","\n","  second_stage_classifier_model.compile(optimizer=optimizer,\n","                          loss=loss,\n","                          metrics=metrics)\n","\n","\n","  print(f'Training model with {tfhub_handle_encoder}')\n","  start_time = time.time()\n","  history = second_stage_classifier_model.fit(x=train_ds, # x=train_ds.take(2), \n","                                validation_data=test_ds, # validation_data=test_ds.take(2), \n","                                epochs=epochs)\n","  stop_time = time.time()\n","  training_time = (stop_time - start_time)*1000 / data_manager.notes['train_size']\n","\n","  # Prepare first stage outputs for the second stage\n","  print(len(first_stage_positive_preds)) #np array\n","  print(len(first_stage_positive_preds_true_labels)) # np array\n","\n","  # Create TensorFlow datasets for the prediction set\n","  pred_dataset = tf.data.Dataset.from_tensor_slices(\n","      (first_stage_positive_preds, first_stage_positive_preds_true_labels)).batch(batch_size)\n","\n","  # Cache the pred dataset\n","  pred_dataset = pred_dataset.cache()\n","\n","  # Prefetch the pred datasets\n","  first_stage_pos_preds = pred_dataset.prefetch(buffer_size=AUTOTUNE)\n","\n","  # Predict only positive outputs of the first stage\n","  start_time = time.time()\n","  y_pred = second_stage_classifier_model.predict(first_stage_pos_preds)#.take(2))\n","  stop_time = time.time()\n","  testing_time = (stop_time - start_time)*1000 / len(first_stage_positive_preds) \n","  y_pred_np = tf.cast(tf.sigmoid(y_pred) \u003e 0.5, tf.int32).numpy()\n","  X, y_true = zip(*first_stage_pos_preds.unbatch())# take(2).\n","  y_true_np = [y.numpy() for y in y_true]\n","  #precision, recall, f1, support = precision_recall_fscore_support(y_true_np, y_pred_np, average='binary')\n","  #tn, fp, fn, tp = confusion_matrix(y_true_np, y_pred_np).ravel()\n","\n","  notes = {'feature_method': bert_model_name,'model': bert_model_name, \n","            'seed': data_manager.notes['seed'], \n","            'split_ratio': data_manager.notes['split_ratio'],\n","            'train_size': data_manager.notes['train_size'],\n","            'test_size': data_manager.notes['test_size'],\n","            'extraction_time':0, 'feature_size':0,\n","            'train_time': training_time,\n","            'pred_time': testing_time, 'dataset': config['dataset']['file']}\n","  result = evaluate(y_true_np, y_pred_np, notes)\n","  pprint(result)\n","  save_results([result], proposed_test_results_file)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"UqfbUsmjrhSB"},"outputs":[{"name":"stdout","output_type":"stream","text":["######################################\n","seed:13\n","13\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.9888925187847108,\n"," 'class_weights': {0: 0.001, 1: 0.999},\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0.07392269732604799,\n"," 'f1_score': 0.9852045256744996,\n"," 'feature_method': 'tf-idf_ngram',\n"," 'feature_size': 29157,\n"," 'fn': 6,\n"," 'fp': 62,\n"," 'model': 'PassiveAggressiveClassifier',\n"," 'pass_aggressive_threshold': -0.3,\n"," 'precision': 0.9733447979363714,\n"," 'pred_time': 0.0005551936072642723,\n"," 'recall': 0.9973568281938326,\n"," 'seed': 13,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 3790,\n"," 'tp': 2264,\n"," 'train_size': 24487,\n"," 'train_time': 0.03486571103783525}\n","Positive predicitions in the first stage: 2326 out of 6122. Ratio:0.37994119568768375\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n","Epoch 1/10\n","3061/3061 [==============================] - 181s 54ms/step - loss: 0.1740 - binary_accuracy: 0.9345 - val_loss: 0.0097 - val_binary_accuracy: 0.9980\n","Epoch 2/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0145 - binary_accuracy: 0.9973 - val_loss: 0.0123 - val_binary_accuracy: 0.9982\n","Epoch 3/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0067 - binary_accuracy: 0.9987 - val_loss: 0.0124 - val_binary_accuracy: 0.9987\n","Epoch 4/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0072 - binary_accuracy: 0.9985 - val_loss: 0.0173 - val_binary_accuracy: 0.9987\n","Epoch 5/10\n","3061/3061 [==============================] - 164s 53ms/step - loss: 0.0086 - binary_accuracy: 0.9987 - val_loss: 0.0162 - val_binary_accuracy: 0.9977\n","Epoch 6/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0091 - binary_accuracy: 0.9987 - val_loss: 0.0150 - val_binary_accuracy: 0.9984\n","Epoch 7/10\n","3061/3061 [==============================] - 164s 53ms/step - loss: 0.0054 - binary_accuracy: 0.9991 - val_loss: 0.0141 - val_binary_accuracy: 0.9987\n","Epoch 8/10\n","3061/3061 [==============================] - 164s 53ms/step - loss: 0.0086 - binary_accuracy: 0.9987 - val_loss: 0.0130 - val_binary_accuracy: 0.9985\n","Epoch 9/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0073 - binary_accuracy: 0.9991 - val_loss: 0.0173 - val_binary_accuracy: 0.9979\n","Epoch 10/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0086 - binary_accuracy: 0.9987 - val_loss: 0.0153 - val_binary_accuracy: 0.9980\n","2326\n","2326\n","291/291 [==============================] - 5s 15ms/step\n","{'accuracy': 0.9978503869303526,\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0,\n"," 'f1_score': 0.998896490840874,\n"," 'feature_method': 'bert_en_uncased_L-12_H-768_A-12',\n"," 'feature_size': 0,\n"," 'fn': 1,\n"," 'fp': 4,\n"," 'model': 'bert_en_uncased_L-12_H-768_A-12',\n"," 'precision': 0.9982355535950596,\n"," 'pred_time': 2.2640426099454136,\n"," 'recall': 0.9995583038869258,\n"," 'seed': 13,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 58,\n"," 'tp': 2263,\n"," 'train_size': 24487,\n"," 'train_time': 67.67243546824615}\n","######################################\n","seed:27\n","27\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.9890558640967004,\n"," 'class_weights': {0: 0.001, 1: 0.999},\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0.07376585468144055,\n"," 'f1_score': 0.9854252773547967,\n"," 'feature_method': 'tf-idf_ngram',\n"," 'feature_size': 29212,\n"," 'fn': 7,\n"," 'fp': 60,\n"," 'model': 'PassiveAggressiveClassifier',\n"," 'pass_aggressive_threshold': -0.3,\n"," 'precision': 0.9741935483870968,\n"," 'pred_time': 0.0005499750366011541,\n"," 'recall': 0.996919014084507,\n"," 'seed': 27,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 3790,\n"," 'tp': 2265,\n"," 'train_size': 24487,\n"," 'train_time': 0.033522575245377925}\n","Positive predicitions in the first stage: 2325 out of 6122. Ratio:0.3797778503756942\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n","Epoch 1/10\n","3061/3061 [==============================] - 181s 54ms/step - loss: 0.1656 - binary_accuracy: 0.9160 - val_loss: 0.0099 - val_binary_accuracy: 0.9982\n","Epoch 2/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0142 - binary_accuracy: 0.9972 - val_loss: 0.0099 - val_binary_accuracy: 0.9980\n","Epoch 3/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0096 - binary_accuracy: 0.9984 - val_loss: 0.0078 - val_binary_accuracy: 0.9987\n","Epoch 4/10\n","3061/3061 [==============================] - 164s 53ms/step - loss: 0.0080 - binary_accuracy: 0.9987 - val_loss: 0.0080 - val_binary_accuracy: 0.9987\n","Epoch 5/10\n","3061/3061 [==============================] - 164s 53ms/step - loss: 0.0070 - binary_accuracy: 0.9990 - val_loss: 0.0114 - val_binary_accuracy: 0.9982\n","Epoch 6/10\n","3061/3061 [==============================] - 164s 53ms/step - loss: 0.0073 - binary_accuracy: 0.9987 - val_loss: 0.0087 - val_binary_accuracy: 0.9987\n","Epoch 7/10\n","3061/3061 [==============================] - 164s 53ms/step - loss: 0.0093 - binary_accuracy: 0.9986 - val_loss: 0.0158 - val_binary_accuracy: 0.9979\n","Epoch 8/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0086 - binary_accuracy: 0.9988 - val_loss: 0.0135 - val_binary_accuracy: 0.9984\n","Epoch 9/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0091 - binary_accuracy: 0.9986 - val_loss: 0.0150 - val_binary_accuracy: 0.9982\n","Epoch 10/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0110 - binary_accuracy: 0.9985 - val_loss: 0.0097 - val_binary_accuracy: 0.9987\n","2325\n","2325\n","291/291 [==============================] - 5s 15ms/step\n","{'accuracy': 0.9991397849462366,\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0,\n"," 'f1_score': 0.999558693733451,\n"," 'feature_method': 'bert_en_uncased_L-12_H-768_A-12',\n"," 'feature_size': 0,\n"," 'fn': 0,\n"," 'fp': 2,\n"," 'model': 'bert_en_uncased_L-12_H-768_A-12',\n"," 'precision': 0.9991177767975298,\n"," 'pred_time': 2.306256550614552,\n"," 'recall': 1.0,\n"," 'seed': 27,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 58,\n"," 'tp': 2265,\n"," 'train_size': 24487,\n"," 'train_time': 67.61394256072722}\n","######################################\n","seed:42\n","42\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.9898725906566481,\n"," 'class_weights': {0: 0.001, 1: 0.999},\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0.07419651766417522,\n"," 'f1_score': 0.9865100087032203,\n"," 'feature_method': 'tf-idf_ngram',\n"," 'feature_size': 29216,\n"," 'fn': 6,\n"," 'fp': 56,\n"," 'model': 'PassiveAggressiveClassifier',\n"," 'pass_aggressive_threshold': -0.3,\n"," 'precision': 0.9758932414980629,\n"," 'pred_time': 0.0005493908682433424,\n"," 'recall': 0.9973603167619886,\n"," 'seed': 42,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 3793,\n"," 'tp': 2267,\n"," 'train_size': 24487,\n"," 'train_time': 0.03511589135351355}\n","Positive predicitions in the first stage: 2323 out of 6122. Ratio:0.3794511597517151\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n","Epoch 1/10\n","3061/3061 [==============================] - 181s 54ms/step - loss: 0.1204 - binary_accuracy: 0.9612 - val_loss: 0.0264 - val_binary_accuracy: 0.9959\n","Epoch 2/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0155 - binary_accuracy: 0.9973 - val_loss: 0.0174 - val_binary_accuracy: 0.9979\n","Epoch 3/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0083 - binary_accuracy: 0.9985 - val_loss: 0.0192 - val_binary_accuracy: 0.9979\n","Epoch 4/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0067 - binary_accuracy: 0.9989 - val_loss: 0.0139 - val_binary_accuracy: 0.9989\n","Epoch 5/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0075 - binary_accuracy: 0.9988 - val_loss: 0.0225 - val_binary_accuracy: 0.9975\n","Epoch 6/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0056 - binary_accuracy: 0.9991 - val_loss: 0.0155 - val_binary_accuracy: 0.9975\n","Epoch 7/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0059 - binary_accuracy: 0.9992 - val_loss: 0.0141 - val_binary_accuracy: 0.9989\n","Epoch 8/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0069 - binary_accuracy: 0.9991 - val_loss: 0.0140 - val_binary_accuracy: 0.9984\n","Epoch 9/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0119 - binary_accuracy: 0.9984 - val_loss: 0.0423 - val_binary_accuracy: 0.9940\n","Epoch 10/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0081 - binary_accuracy: 0.9989 - val_loss: 0.0210 - val_binary_accuracy: 0.9975\n","2323\n","2323\n","291/291 [==============================] - 5s 15ms/step\n","{'accuracy': 0.9961256995264743,\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0,\n"," 'f1_score': 0.9980136835135732,\n"," 'feature_method': 'bert_en_uncased_L-12_H-768_A-12',\n"," 'feature_size': 0,\n"," 'fn': 6,\n"," 'fp': 3,\n"," 'model': 'bert_en_uncased_L-12_H-768_A-12',\n"," 'precision': 0.9986749116607774,\n"," 'pred_time': 2.2536608046927022,\n"," 'recall': 0.9973533303925893,\n"," 'seed': 42,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 53,\n"," 'tp': 2261,\n"," 'train_size': 24487,\n"," 'train_time': 67.93159020313632}\n","######################################\n","seed:72\n","72\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.9880757922247632,\n"," 'class_weights': {0: 0.001, 1: 0.999},\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0.07458565660348505,\n"," 'f1_score': 0.9842093878433917,\n"," 'feature_method': 'tf-idf_ngram',\n"," 'feature_size': 29275,\n"," 'fn': 6,\n"," 'fp': 67,\n"," 'model': 'PassiveAggressiveClassifier',\n"," 'pass_aggressive_threshold': -0.3,\n"," 'precision': 0.9713919726729291,\n"," 'pred_time': 0.0005686684240511296,\n"," 'recall': 0.9973695747479175,\n"," 'seed': 72,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 3774,\n"," 'tp': 2275,\n"," 'train_size': 24487,\n"," 'train_time': 0.033912095140650404}\n","Positive predicitions in the first stage: 2342 out of 6122. Ratio:0.3825547206795165\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n","Epoch 1/10\n","3061/3061 [==============================] - 182s 54ms/step - loss: 0.1492 - binary_accuracy: 0.9318 - val_loss: 0.0116 - val_binary_accuracy: 0.9975\n","Epoch 2/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0120 - binary_accuracy: 0.9973 - val_loss: 0.0091 - val_binary_accuracy: 0.9985\n","Epoch 3/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0086 - binary_accuracy: 0.9984 - val_loss: 0.0136 - val_binary_accuracy: 0.9982\n","Epoch 4/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0093 - binary_accuracy: 0.9985 - val_loss: 0.0132 - val_binary_accuracy: 0.9974\n","Epoch 5/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0073 - binary_accuracy: 0.9987 - val_loss: 0.0204 - val_binary_accuracy: 0.9980\n","Epoch 6/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0039 - binary_accuracy: 0.9994 - val_loss: 0.0144 - val_binary_accuracy: 0.9984\n","Epoch 7/10\n","3061/3061 [==============================] - 164s 54ms/step - loss: 0.0063 - binary_accuracy: 0.9992 - val_loss: 0.0168 - val_binary_accuracy: 0.9982\n","Epoch 8/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0076 - binary_accuracy: 0.9986 - val_loss: 0.0149 - val_binary_accuracy: 0.9984\n","Epoch 9/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0073 - binary_accuracy: 0.9990 - val_loss: 0.0193 - val_binary_accuracy: 0.9977\n","Epoch 10/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0047 - binary_accuracy: 0.9994 - val_loss: 0.0161 - val_binary_accuracy: 0.9977\n","2342\n","2342\n","293/293 [==============================] - 5s 15ms/step\n","{'accuracy': 0.9982920580700256,\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0,\n"," 'f1_score': 0.9991204925241866,\n"," 'feature_method': 'bert_en_uncased_L-12_H-768_A-12',\n"," 'feature_size': 0,\n"," 'fn': 3,\n"," 'fp': 1,\n"," 'model': 'bert_en_uncased_L-12_H-768_A-12',\n"," 'precision': 0.9995600527936648,\n"," 'pred_time': 2.302128061283154,\n"," 'recall': 0.9986813186813187,\n"," 'seed': 72,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 66,\n"," 'tp': 2272,\n"," 'train_size': 24487,\n"," 'train_time': 67.96697048041285}\n","######################################\n","seed:84\n","84\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:563: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.9895459000326691,\n"," 'class_weights': {0: 0.001, 1: 0.999},\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0.07532702941405994,\n"," 'f1_score': 0.9858719646799118,\n"," 'feature_method': 'tf-idf_ngram',\n"," 'feature_size': 29187,\n"," 'fn': 6,\n"," 'fp': 58,\n"," 'model': 'PassiveAggressiveClassifier',\n"," 'pass_aggressive_threshold': -0.3,\n"," 'precision': 0.9746835443037974,\n"," 'pred_time': 0.0005796507891779902,\n"," 'recall': 0.9973202322465387,\n"," 'seed': 84,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 3825,\n"," 'tp': 2233,\n"," 'train_size': 24487,\n"," 'train_time': 0.03687216787976584}\n","Positive predicitions in the first stage: 2291 out of 6122. Ratio:0.37422410976804965\n","****************************************************\n","BERT model selected           : https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n","Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","Training model with https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n","Epoch 1/10\n","3061/3061 [==============================] - 181s 54ms/step - loss: 0.1462 - binary_accuracy: 0.9369 - val_loss: 0.0200 - val_binary_accuracy: 0.9966\n","Epoch 2/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0150 - binary_accuracy: 0.9969 - val_loss: 0.0073 - val_binary_accuracy: 0.9987\n","Epoch 3/10\n","3061/3061 [==============================] - 163s 53ms/step - loss: 0.0103 - binary_accuracy: 0.9979 - val_loss: 0.0155 - val_binary_accuracy: 0.9982\n","Epoch 4/10\n","3061/3061 [==============================] - 164s 53ms/step - loss: 0.0059 - binary_accuracy: 0.9991 - val_loss: 0.0151 - val_binary_accuracy: 0.9980\n","Epoch 5/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0065 - binary_accuracy: 0.9989 - val_loss: 0.0127 - val_binary_accuracy: 0.9984\n","Epoch 6/10\n","3061/3061 [==============================] - 165s 54ms/step - loss: 0.0107 - binary_accuracy: 0.9984 - val_loss: 0.0083 - val_binary_accuracy: 0.9984\n","Epoch 7/10\n","3061/3061 [==============================] - 166s 54ms/step - loss: 0.0053 - binary_accuracy: 0.9991 - val_loss: 0.0155 - val_binary_accuracy: 0.9984\n","Epoch 8/10\n","3061/3061 [==============================] - 169s 55ms/step - loss: 0.0049 - binary_accuracy: 0.9993 - val_loss: 0.0105 - val_binary_accuracy: 0.9989\n","Epoch 9/10\n","3061/3061 [==============================] - 169s 55ms/step - loss: 0.0047 - binary_accuracy: 0.9994 - val_loss: 0.0078 - val_binary_accuracy: 0.9989\n","Epoch 10/10\n","3061/3061 [==============================] - 169s 55ms/step - loss: 0.0029 - binary_accuracy: 0.9996 - val_loss: 0.0097 - val_binary_accuracy: 0.9992\n","2291\n","2291\n","287/287 [==============================] - 5s 15ms/step\n","{'accuracy': 0.9995635093845482,\n"," 'dataset': 'SQLiV3.tsv',\n"," 'extraction_time': 0,\n"," 'f1_score': 0.9997761361092455,\n"," 'feature_method': 'bert_en_uncased_L-12_H-768_A-12',\n"," 'feature_size': 0,\n"," 'fn': 0,\n"," 'fp': 1,\n"," 'model': 'bert_en_uncased_L-12_H-768_A-12',\n"," 'precision': 0.9995523724261415,\n"," 'pred_time': 2.3732173916347574,\n"," 'recall': 1.0,\n"," 'seed': 84,\n"," 'split_ratio': 0.2,\n"," 'test_size': 6122,\n"," 'tn': 57,\n"," 'tp': 2233,\n"," 'train_size': 24487,\n"," 'train_time': 68.49562979155388}\n"]}],"source":["# Run first and second stages with different seeds:\n","seeds = [13, 27, 42, 72, 84]# 34, 1984, 1994, 77]\n","for seed in seeds:\n","  print('######################################')\n","  print(f\"seed:{seed}\")\n","  split_dataset(seed=seed)\n","  print(data_manager.notes['seed'])\n","  #first_stage_y_pred, first_stage_positive_preds_true_labels = first_stage_xgboost()\n","  first_stage_y_pred, first_stage_positive_preds_true_labels = first_stage_passive_aggressive()\n","  second_stage(first_stage_y_pred, first_stage_positive_preds_true_labels)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"","provenance":[{"file_id":"https://github.com/tensorflow/text/blob/master/docs/tutorials/classify_text_with_bert.ipynb","timestamp":1675862264150}],"version":""},"gpuClass":"premium","kernelspec":{"display_name":"rafi-sqli","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"vscode":{"interpreter":{"hash":"085c9640c77a34c1b406144a3bd4a3c83460825e7fcd209668d2630032a9442a"}}},"nbformat":4,"nbformat_minor":0}